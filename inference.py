import asyncio
import aiohttp
import pandas as pd
import json
import re
import pickle
import sys
import os
import time
import logging
from pathlib import Path
from aiolimiter import AsyncLimiter
from qdrant_client import AsyncQdrantClient, models
from underthesea import word_tokenize
from config import Config

# ==============================================================================
# 0. CONFIG & LOGGING
# ==============================================================================
Config.LOGS_DIR.mkdir(parents=True, exist_ok=True)
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)s | %(message)s',
    handlers=[
        logging.FileHandler(Config.LOGS_DIR / 'inference.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger("VNPT_BOT")

LIMITER_EMBED = AsyncLimiter(300, 60) # 300 req/phÃºt
LIMITER_LLM = AsyncLimiter(50, 60)    # 50 req/phÃºt (An toÃ n tuyá»‡t Ä‘á»‘i)

MAX_CONCURRENT_TASKS = 4 # Giáº£m xuá»‘ng 4 Ä‘á»ƒ trÃ¡nh ngháº½n
TIMEOUT_PER_QUESTION = 240 
THRESHOLD_LARGE_CHARS = 40000 
TOP_K = 12 
ALPHA_VECTOR = 0.7
BM25_FILE = Config.OUTPUT_DIR / "bm25_index.pkl"

# ==============================================================================
# 1. SMART SAFETY CHECK (OFFLINE - KHÃ”NG Gá»ŒI API)
# ==============================================================================
def is_sensitive_topic(question):
    """
    Kiá»ƒm tra nháº¡y cáº£m thÃ´ng minh:
    - Block: CÃ¡c tá»« khÃ³a Ä‘en.
    - Allow: Náº¿u cÃ³ tá»« khÃ³a há»c thuáº­t/phÃ¡p luáº­t Ä‘i kÃ¨m thÃ¬ CHO PHÃ‰P.
    """
    q_lower = question.lower()
    
    # 1. Danh sÃ¡ch Ä‘en
    blacklist = [
        "sex", "khiÃªu dÃ¢m", "Ä‘á»“i trá»¥y", "lÃ m tÃ¬nh", "áº¥u dÃ¢m", "kÃ­ch dá»¥c",
        "báº¡o Ä‘á»™ng", "láº­t Ä‘á»•", "pháº£n Ä‘á»™ng", "khá»§ng bá»‘", "biá»ƒu tÃ¬nh", "chá»‘ng phÃ¡",
        "giáº¿t ngÆ°á»i", "tá»± tá»­", "ma tÃºy", "buÃ´n láº­u", "vÅ© khÃ­", "báº¡o lá»±c",
        "xÃºc pháº¡m", "lÄƒng máº¡", "Ä‘áº£ng cá»™ng sáº£n", "xuyÃªn táº¡c", "cá» báº¡c", "cÃ¡ Ä‘á»™"
    ]
    
    # 2. Danh sÃ¡ch tráº¯ng (Báº£o vá»‡ cÃ¡c cÃ¢u há»i há»c thuáº­t)
    whitelist = [
        "luáº­t", "nghá»‹ Ä‘á»‹nh", "quy Ä‘á»‹nh", "thÃ´ng tÆ°", "phÃ¡p luáº­t", "hiáº¿n phÃ¡p",
        "lá»‹ch sá»­", "chiáº¿n tranh", "khÃ¡ng chiáº¿n", "vá»¥ Ã¡n", "tÃ²a Ã¡n", "xÃ©t xá»­",
        "tÃ¡c háº¡i", "phÃ²ng chá»‘ng", "ngÄƒn cháº·n", "khÃ¡i niá»‡m", "Ä‘á»‹nh nghÄ©a"
    ]

    has_bad_word = any(w in q_lower for w in blacklist)
    has_good_word = any(w in q_lower for w in whitelist)

    # Náº¿u cÃ³ tá»« xáº¥u NHÆ¯NG cÅ©ng cÃ³ tá»« há»c thuáº­t -> Coi lÃ  AN TOÃ€N (False positive)
    if has_bad_word and has_good_word:
        return False # Safe
    
    return has_bad_word # Unsafe

def find_refusal_key(options_map):
    keywords = ["khÃ´ng thá»ƒ tráº£ lá»i", "tá»« chá»‘i", "vi pháº¡m", "nháº¡y cáº£m", "khÃ´ng phÃ¹ há»£p", "tÃ¡c Ä‘á»™ng tiÃªu cá»±c"]
    for label, text in options_map.items():
        if any(kw in str(text).lower() for kw in keywords):
            return label
    return None

# ==============================================================================
# 2. RETRIEVER (DEPENDENCY INJECTION)
# ==============================================================================
class HybridRetriever:
    def __init__(self, qdrant_client):
        # Nháº­n client tá»« bÃªn ngoÃ i vÃ o (Dependency Injection)
        self.client = qdrant_client
        self.bm25 = None
        if BM25_FILE.exists():
            try:
                with open(BM25_FILE, "rb") as f: self.bm25 = pickle.load(f)
            except Exception as e:
                logger.error(f"BM25 Load Error: {e}")

    async def search_qdrant_retry(self, query_vec, top_k, max_retries=3):
        for i in range(max_retries):
            try:
                # DÃ¹ng query_points (API má»›i)
                response = await self.client.query_points(
                    collection_name=Config.COLLECTION_NAME,
                    query=query_vec,
                    limit=top_k,
                    with_payload=True
                )
                return response.points
            except Exception as e:
                if i == max_retries - 1:
                    logger.error(f"âŒ Qdrant Fail: {e}")
                    return []
                await asyncio.sleep(1)
        return []

    async def search(self, session, query, top_k=TOP_K):
        # Vector Search
        query_vec = await get_embedding_async(session, query)
        vec_hits = []
        if query_vec:
            vec_hits = await self.search_qdrant_retry(query_vec, top_k)
        
        # BM25 Search
        bm25_hits = []
        if self.bm25:
            try:
                tokens = word_tokenize(query.lower())
                scores = self.bm25['bm25_obj'].get_scores(tokens)
                top_idxs = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:top_k*2]
                
                batch_scores = [scores[i] for i in top_idxs]
                threshold = 1.0
                if batch_scores:
                    dynamic_thresh = batch_scores[int(len(batch_scores) * 0.3)]
                    threshold = max(1.0, dynamic_thresh)

                for idx in top_idxs:
                    if scores[idx] >= threshold: 
                        bm25_hits.append({
                            "id": self.bm25['chunk_ids'][idx], 
                            "score": scores[idx], 
                            "text": self.bm25['texts'][idx], 
                            "title": self.bm25['titles'][idx]
                        })
            except Exception as e:
                logger.error(f"BM25 Error: {e}")

        # Fusion
        fused = {}
        max_v = max([h.score for h in vec_hits]) if vec_hits else 1.0
        for h in vec_hits:
            fused[h.payload['chunk_id']] = {"text": h.payload['text'], "title": h.payload['title'], "score": (h.score/max_v)*ALPHA_VECTOR}
        
        max_b = max([h['score'] for h in bm25_hits]) if bm25_hits else 1.0
        for h in bm25_hits:
            norm = (h['score']/max_b)*(1-ALPHA_VECTOR)
            cid = h['id']
            if cid in fused: fused[cid]['score'] += norm
            else: fused[cid] = {"text": h['text'], "title": h['title'], "score": norm}
            
        return sorted(fused.values(), key=lambda x: x['score'], reverse=True)[:top_k]

# ==============================================================================
# 3. API CLIENTS & PROMPTS
# ==============================================================================
async def call_llm_generic(session, messages, model_name, max_tokens=1024, retry=3):
    creds = Config.VNPT_CREDENTIALS.get(model_name)
    url = f"{Config.VNPT_API_URL}/{model_name.replace('_', '-')}"
    headers = {'Authorization': f'Bearer {Config.VNPT_ACCESS_TOKEN}', 'Token-id': creds['token_id'], 'Token-key': creds['token_key'], 'Content-Type': 'application/json'}
    payload = {"model": model_name, "messages": messages, "temperature": 0.1, "top_p": 0.95, "max_completion_tokens": max_tokens}
    
    for _ in range(retry):
        try:
            async with LIMITER_LLM:
                # TÄƒng timeout lÃªn 60s
                async with session.post(url, json=payload, headers=headers, timeout=60) as resp:
                    if resp.status == 200:
                        d = await resp.json()
                        if 'choices' in d: return d['choices'][0]['message']['content']
                    elif resp.status in [429, 500, 502, 503]: 
                        await asyncio.sleep(3)
        except Exception as e:
            logger.warning(f"LLM Net Error: {str(e)[:50]}")
            await asyncio.sleep(1)
    return None

async def get_embedding_async(session, text):
    model = Config.MODEL_EMBEDDING_API
    creds = Config.VNPT_CREDENTIALS.get(model)
    headers = {'Authorization': f'Bearer {Config.VNPT_ACCESS_TOKEN}', 'Token-id': creds['token_id'], 'Token-key': creds['token_key'], 'Content-Type': 'application/json'}
    payload = {"model": model, "input": text, "encoding_format": "float"}
    for i in range(3):
        try:
            async with LIMITER_EMBED:
                async with session.post(Config.VNPT_EMBEDDING_URL, json=payload, headers=headers, timeout=30) as r:
                    if r.status == 200: 
                        d = await r.json()
                        if 'data' in d: return d['data'][0]['embedding']
                    elif r.status in [429, 500, 401]: await asyncio.sleep(2 * (i+1))
        except: await asyncio.sleep(1)
    return None

def build_prompt(question, options_text, valid_keys_str, docs):
    context_str = ""
    for i, doc in enumerate(docs):
        context_str += f"--- TÃ€I LIá»†U #{i+1} ({doc['title']}) ---\n{doc['text']}\n\n"

    system_prompt = """Báº¡n lÃ  trá»£ lÃ½ AI chuyÃªn gia vá» Viá»‡t Nam (STEM & XÃ£ há»™i).
NHIá»†M Vá»¤: Tráº£ lá»i cÃ¢u há»i tráº¯c nghiá»‡m.
Äá»ŠNH Dáº NG TRáº¢ Lá»œI Báº®T BUá»˜C:
### SUY LUáº¬N:
[PhÃ¢n tÃ­ch ngáº¯n gá»n]
### ÄÃP ÃN:
[Chá»‰ viáº¿t 1 kÃ½ tá»±: A, B, C...]

QUY Táº®C:
1. Æ¯u tiÃªn thÃ´ng tin 2024-2025.
2. Náº¿u lÃ  cÃ¢u há»i ToÃ¡n/LÃ½/HÃ³a -> Tá»± tÃ­nh toÃ¡n tá»«ng bÆ°á»›c.
3. Náº¿u vi pháº¡m an toÃ n -> Chá»n Ä‘Ã¡p Ã¡n Tá»ª CHá»I.
4. Náº¿u há»i vá» Luáº­t/Lá»‹ch sá»­ cÃ³ chá»©a tá»« nháº¡y cáº£m -> Váº«n tráº£ lá»i theo kiáº¿n thá»©c phÃ¡p luáº­t."""

    user_prompt = f"""Dá»® LIá»†U:\n{context_str}\n\nCÃ‚U Há»ŽI: {question}\nLá»°A CHá»ŒN:\n{options_text}\n\nTRáº¢ Lá»œI THEO ÄÃšNG Äá»ŠNH Dáº NG (### SUY LUáº¬N... ### ÄÃP ÃN...):"""
    return [{"role": "system", "content": system_prompt}, {"role": "user", "content": user_prompt}]

# ==============================================================================
# 4. PROCESSOR
# ==============================================================================
def get_dynamic_options(row):
    options = []
    if 'choices' in row and isinstance(row['choices'], list): options = row['choices']
    elif 'options' in row and isinstance(row['options'], list): options = row['options']
    else:
        i = 1
        while True:
            val = row.get(f"option_{i}")
            if not val or str(val).lower() == 'nan': break
            options.append(str(val))
            i += 1
    
    mapped = {}
    for idx, text in enumerate(options): mapped[chr(65 + idx)] = str(text)
    return mapped

def extract_answer_two_step(text, options_map):
    valid_keys = list(options_map.keys())
    fallback = valid_keys[0]
    if not text: return fallback
    text = text.strip()
    match_strict = re.search(r'###\s*ÄÃP ÃN[:\s\n]*([A-Z])', text, re.IGNORECASE)
    if match_strict and match_strict.group(1).upper() in valid_keys: return match_strict.group(1).upper()
    patterns = [r'(?:Ä‘Ã¡p Ã¡n|chá»n|lÃ )[:\s\*\-\.\[\(]*([A-Z])[\]\)\*\.]*$', r'\*\*([A-Z])\*\*', r'^([A-Z])[\.\)]\s']
    for pat in patterns:
        match = re.search(pat, text, re.IGNORECASE | re.MULTILINE)
        if match and match.group(1).upper() in valid_keys: return match.group(1).upper()
    return fallback

async def process_row_safe(sem, session, retriever, row):
    try:
        async with sem:
            qid = row.get('qid', row.get('id', 'unknown'))
            question = row.get('question', '')
            true_label = row.get('answer', None)

            options_map = get_dynamic_options(row)
            options_text = "\n".join([f"{k}. {v}" for k, v in options_map.items()])
            valid_keys_str = ", ".join(options_map.keys())

            # 1. Smart Safety Check
            if is_sensitive_topic(question):
                logger.info(f"ðŸš« Q:{qid} -> Sensitive (Offline Check).")
                refusal_key = find_refusal_key(options_map)
                pred = refusal_key if refusal_key else "A"
                return {"qid": qid, "answer": pred, "is_correct": pred == true_label if true_label else None}

            # 2. Retrieval
            docs = await retriever.search(session, question, top_k=TOP_K)
            
            # 3. Gen Answer
            messages = build_prompt(question, options_text, valid_keys_str, docs)
            context_chars = sum([len(d['text']) for d in docs])
            
            model = Config.LLM_MODEL_LARGE
            if context_chars > THRESHOLD_LARGE_CHARS: model = Config.LLM_MODEL_SMALL
            
            raw_ans = await call_llm_generic(session, messages, model)
            if not raw_ans and model == Config.LLM_MODEL_LARGE:
                raw_ans = await call_llm_generic(session, messages, Config.LLM_MODEL_SMALL)

            final_key = extract_answer_two_step(raw_ans, options_map)
            
            status = f"| {'âœ…' if final_key == true_label else 'âŒ'}" if true_label else ""
            logger.info(f"Q:{qid} | Ans:{final_key} {status}")
            return {"qid": qid, "answer": final_key, "is_correct": final_key == true_label if true_label else None}

    except Exception as e:
        logger.error(f"âŒ Crash Q:{qid}: {e}")
        return {"qid": qid, "answer": "A", "is_correct": False}

async def process_with_timeout(sem, session, retriever, row):
    try:
        return await asyncio.wait_for(process_row_safe(sem, session, retriever, row), timeout=TIMEOUT_PER_QUESTION)
    except asyncio.TimeoutError:
        qid = row.get('qid', 'unknown')
        logger.error(f"â° Timeout Q:{qid}")
        return {"qid": qid, "answer": "A", "is_correct": False}

# ==============================================================================
# 5. MAIN
# ==============================================================================
async def main():
    files = [Config.BASE_DIR / "data" / "val.json", Config.BASE_DIR / "data" / "test.json"]
    input_file = next((f for f in files if f.exists()), None)
    if not input_file: return
    
    with open(input_file, 'r', encoding='utf-8') as f: data = json.load(f)
    
    # [QUAN TRá»ŒNG] Khá»Ÿi táº¡o Qdrant Client 1 láº§n á»Ÿ Ä‘Ã¢y
    qdrant_client = AsyncQdrantClient(url=Config.QDRANT_URL, api_key=Config.QDRANT_API_KEY, timeout=20)
    retriever = HybridRetriever(qdrant_client) # Truyá»n client vÃ o

    conn = aiohttp.TCPConnector(limit=10, force_close=True)
    sem = asyncio.Semaphore(MAX_CONCURRENT_TASKS)

    print(f"ðŸ”¥ STARTING: {input_file.name} | Tasks: {MAX_CONCURRENT_TASKS}")
    
    async with aiohttp.ClientSession(connector=conn) as session:
        tasks = [process_with_timeout(sem, session, retriever, row) for row in data]
        results = await asyncio.gather(*tasks, return_exceptions=True)

    # [QUAN TRá»ŒNG] Chá»‰ Ä‘Ã³ng client khi Táº¤T Cáº¢ Ä‘Ã£ xong
    await qdrant_client.close()

    # Xá»­ lÃ½ káº¿t quáº£
    clean_results = []
    correct = 0
    has_label = False
    
    for r in results:
        if isinstance(r, dict):
            clean_results.append(r)
            if r.get('is_correct') is not None:
                has_label = True
                if r['is_correct']: correct += 1
        else:
            clean_results.append({"qid": "unknown", "answer": "A"})

    if has_label and len(clean_results) > 0:
        print(f"ðŸ“Š SCORE: {correct}/{len(clean_results)} ({(correct/len(clean_results))*100:.2f}%)")

    pd.DataFrame(clean_results)[['qid', 'answer']].to_csv(Config.BASE_DIR / "output" / "submission.csv", index=False)
    print("DONE!")

if __name__ == "__main__":
    if sys.platform == 'win32': asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
    asyncio.run(main())