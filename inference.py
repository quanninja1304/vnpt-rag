import asyncio
import aiohttp
import pandas as pd
import json
import re
import pickle
import sys
import os
import time
import logging
import random
from pathlib import Path
from aiolimiter import AsyncLimiter
from qdrant_client import AsyncQdrantClient
import uuid
from underthesea import word_tokenize
from config import Config
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Set, Optional, Tuple
from collections import defaultdict


# ==============================================================================
# 0. C·∫§U H√åNH CHI·∫æN THU·∫¨T (Tactical Config)
# ==============================================================================
Config.LOGS_DIR.mkdir(parents=True, exist_ok=True)
Config.OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

# File l∆∞u k·∫øt qu·∫£ (D√πng ƒë·ªÉ Resume)
OUTPUT_FILE = Config.BASE_DIR / "output" / "submission.csv"
DEBUG_LOG_FILE = Config.LOGS_DIR / "debug_trace.txt"

# C·∫•u h√¨nh ch·∫°y an to√†n tuy·ªát ƒë·ªëi
MAX_CONCURRENT_TASKS = 1      # Ch·∫°y t·ª´ng c√¢u m·ªôt (Ch·∫≠m nh∆∞ng ch·∫Øc 100%)
TIMEOUT_PER_QUESTION = 600 # 10 ph√∫t

# Rate Limit (T·ªëc ƒë·ªô)
LIMITER_LARGE = AsyncLimiter(1, 95)   # 40 req/gi·ªù
LIMITER_SMALL = AsyncLimiter(1, 65)   # 60 req/gi·ªù
LIMITER_EMBED = AsyncLimiter(300, 60)  # 300 req/ph√∫t

# Ng√¢n s√°ch (Quota) - ƒê·ªÉ theo d√µi
QUOTA_LARGE = 500
QUOTA_SMALL = 1000

# Constants
THRESHOLD_SMALL_CONTEXT = 15000 
TOP_K = 18
ALPHA_VECTOR = 0.5
BM25_FILE = Config.OUTPUT_DIR / "bm25_index.pkl"

# Logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)s | %(message)s',
    handlers=[
        logging.FileHandler(Config.LOGS_DIR / 'inference_resume.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger("VNPT_BOT")

# ==============================================================================
# 1. C√ÅC H√ÄM X·ª¨ L√ù (UTILS)
# ==============================================================================

def extract_balanced_json(text):
    """
    T√¨m JSON object ƒë·∫ßu ti√™n v·ªõi c·∫∑p {} c√¢n b·∫±ng
    
    V√ç D·ª§ X·ª¨ L√ù ƒê∆Ø·ª¢C:
    - 'Here is the answer: {"x": {"y": "z"}} hope this helps'
    - '{"a": "b", "c": "$x^2$"}' (ch·ª©a k√Ω t·ª± ƒë·∫∑c bi·ªát)
    - 'Sure! {"nested": {"key": "value"}} Done'
    """
    
    # T√¨m v·ªã tr√≠ { ƒë·∫ßu ti√™n
    start = text.find('{')
    if start == -1:
        return None
    
    # ƒê·∫øm c·∫∑p ngo·∫∑c ƒë·ªÉ t√¨m } ƒë√≥ng
    depth = 0
    in_string = False
    escape = False
    
    for i in range(start, len(text)):
        char = text[i]
        
        # X·ª≠ l√Ω escape trong string
        if escape:
            escape = False
            continue
        
        if char == '\\':
            escape = True
            continue
        
        # X·ª≠ l√Ω string (b·ªè qua {} trong "...")
        if char == '"':
            in_string = not in_string
            continue
        
        if in_string:
            continue
        
        # ƒê·∫øm ngo·∫∑c
        if char == '{':
            depth += 1
        elif char == '}':
            depth -= 1
            
            # T√¨m th·∫•y c·∫∑p {} ho√†n ch·ªânh
            if depth == 0:
                return text[start:i+1]
    
    return None

def parse_json_strict(raw_response):
    """
    Parse JSON ROBUST - X·ª≠ l√Ω ƒë∆∞·ª£c nhi·ªÅu format kh√°c nhau
    
    CHI·∫æN L∆Ø·ª¢C M·ªöI:
    1. Th·ª≠ parse tr·ª±c ti·∫øp b·∫±ng json.loads() (nhanh nh·∫•t)
    2. Lo·∫°i b·ªè markdown fence
    3. T√¨m JSON b·∫±ng balanced bracket matching (x·ª≠ l√Ω nested {})
    4. Fallback: Extract t·ª´ kh√≥a b·∫±ng regex
    """
    
    if not raw_response:
        return None
    
    cleaned = raw_response.strip()
    
    # ========================================
    # B∆Ø·ªöC 1: TH·ª¨ PARSE TR·ª∞C TI·∫æP (Fast Path)
    # ========================================
    try:
        data = json.loads(cleaned)
        if isinstance(data, dict) and "safety" in data and "domain" in data:
            return data
    except:
        pass
    
    # ========================================
    # B∆Ø·ªöC 2: LO·∫†I B·ªé MARKDOWN FENCE
    # ========================================
    if "```" in cleaned:
        # Match ```json ... ``` ho·∫∑c ``` ... ```
        fence_match = re.search(r"```(?:json)?\s*(\{.*?\})\s*```", cleaned, re.DOTALL)
        if fence_match:
            cleaned = fence_match.group(1).strip()
            try:
                data = json.loads(cleaned)
                if isinstance(data, dict) and "safety" in data and "domain" in data:
                    return data
            except:
                pass
    
    # ========================================
    # B∆Ø·ªöC 3: BALANCED BRACKET MATCHING
    # X·ª≠ l√Ω ƒë∆∞·ª£c nested JSON nh∆∞: {"x": {"y": "z"}}
    # ========================================
    json_str = extract_balanced_json(cleaned)
    
    if json_str:
        try:
            data = json.loads(json_str)
            if isinstance(data, dict) and "safety" in data and "domain" in data:
                return data
        except:
            pass
    
    # ========================================
    # B∆Ø·ªöC 4: FALLBACK - EXTRACT T·ª™ KH√ìA
    # N·∫øu model tr·∫£ v·ªÅ d·∫°ng t·ª± do, v√≠ d·ª•:
    # "I think it's UNSAFE and domain is LEGAL"
    # ========================================
    safety_match = re.search(r'(?:safety|an to√†n)[":\s]*(SAFE|UNSAFE)', cleaned, re.IGNORECASE)
    domain_match = re.search(r'(?:domain|lƒ©nh v·ª±c)[":\s]*(STEM|LEGAL|SOCIAL)', cleaned, re.IGNORECASE)
    
    if safety_match and domain_match:
        return {
            "safety": safety_match.group(1).upper(),
            "domain": domain_match.group(1).upper()
        }
    
    # ========================================
    # TH·∫§T B·∫†I HO√ÄN TO√ÄN
    # ========================================
    logger.warning(f"Failed to parse JSON from response: {cleaned[:200]}...")
    return None

def is_all_above_option(text):
    """Ki·ªÉm tra xem ƒë√°p √°n c√≥ ph·∫£i l√† 'T·∫•t c·∫£ c√°c √Ω tr√™n' hay kh√¥ng"""
    text_lower = str(text).lower()
    patterns = [
        r"t·∫•t c·∫£.*(?:ƒë√°p √°n|√Ω|l·ª±a ch·ªçn)",  # T·∫•t c·∫£ c√°c ƒë√°p √°n tr√™n
        r"c·∫£.*(?:ƒë·ªÅu|l√†).*ƒë√∫ng",           # C·∫£ 3 √Ω ƒë·ªÅu ƒë√∫ng
        r"c√°c √Ω tr√™n ƒë·ªÅu",
        r"ph∆∞∆°ng √°n.*c·∫£"                   # C·∫£ A v√† B
    ]
    return any(re.search(p, text_lower) for p in patterns)

def find_true_refusal_key(options_map):
    """
    T√¨m ƒë√°p √°n t·ª´ ch·ªëi - Phi√™n b·∫£n t·ªëi ∆∞u
    Tr·∫£ v·ªÅ: (Key, Type) v·ªõi Type = "SAFETY" | "NO_INFO" | None
    """
    
    # NH√ìM 1: SAFETY REFUSAL
    safety_patterns = [
        r"^(?:t√¥i|h·ªá th·ªëng)\s*kh√¥ng\s*(?:th·ªÉ|ƒë∆∞·ª£c|h·ªó tr·ª£)\s*(?:tr·∫£ l·ªùi|cung c·∫•p)",
        r"vi ph·∫°m\s+(?:ph√°p lu·∫≠t|ch√≠nh s√°ch)",
        r"kh√¥ng\s+(?:th·ªÉ|h·ªó tr·ª£).*(?:l√†m gi·∫£|tr·ªën thu·∫ø|gian l·∫≠n)"
    ]
    
    safety_exclusions = [
        "ƒë∆∞·ª£c xem l√†", "b·ªã coi l√†", "c·∫•u th√†nh t·ªôi"
    ]
    
    for label, text in options_map.items():
        text_lower = str(text).lower().strip()
        
        if any(ex in text_lower for ex in safety_exclusions):
            continue
        
        if any(re.search(p, text_lower) for p in safety_patterns):
            return label, "SAFETY"
    
    # NH√ìM 2: NO INFO REFUSAL
    no_info_patterns = [
        r"kh√¥ng\s+(?:c√≥|ƒë·ªß|t√¨m th·∫•y)\s+(?:th√¥ng tin|d·ªØ li·ªáu)",
        r"kh√¥ng\s+th·ªÉ\s+(?:x√°c ƒë·ªãnh|k·∫øt lu·∫≠n|t√≠nh to√°n)(?:\.|,|\s|$)",
        r"th√¥ng tin.*kh√¥ng\s+ƒë·ªß"
    ]
    
    no_info_exclusions = [
        "kh√¥ng th·ªÉ thay ƒë·ªïi", "kh√¥ng th·ªÉ t√°ch r·ªùi", 
        "kh√¥ng th·ªÉ thi·∫øu", "kh√¥ng th·ªÉ ph·ªß nh·∫≠n"
    ]
    
    for label, text in options_map.items():
        text_lower = str(text).lower().strip()
        
        if "vi ph·∫°m" in text_lower or "lu·∫≠t" in text_lower:
            continue
        
        if any(ex in text_lower for ex in no_info_exclusions):
            continue
        
        if any(re.search(p, text_lower) for p in no_info_patterns):
            return label, "NO_INFO"
    
    return None, None


async def unified_router_v3(session, question, options_map):
    """
    ROUTER ƒê√É ƒê∆Ø·ª¢C FIX - Kh·∫Øc ph·ª•c 5 v·∫•n ƒë·ªÅ:
    1. R√∫t g·ªçn prompt t·ª´ 800 t·ª´ ‚Üí 200 t·ª´
    2. ƒê∆°n gi·∫£n h√≥a logic ‚Üí 2 b∆∞·ªõc thay v√¨ 3
    3. Parse JSON ch·∫∑t ch·∫Ω h∆°n
    4. Log ƒë·∫ßy ƒë·ªß ƒë·ªÉ debug
    5. Timeout 20s + retry
    """
    
    q_lower = question.lower()
    
    # PRE-CALC
    refusal_key, refusal_type = find_true_refusal_key(options_map)
    options_text = "\n".join([f"{k}. {v}" for k, v in options_map.items()])
    
    # ========================================
    # PROMPT (200 t·ª´)
    # ========================================
    
    system_prompt = """Ph√¢n lo·∫°i c√¢u h·ªèi thi theo 2 ti√™u ch√≠:

1. SAFETY (An to√†n):
   UNSAFE: H∆∞·ªõng d·∫´n C√ÅCH L√ÄM h√†nh vi vi ph·∫°m:
   - Tr·ªën/tr√°nh/l√°ch lu·∫≠t, thanh tra, thu·∫ø
   - L√†m gi·∫£ tem, t√†i li·ªáu, ti·∫øp t·ª•c ho·∫°t ƒë·ªông khi b·ªã c·∫•m
   - Ph√° ho·∫°i, l·∫≠t ƒë·ªï, x√∫c ph·∫°m l√£nh ƒë·∫°o
   - Khi√™u d√¢m, b·∫°o l·ª±c, v≈© kh√≠
   
   SAFE: H·ªèi ki·∫øn th·ª©c (k·ªÉ c·∫£ chi·∫øn tranh, ch√≠nh tr·ªã, lu·∫≠t h√¨nh s·ª±, y h·ªçc)

2. DOMAIN (Lƒ©nh v·ª±c):
   STEM: To√°n, L√Ω, H√≥a (c√≥ c√¥ng th·ª©c)
   LEGAL: Lu·∫≠t ph√°p (ƒêi·ªÅu X, B·ªô lu·∫≠t...)
   SOCIAL: L·ªãch s·ª≠, ƒê·ªãa l√Ω, VƒÉn h·ªçc

OUTPUT ch·ªâ 1 d√≤ng JSON:
{"safety":"SAFE|UNSAFE","domain":"STEM|LEGAL|SOCIAL"}"""

    user_content = f"C√¢u h·ªèi: {question}\n\nƒê√°p √°n:\n{options_text}\n\nJSON:"
    
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_content}
    ]
    
    # ========================================
    # FIX 2: TH√äM TIMEOUT + RETRY
    # ========================================
    
    max_retries = 2
    for attempt in range(max_retries):
        try:
            raw_resp = await call_llm_generic(
                session, messages,
                Config.LLM_MODEL_SMALL,
                stats=None,
                max_tokens=300,
                timeout=45
            )
            
            if not raw_resp:
                logger.warning(f"Attempt {attempt+1}: Empty response")
                continue
            
            # ========================================
            # FIX 3: PARSE JSON CH·∫∂T CH·∫º H∆†N
            # ========================================
            
            result = parse_json_strict(raw_resp)
            
            if not result:
                logger.warning(f"Attempt {attempt+1}: Failed to parse JSON")
                logger.debug(f"Raw response: {raw_resp[:200]}...")
                continue
            
            # ========================================
            # FIX 4: X·ª¨ L√ù K·∫æT QU·∫¢
            # ========================================
            
            safety = result.get("safety", "SAFE").upper()
            domain = result.get("domain", "SOCIAL").upper()
            
            # SAFETY NET: C·ª©u c√°c c√¢u h·ªèi ch√≠nh tr·ªã h·ªçc thu·∫≠t
            if safety == "UNSAFE":
                political_whitelist = [
                    "h·ªì ch√≠ minh", "b√°c h·ªì", "ƒë·∫£ng", "c√°ch m·∫°ng",
                    "chi·∫øn tranh", "kh√°ng chi·∫øn", "l·ªãch s·ª≠"
                ]
                dirty_blacklist = [
                    "khi√™u d√¢m", "sex", "porn", "l·∫≠t ƒë·ªï", 
                    "kh·ªßng b·ªë", "xuy√™n t·∫°c", "b√¥i nh·ªç"
                ]
                
                has_political = any(w in q_lower for w in political_whitelist)
                has_dirty = any(w in q_lower for w in dirty_blacklist)
                
                if has_political and not has_dirty:
                    logger.info(f"‚úÖ SAFETY NET: Rescued political question")
                    safety = "SAFE"
            
            # INTENT OVERRIDE: B·∫Øt c√°c pattern nguy hi·ªÉm model b·ªè s√≥t
            if safety == "SAFE":
                bad_patterns = [
                    r"(?:c√°ch|ph∆∞∆°ng ph√°p).*(?:vi ph·∫°m|tr·ªën|tr√°nh|l√°ch)",
                    r"tr√°nh.*(?:cung c·∫•p|khai b√°o).*th√¥ng tin",
                    r"ti·∫øp t·ª•c.*ho·∫°t ƒë·ªông.*(?:b·ªã ƒë√¨nh ch·ªâ|b·ªã c·∫•m)"
                ]
                
                if any(re.search(p, q_lower) for p in bad_patterns):
                    logger.warning(f"‚ö†Ô∏è INTENT OVERRIDE: Blocked by pattern")
                    safety = "UNSAFE"
            
            # RETURN K·∫æT QU·∫¢
            if safety == "UNSAFE":
                return _create_blocked_result("AI-BLOCKED", options_map)
            
            # ========================================
            # FIX L·ªñI 2: X·ª¨ L√ù REFUSAL KEY CHO SAFE
            # ========================================
            
            # Quy·∫øt ƒë·ªãnh d√πng Large/Small
            is_stem = (domain == "STEM")
            use_large = (
                is_stem 
                or (domain == "LEGAL") 
                or len(question) > 500
            )
            
            # X·ª¨ L√ù REFUSAL KEY:
            # - N·∫øu l√† STEM v√† c√≥ ƒë√°p √°n NO_INFO -> Gi·ªØ l·∫°i ƒë·ªÉ fallback
            # - N·∫øu l√† SOCIAL/LEGAL -> B·ªè qua refusal (ƒë√≥ l√† b·∫´y)
            final_refusal_key = None
            final_refusal_type = None
            
            if refusal_key and refusal_type == "NO_INFO":
                # Ch·ªâ gi·ªØ NO_INFO cho c√¢u STEM (To√°n/L√Ω)
                if is_stem:
                    final_refusal_key = refusal_key
                    final_refusal_type = "NO_INFO"
                    logger.info(f"üìù Detected NO_INFO answer for STEM question: {refusal_key}")
                else:
                    # SOCIAL/LEGAL lu√¥n c√≥ ƒë√°p √°n ƒë√∫ng
                    logger.info(f"üé£ Ignored TRAP refusal for {domain} question")
            
            return {
                "is_unsafe": False,
                "is_stem": is_stem,
                "use_large": use_large,
                "tag": f"AI-{domain}-{'L' if use_large else 'S'}",
                "refusal_key": final_refusal_key,
                "refusal_type": final_refusal_type
            }
        
        except Exception as e:
            logger.warning(f"Attempt {attempt+1} failed: {e}")
            if attempt == max_retries - 1:
                logger.error(f"All {max_retries} attempts failed!")
    
    # ========================================
    # FALLBACK REGEX (KHI AI HO√ÄN TO√ÄN L·ªñI)
    # ========================================
    
    logger.info("‚ö†Ô∏è Using REGEX FALLBACK (AI failed after retries)")
    
    # Hard ban
    hard_ban = ["khi√™u d√¢m", "·∫•u d√¢m", "sex", "porn", "xxx", "c√° ƒë·ªô"]
    if any(w in q_lower for w in hard_ban):
        return _create_blocked_result("REGEX-DIRTY", options_map)
    
    # Intent patterns
    bad_intent = [
        r"(?:c√°ch|ph∆∞∆°ng ph√°p).*(?:vi ph·∫°m|tr·ªën|tr√°nh|l√°ch|l√†m gi·∫£)",
        r"tr√°nh.*(?:cung c·∫•p|khai b√°o).*(?:th√¥ng tin|h·ªì s∆°)",
        r"ti·∫øp t·ª•c.*ho·∫°t ƒë·ªông.*(?:b·ªã ƒë√¨nh ch·ªâ|b·ªã c·∫•m)"
    ]
    
    if any(re.search(p, q_lower) for p in bad_intent):
        return _create_blocked_result("REGEX-INTENT", options_map)
    
    # Check refusal type
    if refusal_type == "SAFETY":
        return _create_blocked_result("REGEX-ANS-SAFETY", options_map)
    
    # Default safe
    has_math = bool(re.search(r"\$|\\frac|\\int|\\sum", question))
    
    # FIX L·ªñI 2 (FALLBACK): Gi·ªØ refusal_key cho STEM + NO_INFO
    final_refusal_key = None
    final_refusal_type = None
    
    if has_math and refusal_key and refusal_type == "NO_INFO":
        final_refusal_key = refusal_key
        final_refusal_type = "NO_INFO"
        logger.info(f"üìù FALLBACK: Kept NO_INFO for math question")
    
    return {
        "is_unsafe": False,
        "is_stem": has_math,
        "use_large": True,
        "tag": "REGEX-FALLBACK",
        "refusal_key": final_refusal_key,
        "refusal_type": final_refusal_type
    }

def _create_blocked_result(reason, options_map):
    """T·∫°o k·∫øt qu·∫£ ch·∫∑n"""
    key, _ = find_true_refusal_key(options_map)
    
    if not key:
        # Fallback: T√¨m b·∫•t k·ª≥ ƒë√°p √°n n√†o c√≥ "kh√¥ng th·ªÉ"
        keywords = ["t√¥i kh√¥ng th·ªÉ", "kh√¥ng th·ªÉ cung c·∫•p", "kh√¥ng th·ªÉ chia s·∫ª"]
        for k, v in options_map.items():
            if any(kw in str(v).lower() for kw in keywords):
                key = k
                break
    
    final_key = key if key else "A"
    
    return {
        "is_unsafe": True,
        "is_stem": False,
        "use_large": False,
        "tag": f"BLOCKED-{reason}",
        "refusal_key": final_key,
        "refusal_type": "SAFETY"
    }

def find_no_info_key(options_map):
    """
    T√¨m ƒë√°p √°n mang t√≠nh LOGIC/KHOA H·ªåC (Kh√¥ng x√°c ƒë·ªãnh ƒë∆∞·ª£c).
    (Phi√™n b·∫£n n√¢ng c·∫•p: B·∫Øt ƒëa d·∫°ng c·∫•u tr√∫c c√¢u)
    """
    
    # Danh s√°ch Pattern (Chia nh√≥m ƒë·ªÉ d·ªÖ qu·∫£n l√Ω)
    no_info_patterns = [
        # NH√ìM 1: TR·ª∞C TI·∫æP "KH√îNG ƒê·ª¶..."
        # B·∫Øt: "Kh√¥ng c√≥ th√¥ng tin", "Kh√¥ng ƒë·ªß d·ªØ ki·ªán", "Thi·∫øu c∆° s·ªü", "Ch∆∞a ƒë·ªß b·∫±ng ch·ª©ng"
        r"(?:kh√¥ng|ch∆∞a) (?:c√≥|ƒë·ªß|t√¨m th·∫•y) (?:th√¥ng tin|d·ªØ li·ªáu|d·ªØ ki·ªán|c∆° s·ªü|cƒÉn c·ª©|b·∫±ng ch·ª©ng|gi·∫£ thi·∫øt)",
        
        # NH√ìM 2: ƒê·∫¢O NG·ªÆ "TH√îNG TIN... KH√îNG ƒê·ª¶"
        # B·∫Øt: "Th√¥ng tin cung c·∫•p kh√¥ng ƒë·ªß", "D·ªØ li·ªáu b√†i to√°n ch∆∞a ƒë·ªß"
        r"(?:th√¥ng tin|d·ªØ li·ªáu|d·ªØ ki·ªán|gi·∫£ thi·∫øt).* (?:kh√¥ng|ch∆∞a) (?:ƒë·ªß|r√µ r√†ng|ch√≠nh x√°c)",
        
        # NH√ìM 3: KH√îNG TH·ªÇ H√ÄNH ƒê·ªòNG (ƒê·ªòNG T·ª™ M·∫†NH)
        # B·∫Øt: "Kh√¥ng th·ªÉ x√°c ƒë·ªãnh", "Kh√¥ng th·ªÉ k·∫øt lu·∫≠n", "Kh√¥ng th·ªÉ t√≠nh", "Kh√¥ng th·ªÉ ƒë∆∞a ra"
        # Th√™m \b ƒë·ªÉ ranh gi·ªõi t·ª´ r√µ r√†ng
        r"kh√¥ng th·ªÉ (?:x√°c ƒë·ªãnh|k·∫øt lu·∫≠n|t√≠nh to√°n|tr·∫£ l·ªùi|kh·∫≥ng ƒë·ªãnh|ƒë∆∞a ra|so s√°nh)(?:\.|,| |$)",
        
        # NH√ìM 4: C·ª§M T·ª™ KINH ƒêI·ªÇN TRONG TR·∫ÆC NGHI·ªÜM
        # B·∫Øt: "T·ª´ th√¥ng tin ƒë√£ cho...", "D·ª±a v√†o d·ªØ li·ªáu tr√™n..." ƒëi k√®m ph·ªß ƒë·ªãnh
        r"(?:t·ª´|d·ª±a v√†o|v·ªõi|cƒÉn c·ª©).* (?:th√¥ng tin|d·ªØ li·ªáu|d·ªØ ki·ªán).* (?:kh√¥ng|ch∆∞a|kh√≥)",
        
        # NH√ìM 5: META (V·ªÅ c√¢u h·ªèi)
        r"c√¢u h·ªèi (?:kh√¥ng th·ªÉ|kh√¥ng c√≥) (?:tr·∫£ l·ªùi|ƒë√°p √°n)"
    ]
    
    # Danh s√°ch lo·∫°i tr·ª´ (Tr√°nh b·∫Øt nh·∫ßm ki·∫øn th·ª©c)
    # V√≠ d·ª•: "NƒÉng l·ª±c l√† ƒë·∫∑c ƒëi·ªÉm kh√¥ng th·ªÉ thay ƒë·ªïi" -> B·ªã lo·∫°i tr·ª´.
    exclusions = [
        "t√¥i kh√¥ng th·ªÉ", # Nh∆∞·ªùng cho Safety
        "kh√¥ng th·ªÉ thay ƒë·ªïi", "kh√¥ng th·ªÉ t√°ch r·ªùi", "kh√¥ng th·ªÉ thi·∫øu", 
        "kh√¥ng th·ªÉ ph·ªß nh·∫≠n", "kh√¥ng th·ªÉ tr√°nh kh·ªèi", "kh√¥ng th·ªÉ ƒë·∫£o ng∆∞·ª£c",
        "kh√¥ng th·ªÉ chia c·∫Øt", "kh√¥ng th·ªÉ nh·∫ßm l·∫´n"
    ]

    for label, text in options_map.items():
        text_lower = str(text).lower().strip()
        
        # 1. Check Exclusion (Lo·∫°i tr·ª´ tr∆∞·ªõc)
        if any(ex in text_lower for ex in exclusions):
            continue
            
        # 2. Check "Vi ph·∫°m/Lu·∫≠t" (ƒê·ªÉ ch·∫Øc ch·∫Øn kh√¥ng c∆∞·ªõp c·ªßa Safety)
        if "vi ph·∫°m" in text_lower or "lu·∫≠t" in text_lower or "ch√≠nh s√°ch" in text_lower:
            continue
        
        # 3. Check Patterns
        if any(re.search(p, text_lower) for p in no_info_patterns):
            return label

    return None

    
def write_debug_log(qid, question, route_tag, model_used, answer, true_label=None, note=""):
    """H√†m ghi log chi ti·∫øt v√†o file txt"""
    try:
        timestamp = datetime.now().strftime("%H:%M:%S")
        
        # Ki·ªÉm tra ƒë√∫ng sai n·∫øu c√≥ ƒë√°p √°n m·∫´u
        result_status = ""
        if true_label:
            result_status = "‚úÖ ƒê√öNG" if str(answer).strip() == str(true_label).strip() else f"‚ùå SAI (ƒê√∫ng l√† {true_label})"
        
        log_content = f"""
--------------------------------------------------------------------------------
[{timestamp}] QID: {qid}
‚ùì Question: {question}
üè∑Ô∏è Route: {route_tag} | ü§ñ Model: {model_used}
üìù Answer: {answer} {result_status}
‚ÑπÔ∏è Note: {note}
--------------------------------------------------------------------------------
"""
        # M·ªü file mode 'a' (append) ƒë·ªÉ ghi n·ªëi ti·∫øp
        with open(DEBUG_LOG_FILE, "a", encoding="utf-8") as f:
            f.write(log_content)
            
    except Exception as e:
        print(f"L·ªói ghi log: {e}")


async def unified_router_logic(session, question):
    """
    ROUTER T·ªîNG H·ª¢P V2 (Robust Parsing & Legal Awareness)
    """
    q_lower = question.lower()

    # --- B∆Ø·ªöC 1: HARD CHECK (Zero-Cost) ---
    # 1.1 An to√†n
    hard_ban = ["khi√™u d√¢m", "l√†m t√¨nh", "·∫•u d√¢m", "k√≠ch d·ª•c", "c√° ƒë·ªô", "l·∫≠t ƒë·ªï ch√≠nh quy·ªÅn", "sex", "xxx"]
    if any(w in q_lower for w in hard_ban):
        return {"is_unsafe": True, "is_stem": False, "use_large": False, "tag": "BLOCKED"}

    # 1.2 STEM (To√°n h·ªçc)
    has_math_regex = bool(re.search(r"\$|\\frac|\\int|\\sum|\^\{|sin\(|cos\(|tan\(", question))

    # 1.3 Lu·∫≠t ph√°p (Legal Keywords) - B·∫Øt bu·ªôc d√πng Large
    # ƒê√¢y l√† c√°c t·ª´ kh√≥a ƒë√≤i h·ªèi s·ª± ch√≠nh x√°c tuy·ªát ƒë·ªëi t·ª´ng c√¢u ch·ªØ
    legal_keywords = ["lu·∫≠t", "ngh·ªã ƒë·ªãnh", "th√¥ng t∆∞", "hi·∫øn ph√°p", "quy ƒë·ªãnh", "ƒëi·ªÅu kho·∫£n", "ph·∫°t t√π", "x·ª≠ ph·∫°t"]
    is_legal_hard = any(k in q_lower for k in legal_keywords)

    # --- B∆Ø·ªöC 2: G·ªåI MODEL SMALL ---
    system_prompt = """B·∫°n l√† b·ªô ph√¢n lo·∫°i c√¢u h·ªèi thi.
NHI·ªÜM V·ª§: Ph√¢n lo·∫°i theo 3 ti√™u ch√≠: [SAFETY] | [DOMAIN] | [DIFFICULTY]

1. SAFETY (An to√†n):
- UNSAFE: Vi ph·∫°m ƒë·∫°o ƒë·ª©c, ph√°p lu·∫≠t, khi√™u d√¢m, ph·∫£n ƒë·ªông.
- SAFE: C√°c c√¢u h·ªèi ki·∫øn th·ª©c (bao g·ªìm c·∫£ L·ªãch s·ª≠ chi·∫øn tranh, H√¨nh s·ª±, Sinh h·ªçc).

2. DOMAIN (Lƒ©nh v·ª±c):
- STEM: To√°n, L√Ω, H√≥a, Sinh, Kinh t·∫ø l∆∞·ª£ng. ƒê·∫∂C BI·ªÜT: Bao g·ªìm c·∫£ LU·∫¨T PH√ÅP/CH√çNH TR·ªä (C·∫ßn tr√≠ch d·∫´n ch√≠nh x√°c).
- SOCIAL: VƒÉn h·ªçc, L·ªãch s·ª≠, ƒê·ªãa l√Ω, ƒê·ªùi s·ªëng, Tra c·ª©u th√¥ng tin th∆∞·ªùng.

3. DIFFICULTY (ƒê·ªô kh√≥):
- COMPLEX: C·∫ßn t√≠nh to√°n, suy lu·∫≠n nhi·ªÅu b∆∞·ªõc, so s√°nh c√°c ƒëi·ªÅu lu·∫≠t.
- SIMPLE: Ch·ªâ c·∫ßn tra c·ª©u ƒë·ªãnh nghƒ©a, ng√†y th√°ng, s·ª± ki·ªán ƒë∆°n gi·∫£n.

V√ç D·ª§ M·∫™U:
- Q: "T√≠nh t√≠ch ph√¢n c·ªßa x^2" -> SAFE | STEM | COMPLEX
- Q: "Theo ƒêi·ªÅu 12 B·ªô lu·∫≠t H√¨nh s·ª±, t·ªôi ph·∫°m l√† g√¨?" -> SAFE | STEM | COMPLEX
- Q: "Th·ªß ƒë√¥ c·ªßa Ph√°p l√† g√¨?" -> SAFE | SOCIAL | SIMPLE
- Q: "C√°ch ch·∫ø t·∫°o ch·∫•t n·ªï?" -> UNSAFE | STEM | COMPLEX

OUTPUT (Ch·ªâ vi·∫øt c√°c t·ª´ kh√≥a):"""

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": f"C√¢u h·ªèi: {question}"}
    ]

    try:
        # G·ªçi API (Stats=None ƒë·ªÉ kh√¥ng t√≠nh quota)
        raw_resp = await call_llm_generic(session, messages, Config.LLM_MODEL_SMALL, stats=None, max_tokens=20)
        
        # --- ROBUST PARSING (D√πng Regex thay v√¨ Split) ---
        if raw_resp:
            resp_upper = raw_resp.upper()

            # 1. Check Safety
            is_unsafe = "UNSAFE" in resp_upper
            
            # 2. Check Domain (STEM/LEGAL vs SOCIAL)
            # N·∫øu model n√≥i STEM ho·∫∑c c√¢u h·ªèi ch·ª©a k√Ω hi·ªáu to√°n/t·ª´ kh√≥a lu·∫≠t -> STEM
            is_stem_model = "STEM" in resp_upper
            final_stem = is_stem_model or has_math_regex or is_legal_hard

            # 3. Check Difficulty
            is_complex_model = "COMPLEX" in resp_upper
            
            # 4. Logic quy·∫øt ƒë·ªãnh Model Large
            # D√πng Large khi: Model b·∫£o kh√≥ HO·∫∂C L√† to√°n/lu·∫≠t (b·∫Øt bu·ªôc ch√≠nh x√°c)
            use_large = is_complex_model or final_stem

            return {
                "is_unsafe": is_unsafe,
                "is_stem": final_stem,
                "use_large": use_large,
                "tag": f"ROUTED-{'STEM' if final_stem else 'SOCIAL'}-{'LARGE' if use_large else 'SMALL'}"
            }

    except Exception as e:
        logger.warning(f"Router Error: {e}")

    # --- B∆Ø·ªöC 3: FALLBACK AN TO√ÄN ---
    # N·∫øu API l·ªói ho·∫∑c kh√¥ng b·∫Øt ƒë∆∞·ª£c g√¨ -> M·∫∑c ƒë·ªãnh d√πng Large cho an to√†n (Tr·ª´ khi ch·∫Øc ch·∫Øn l√† Safe Social)
    return {
        "is_unsafe": False,
        "is_stem": has_math_regex or is_legal_hard, 
        "use_large": True, # Fallback v·ªÅ Large ƒë·ªÉ ƒë·∫£m b·∫£o tr√≠ th√¥ng minh
        "tag": "FALLBACK-LARGE"
    }

def unified_router(question):
    """
    B·ªô ƒë·ªãnh tuy·∫øn t·ªïng h·ª£p (Local - 0 API Call).
    Ph√¢n lo·∫°i c√¢u h·ªèi th√†nh 4 nh√≥m ƒë·ªÉ ch·ªçn chi·∫øn thu·∫≠t ph√π h·ª£p.
    
    OUTPUT:
    - 'BLOCKED': C√¢u h·ªèi nh·∫°y c·∫£m/c·∫•m -> Tr·∫£ l·ªùi t·ª´ ch·ªëi ngay.
    - 'STEM': To√°n, L√Ω, H√≥a -> C·∫ßn Large Model + CoT Prompt.
    - 'COMPLEX': Logic, suy lu·∫≠n, ƒë√°nh ƒë·ªë -> C·∫ßn Large Model + CoT Prompt.
    - 'SIMPLE': Tra c·ª©u VƒÉn, S·ª≠, ƒê·ªãa -> D√πng Small Model (ho·∫∑c Large n·∫øu th√≠ch) + Simple Prompt.
    """
    q_lower = question.lower()

    # ==============================================================================
    # 1. SAFETY CHECK (∆Øu ti√™n cao nh·∫•t - Ch·∫∑n tr∆∞·ªõc khi l√†m b·∫•t c·ª© vi·ªác g√¨)
    # ==============================================================================
    hard_ban = [
        "khi√™u d√¢m", "l√†m t√¨nh", "·∫•u d√¢m", "k√≠ch d·ª•c", "c√° ƒë·ªô", "c·ªù b·∫°c",
        "l·∫≠t ƒë·ªï", "ph·∫£n ƒë·ªông", "kh·ªßng b·ªë", "gi·∫øt ng∆∞·ªùi", "t·ª± s√°t", "t·ª± t·ª≠",
        "ch·∫ø bom", "ch·∫ø s√∫ng", "ma t√∫y ƒë√°", "thu·ªëc l·∫Øc", "sex", "xxx"
    ]
    if any(w in q_lower for w in hard_ban): return 'BLOCKED'

    # Soft ban: Ch·ªâ ch·∫∑n n·∫øu kh√¥ng c√≥ t·ª´ kh√≥a h·ªçc thu·∫≠t ƒëi k√®m
    soft_ban = ["ma t√∫y", "v≈© kh√≠", "b·∫°o l·ª±c", "ch·∫øt", "bi·ªÉu t√¨nh", "ch√≠nh tr·ªã"]
    academic_whitelist = [
        "lu·∫≠t", "ngh·ªã ƒë·ªãnh", "quy ƒë·ªãnh", "l·ªãch s·ª≠", "t√¥n gi√°o", "kinh th√°nh", 
        "torah", "qur'an", "vƒÉn b·∫£n", "c·ªï ƒë·∫°i", "h√¨nh ph·∫°t", "t·ªôi danh",
        "theo ƒëo·∫°n vƒÉn", "d·ª±a v√†o th√¥ng tin", "theo ng·ªØ c·∫£nh"
    ]
    
    has_bad = any(w in q_lower for w in soft_ban)
    has_academic = any(w in q_lower for w in academic_whitelist)
    
    if has_bad and not has_academic: return 'BLOCKED'

    # ==============================================================================
    # 2. STEM CHECK (To√°n/L√Ω/H√≥a - C·∫ßn t√≠nh to√°n ch√≠nh x√°c)
    # ==============================================================================
    # Regex b·∫Øt k√Ω hi·ªáu To√°n h·ªçc ƒë·∫∑c th√π
    if re.search(r"\$|\\frac|\\int|\\sum|\^\{|sin\(|cos\(|tan\(|log\(|lim_|\\sqrt", question):
        return 'STEM'
    
    # T·ª´ kh√≥a ƒë·ªãnh l∆∞·ª£ng/ƒë∆°n v·ªã ƒëo l∆∞·ªùng
    stem_keywords = [
        # --- To√°n h·ªçc & V·∫≠t l√Ω ---
        "gi√° tr·ªã c·ªßa", "k·∫øt qu·∫£ ph√©p t√≠nh", "nghi·ªám c·ªßa", "x√°c su·∫•t", "t·ªça ƒë·ªô", 
        "ƒë·∫°o h√†m", "t√≠ch ph√¢n", "trung b√¨nh c·ªông", "ph∆∞∆°ng sai", "ƒë·ªô l·ªách chu·∫©n",
        "v·∫≠n t·ªëc", "gia t·ªëc", "c∆∞·ªùng ƒë·ªô", "ƒëi·ªán tr·ªü", "n·ªìng ƒë·ªô", "s·ªë mol",
        "di·ªán t√≠ch", "th·ªÉ t√≠ch", "chu vi", "b√°n k√≠nh",
        
        # --- T√†i ch√≠nh & Kinh t·∫ø l∆∞·ª£ng ---
        "k·ª≥ v·ªçng",          # B·∫Øt "gi√° tr·ªã k·ª≥ v·ªçng", "l·ª£i nhu·∫≠n k·ª≥ v·ªçng"
        "ƒë·∫ßu t∆∞",           # B√†i to√°n ROI
        "l·ª£i nhu·∫≠n",        # T√≠nh l√£i
        "m·ª©c l·ªó", "thua l·ªó", # T√≠nh l·ªó
        "l√£i su·∫•t", "v·ªën",  # B√†i to√°n l√£i k√©p/ƒë∆°n
        "tƒÉng tr∆∞·ªüng",      # B√†i to√°n % tƒÉng tr∆∞·ªüng
        "t·ªâ l·ªá", "ph·∫ßn trƒÉm"
    ]
    if any(k in q_lower for k in stem_keywords):
        return 'STEM'

    # X·ª≠ l√Ω t·ª´ "T√≠nh": Ph√¢n bi·ªát "T√≠nh to√°n" (STEM) vs "T√≠nh c√°ch" (SIMPLE)
    if "t√≠nh" in q_lower:
        social_context = ["t√≠nh c√°ch", "t√≠nh ch·∫•t", "t√≠nh nƒÉng", "t√≠nh nh√¢n vƒÉn", "m√°y t√≠nh", "thu·ªôc t√≠nh"]
        if not any(sc in q_lower for sc in social_context):
            return 'STEM' # C√≥ ch·ªØ "t√≠nh" m√† kh√¥ng ph·∫£i "t√≠nh c√°ch" -> Kh·∫£ nƒÉng cao l√† To√°n

    # ==============================================================================
    # 3. COMPLEX/LOGIC CHECK (Suy lu·∫≠n, ƒê·ªë m·∫πo, Logic)
    # ==============================================================================
    logic_keywords = [
        "gi·∫£ s·ª≠", "n·∫øu... th√¨", "suy ra", "logic", "ng∆∞·ªùi ti·∫øp theo", "quy lu·∫≠t", 
        "m√¢u thu·∫´n", "t∆∞∆°ng ph·∫£n", "√Ω n√†o sau ƒë√¢y ƒë√∫ng", "nguy√™n nh√¢n ch√≠nh",
        "d·ª±a v√†o th√¥ng tin", "theo ƒëo·∫°n vƒÉn", "√Ω ch√≠nh", "k·∫øt lu·∫≠n n√†o"
    ]
    if any(k in q_lower for k in logic_keywords):
        return 'COMPLEX'

    # ==============================================================================
    # 4. SIMPLE CHECK (M·∫∑c ƒë·ªãnh - Tra c·ª©u ki·∫øn th·ª©c)
    # ==============================================================================
    return 'SIMPLE'


async def smart_router_with_small(session, question):
    """
    D√πng Model Small ƒë·ªÉ ph√¢n lo·∫°i ƒë·ªô kh√≥ c√¢u h·ªèi.
    OUTPUT: True (Kh√≥/STEM/Lu·∫≠t suy lu·∫≠n -> D√πng Large) | False (Tra c·ª©u/VƒÉn/S·ª≠ -> D√πng Small)
    """
    # 1. L·ªöP L·ªåC 1: Regex To√°n h·ªçc/K√Ω hi·ªáu (Nhanh, kh√¥ng t·ªën API)
    # B·∫Øt c√°c c√¥ng th·ª©c LaTeX, k√Ω hi·ªáu to√°n, h√≥a h·ªçc ƒë·∫∑c th√π
    if re.search(r"\$|\\frac|\\int|\\sum|\^\{|sin\(|cos\(|tan\(|log\(|ln\(", question):
        return True

    # 2. L·ªöP L·ªåC 2: G·ªçi Model Small ph√¢n lo·∫°i ng·ªØ nghƒ©a
    system_prompt = """B·∫°n l√† b·ªô ph√¢n lo·∫°i c√¢u h·ªèi thi. 
NHI·ªÜM V·ª§: Ph√¢n lo·∫°i c√¢u h·ªèi v√†o 1 trong 2 nh√≥m:

1. NH√ìM PH·ª®C T·∫†P (Tr·∫£ l·ªùi: COMPLEX):
   - To√°n, L√Ω, H√≥a, Sinh, Kinh t·∫ø l∆∞·ª£ng (c·∫ßn t√≠nh to√°n).
   - T∆∞ duy Logic, ƒê·ªë m·∫πo, Suy lu·∫≠n nguy√™n nh√¢n - h·ªá qu·∫£ ph·ª©c t·∫°p.
   - C√¢u h·ªèi Ph·ªß ƒë·ªãnh xo·∫Øn n√£o ("Ngo·∫°i tr·ª´...", "Kh√¥ng ph·∫£i l√†...").

2. NH√ìM TRA C·ª®U (Tr·∫£ l·ªùi: SIMPLE):
   - L·ªãch s·ª≠, ƒê·ªãa l√Ω, VƒÉn h·ªçc, T√°c gi·∫£ - T√°c ph·∫©m.
   - Tr√≠ch xu·∫•t th√¥ng tin ƒë∆°n thu·∫ßn ("Theo ƒëo·∫°n vƒÉn...", "Chi ti·∫øt n√†o...").
   - ƒê·ªãnh nghƒ©a, Kh√°i ni·ªám, Ng√†y th√°ng nƒÉm.

OUTPUT: Ch·ªâ tr·∫£ l·ªùi duy nh·∫•t 1 t·ª´: COMPLEX ho·∫∑c SIMPLE."""

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": f"C√¢u h·ªèi: {question}"}
    ]

    try:
        # G·ªçi model small, max_tokens c·ª±c th·∫•p (ch·ªâ c·∫ßn 1 t·ª´)
        # stats=None ƒë·ªÉ kh√¥ng t√≠nh v√†o quota ch√≠nh (ho·∫∑c truy·ªÅn stats n·∫øu mu·ªën track)
        resp = await call_llm_generic(session, messages, Config.LLM_MODEL_SMALL, stats=None, max_tokens=10)
        
        if resp:
            label = resp.strip().upper()
            if "COMPLEX" in label: return True
            if "SIMPLE" in label: return False
                
    except Exception as e:
        logger.warning(f"Router Error: {e}")

    # 3. L·ªöP L·ªåC 3: Fallback an to√†n (N·∫øu API l·ªói)
    # Ch·ªâ b·∫Øt c√°c t·ª´ kh√≥a T√çNH TO√ÅN th·ª±c s·ª±, b·ªè qua c√°c t·ª´ tra c·ª©u
    # "t√≠nh" trong "t√≠nh c√°ch" -> False. "t√≠nh" trong "t√≠nh gi√° tr·ªã" -> True (do ng·ªØ c·∫£nh)
    # ·ªû ƒë√¢y d√πng list h·∫πp ƒë·ªÉ tr√°nh b·∫Øt nh·∫ßm.
    safe_keywords = [
        "t√≠nh gi√° tr·ªã", "c√¥ng th·ª©c", "l√£i su·∫•t", "kh·∫•u hao", "t·ªça ƒë·ªô", 
        "x√°c su·∫•t", "v·∫≠n t·ªëc", "gia t·ªëc", "bi·∫øn ƒë·ªïi", "t·ªâ l·ªá", "ph∆∞∆°ng tr√¨nh"
    ]
    return any(k in question.lower() for k in safe_keywords)


def get_current_date_str():
    return datetime.now().strftime("%d/%m/%Y")

async def rerank_with_small(session, question, initial_docs, top_n=8, stats=None):
    if not initial_docs: return []
    if len(initial_docs) <= top_n: return initial_docs

    # 1. Input
    docs_text = ""
    for i, doc in enumerate(initial_docs):
        clean_body = str(doc.get('text', '')).strip().replace("\n", " ")
        preview_text = " ".join(clean_body.split())[:1000] 
        docs_text += f"ID [{i}]: {preview_text}...\n\n"

    # 2. Prompt (Th√™m v√≠ d·ª• c·ª• th·ªÉ ƒë·ªÉ model d·ªÖ hi·ªÉu)
    system_prompt = """B·∫°n l√† chuy√™n gia l·ªçc th√¥ng tin RAG.
NHI·ªÜM V·ª§: Ch·ªçn ra t·ªëi ƒëa 8 t√†i li·ªáu li√™n quan nh·∫•t ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi.

TI√äU CH√ç KH·∫ÆT KHE:
1. ∆Øu ti√™n t√†i li·ªáu ch·ª©a ƒë√°p √°n tr·ª±c ti·∫øp ho·∫∑c t·ª´ kh√≥a ch√≠nh x√°c.
2. Lo·∫°i b·ªè t√†i li·ªáu r√°c ho·∫∑c kh√¥ng li√™n quan.
3. N·∫øu c√¢u h·ªèi y√™u c·∫ßu t√≠nh to√°n/s·ªë li·ªáu -> Ch·ªçn t√†i li·ªáu ch·ª©a con s·ªë.

OUTPUT: Ch·ªâ tr·∫£ v·ªÅ m·∫£ng s·ªë ID. V√≠ d·ª•: [0, 5, 2]"""

    user_prompt = f"""C√ÇU H·ªéI: "{question}"

DANH S√ÅCH T√ÄI LI·ªÜU:
{docs_text}

H√ÉY CH·ªåN ID T√ÄI LI·ªÜU LI√äN QUAN NH·∫§T (JSON Array):"""

    messages = [{"role": "system", "content": system_prompt}, {"role": "user", "content": user_prompt}]

    try:
        response = await call_llm_generic(session, messages, Config.LLM_MODEL_SMALL, stats, max_tokens=100)
        
        # [DEBUG LOG] Xem model tr·∫£ l·ªùi g√¨ khi b·ªã fail
        if not response or not any(c.isdigit() for c in response):
            logger.warning(f"‚ö†Ô∏è Rerank Empty Response: '{response}'")

        if response:
            found_indices = [int(s) for s in re.findall(r'\d+', response)]
            
            valid_docs = []
            seen = set()
            for idx in found_indices:
                if 0 <= idx < len(initial_docs) and idx not in seen:
                    valid_docs.append(initial_docs[idx])
                    seen.add(idx)
            
            # [FIX BACKFILL] Lu√¥n ƒë·∫£m b·∫£o ƒë·ªß top_n docs
            if len(valid_docs) < top_n:
                for i, doc in enumerate(initial_docs):
                    if i not in seen:
                        valid_docs.append(doc)
                        if len(valid_docs) >= top_n: break
            
            return valid_docs[:top_n]

    except Exception as e:
        logger.warning(f"Rerank Error: {e}")
    
    return initial_docs[:top_n]

async def route_question_type(session, question):
    """
    Ph√¢n lo·∫°i c√¢u h·ªèi: STEM hay KH√ÅC?
    Chi·∫øn thu·∫≠t: Regex (Math) -> Model Small
    """
    # 1. Check nhanh c√°c k√Ω hi·ªáu To√°n h·ªçc ƒë·∫∑c th√π (Ti·∫øt ki·ªám quota)
    # T√¨m d·∫•u $, c√°c l·ªánh latex c∆° b·∫£n
    if re.search(r"\$|\\frac|\\int|\\sum|\\sqrt|\^\{", question):
        return True # Ch·∫Øc ch·∫Øn l√† STEM

    # 2. G·ªçi Model Small ƒë·ªÉ ph√¢n lo·∫°i ng·ªØ nghƒ©a
    system_prompt = """
                    B·∫°n l√† b·ªô ph√¢n lo·∫°i c√¢u h·ªèi.
                    NHI·ªÜM V·ª§: X√°c ƒë·ªãnh c√¢u h·ªèi thu·ªôc nh√≥m T·ª∞ NHI√äN (To√°n, L√Ω, H√≥a, Sinh, Kinh t·∫ø ƒë·ªãnh l∆∞·ª£ng, K·ªπ thu·∫≠t) hay X√É H·ªòI (VƒÉn, S·ª≠, ƒê·ªãa, Lu·∫≠t, ƒê·ªùi s·ªëng).

                    OUTPUT:
                    - N·∫øu l√† T·ª± nhi√™n/T√≠nh to√°n -> Tr·∫£ l·ªùi: STEM
                    - N·∫øu l√† X√£ h·ªôi/Tra c·ª©u -> Tr·∫£ l·ªùi: SOCIAL
                    - Ch·ªâ tr·∫£ l·ªùi ƒë√∫ng 1 t·ª´.
                    """
    
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": f"C√¢u h·ªèi: {question}"}
    ]

    # G·ªçi Small, max_tokens=5 cho nhanh
    # L∆∞u √Ω: C·∫ßn truy·ªÅn stats gi·∫£ ho·∫∑c None n·∫øu h√†m call_llm_generic c·ªßa b·∫°n y√™u c·∫ßu
    # ·ªû ƒë√¢y gi·∫£ ƒë·ªãnh call_llm_generic kh√¥ng b·∫Øt bu·ªôc stats
    try:
        # G·ªçi model small v·ªõi timeout ng·∫Øn
        resp = await call_llm_generic(session, messages, Config.LLM_MODEL_SMALL, max_tokens=10)
        
        if resp and "STEM" in resp.upper():
            return True
        return False
    except:
        # Fallback n·∫øu g·ªçi AI l·ªói -> D√πng l·∫°i keyword c≈© cho an to√†n
        stem_keywords = [
        # 1. TO√ÅN H·ªåC & TH·ªêNG K√ä C∆† B·∫¢N
        "c√¥ng th·ª©c", "h√†m s·ªë", "ph∆∞∆°ng tr√¨nh", "b·∫•t ph∆∞∆°ng tr√¨nh", "nghi·ªám",
        "x√°c su·∫•t", "t·ªâ l·ªá", "ph·∫ßn trƒÉm", "trung b√¨nh", "b√¨nh qu√¢n",
        "t·ªça ƒë·ªô", "vect∆°", "ma tr·∫≠n", "ƒë·∫°o h√†m", "t√≠ch ph√¢n", "logarit",
        "di·ªán t√≠ch", "th·ªÉ t√≠ch", "chu vi", "b√°n k√≠nh", "ƒë∆∞·ªùng k√≠nh",
        "sin", "cos", "tan", "cot", "h√¨nh h·ªçc", "ƒë·ªì th·ªã",

        # 2. T√ÄI CH√çNH - K·∫æ TO√ÅN (Fix l·ªói test_0095)
        "l√£i su·∫•t", "v·ªën h√≥a", "c·ªï t·ª©c", "kh·∫•u hao", "t√†i s·∫£n", "ngu·ªìn v·ªën",
        "n·ª£ ph·∫£i tr·∫£", "v·ªën ch·ªß s·ªü h·ªØu", "doanh thu", "chi ph√≠", "l·ª£i nhu·∫≠n",
        "b·∫£ng c√¢n ƒë·ªëi", "b√°o c√°o t√†i ch√≠nh", "d√≤ng ti·ªÅn", "thu nh·∫≠p r√≤ng",
        "gi√° v·ªën", "h√†ng t·ªìn kho", "bi√™n l·ª£i nhu·∫≠n", "c·ªï phi·∫øu", "tr√°i phi·∫øu",
        "ti·ªÅn t·ªá", "t·ª∑ gi√°", "h·ªëi ƒëo√°i", "l·∫°m ph√°t", "gdp", "cpi",
        "usd", "vnd", "ƒë·ªìng", "tri·ªáu", "t·ª∑", "ngh√¨n", # ƒê∆°n v·ªã ti·ªÅn t·ªá

        # 3. V·∫¨T L√ù & K·ª∏ THU·∫¨T
        "v·∫≠n t·ªëc", "gia t·ªëc", "qu√£ng ƒë∆∞·ªùng", "th·ªùi gian", "l·ª±c", "c√¥ng su·∫•t",
        "nƒÉng l∆∞·ª£ng", "ƒë·ªông nƒÉng", "th·∫ø nƒÉng", "nhi·ªát l∆∞·ª£ng", "ƒëi·ªán √°p",
        "c∆∞·ªùng ƒë·ªô", "d√≤ng ƒëi·ªán", "ƒëi·ªán tr·ªü", "t·∫ßn s·ªë", "b∆∞·ªõc s√≥ng", "chu k·ª≥",
        "√°p su·∫•t", "tr·ªçng l∆∞·ª£ng", "kh·ªëi l∆∞·ª£ng ri√™ng", "ƒë·ªô l·ªõn", "bi√™n ƒë·ªô",
        "m/s", "km/h", "kwh", "hz", "v√¥n", "ampe", "joule",

        # 4. H√ìA H·ªåC & SINH H·ªåC (T√≠nh to√°n)
        "n·ªìng ƒë·ªô", "mol", "kh·ªëi l∆∞·ª£ng mol", "ph·∫£n ·ª©ng", "c√¢n b·∫±ng",
        "k·∫øt t·ªßa", "nguy√™n t·ª≠ kh·ªëi", "ph√¢n t·ª≠ kh·ªëi", "h√≥a tr·ªã", "ph",
        "dung d·ªãch", "ch·∫•t tan", "dung m√¥i", "ki·ªÅm", "axit",

        # 5. T·ª™ KH√ìA D·∫§U HI·ªÜU B√ÄI TO√ÅN (Logic)
        "gi·∫£ s·ª≠", "cho bi·∫øt", "bi·∫øt r·∫±ng", "k·∫øt qu·∫£ c·ªßa", "gi√° tr·ªã c·ªßa",
        "t√≠nh to√°n", "∆∞·ªõc t√≠nh", "d·ª± b√°o", "tƒÉng bao nhi√™u", "gi·∫£m bao nhi√™u"
        ]
        return any(k in question.lower() for k in stem_keywords)
    

def extract_answer_strict(text, options_map):
    """Tr√≠ch xu·∫•t ƒë√°p √°n t·ª´ output c·ªßa LLM m·ªôt c√°ch ch·∫∑t ch·∫Ω"""
    valid_keys = list(options_map.keys())
    if not text: return None
    text = text.strip()
    
    # C√°c m·∫´u regex ƒë·ªÉ b·∫Øt ƒë√°p √°n chu·∫©n
    patterns = [
        r'###\s*ƒê√ÅP √ÅN[:\s\n]*([A-Z])',  # Format chu·∫©n: ### ƒê√ÅP √ÅN: A
        r'ƒê√ÅP √ÅN[:\s]*([A-Z])',          # Format l·ªèng: ƒê√ÅP √ÅN: A
        r'CH·ªåN[:\s]*([A-Z])',            # Format: Ch·ªçn A
        r'K·∫æT LU·∫¨N[:\s]*([A-Z])',        # Format: K·∫øt lu·∫≠n A
        r'^([A-Z])\.$',                  # Ch·ªâ tr·∫£ v·ªÅ: A.
        r'^([A-Z])$'                     # Ch·ªâ tr·∫£ v·ªÅ: A
    ]
    
    # 1. ∆Øu ti√™n t√¨m theo pattern ƒë·ªãnh s·∫µn
    for p in patterns:
        match = re.search(p, text, re.IGNORECASE)
        if match and match.group(1).upper() in valid_keys: 
            return match.group(1).upper()
            
    # 2. Fallback: T√¨m k√Ω t·ª± in ƒë·∫≠m cu·ªëi c√πng (Markdown bold)
    # V√≠ d·ª•: "ƒê√°p √°n ƒë√∫ng l√† *A*"
    matches = re.findall(r'\*\*([A-Z])\*\*', text)
    if matches:
        last_match = matches[-1].upper()
        if last_match in valid_keys: 
            return last_match
    
    loose_patterns = [
        r'(?:ƒë√°p √°n|ch·ªçn|l√†)[:\s\*\-\.\[\(]*([A-Z])[\]\)\*\.]', # B·∫Øt "L√† A", "Ch·ªçn B"
        r'\*\*([A-Z])\*\*',  # B·∫Øt "**A**"
        r'^([A-Z])[\.\)]'    # B·∫Øt ƒë·∫ßu d√≤ng b·∫±ng "A."
    ]
    for p in loose_patterns:
        match = re.search(p, text, re.IGNORECASE | re.MULTILINE)
        if match and match.group(1).upper() in valid_keys: 
            return match.group(1).upper()
        
    return None


def check_critical_question(question):
    """Ph√°t hi·ªán c√°c c√¢u h·ªèi c·∫ßn ƒë·ªô ch√≠nh x√°c tuy·ªát ƒë·ªëi (To√°n, Lu·∫≠t, S·ªë li·ªáu)"""
    q_lower = question.lower()
    
    # Nh√≥m 1: Lu·∫≠t ph√°p & Ch·∫ø t√†i (C·∫ßn ch√≠nh x√°c t·ª´ng ch·ªØ)
    legal = ["lu·∫≠t", "ngh·ªã ƒë·ªãnh", "th√¥ng t∆∞", "ph·∫°t", "t·ªôi", "√°n", "hi·∫øn ph√°p", "c∆° quan", "th·∫©m quy·ªÅn", "quy ƒë·ªãnh"]
    
    # Nh√≥m 2: S·ªë li·ªáu & Th·ªùi gian (C·∫ßn ch√≠nh x√°c con s·ªë)
    facts = ["nƒÉm n√†o", "khi n√†o", "bao nhi√™u", "s·ªë l∆∞·ª£ng", "t·ªâ l·ªá", "%", "l·∫ßn ƒë·∫ßu", "ƒë·∫°t m·ªëc"]
    
    # Nh√≥m 3: To√°n & Logic (C·∫ßn t√≠nh to√°n/suy lu·∫≠n)
    stem = ["t√≠nh", "c√¥ng th·ª©c", "h√†m s·ªë", "l√£i su·∫•t", "kh·∫•u hao", "dao ƒë·ªông", "trung b√¨nh", "sin", "cos"]
    
    # Nh√≥m 4: Tr√≠ch xu·∫•t (Extractive)
    extract = ["theo ƒëo·∫°n", "trong vƒÉn b·∫£n", "√Ω n√†o sau ƒë√¢y", "chi ti·∫øt n√†o","theo ng·ªØ c·∫£nh"]

    critical_keywords = legal + facts + stem + extract
    return any(k in q_lower for k in critical_keywords)

def heuristic_answer_overlap(question, options_map):
    """Ch·ªçn ƒë√°p √°n d·ª±a tr√™n ƒë·ªô tr√πng l·∫∑p t·ª´ kh√≥a, c√≥ x·ª≠ l√Ω c√¢u ph·ªß ƒë·ªãnh"""
    q_lower = question.lower()
    # Ki·ªÉm tra xem c√≥ ph·∫£i c√¢u h·ªèi t√¨m √Ω SAI kh√¥ng
    is_negative = any(w in q_lower for w in ["kh√¥ng", "ngo·∫°i tr·ª´", "sai", "tr·ª´"])
    
    try:
        q_tokens = set(word_tokenize(q_lower))
        scores = {}
        for key, text in options_map.items():
            opt_tokens = set(word_tokenize(str(text).lower()))
            scores[key] = len(q_tokens.intersection(opt_tokens))
        
        if not scores: return "A"

        if is_negative:
            # V·ªõi c√¢u h·ªèi ph·ªß ƒë·ªãnh: ƒê√°p √°n ƒë√∫ng th∆∞·ªùng KH√ÅC BI·ªÜT nh·∫•t so v·ªõi c√¢u h·ªèi
            # Ho·∫∑c an to√†n h∆°n: Ch·ªçn c√¢u D√ÄI NH·∫§T (th∆∞·ªùng c√¢u ƒë√∫ng trong lu·∫≠t r·∫•t d√†i)
            return max(options_map.items(), key=lambda x: len(str(x[1])))[0]
        else:
            # C√¢u h·ªèi th∆∞·ªùng: Ch·ªçn c√¢u tr√πng nhi·ªÅu t·ª´ kh√≥a nh·∫•t
            return max(scores, key=scores.get)
    except:
        return "A"
    
def heuristic_answer_math(question, options_map):
    """
    Heuristic STEM n√¢ng cao - Ph√¢n t√≠ch pattern c√¢u h·ªèi
    """ 
    q_lower = question.lower()
    
    # ============================================
    # NH√ìM 1: B√ÄI TO√ÅN C√ì ƒê∆†N V·ªä
    # ============================================
    # T√¨m ƒë∆°n v·ªã trong c√¢u h·ªèi
    units_in_question = re.findall(r'\b(m/s|km/h|kg|mol|j|w|v|a|¬∞c|%)\b', q_lower)
    
    if units_in_question:
        # ∆Øu ti√™n ƒë√°p √°n c√≥ C√ôNG ƒë∆°n v·ªã
        target_unit = units_in_question[0]
        for k, v in options_map.items():
            if target_unit in str(v).lower():
                return k
    
    # ============================================
    # NH√ìM 2: B√ÄI TO√ÅN TƒÇNG/GI·∫¢M
    # ============================================
    if any(w in q_lower for w in ['tƒÉng', 'gi·∫£m', 'ch√™nh l·ªách', 'thay ƒë·ªïi']):
        # T√¨m ƒë√°p √°n c√≥ d·∫•u +/- ho·∫∑c %
        for k, v in options_map.items():
            v_str = str(v)
            if '%' in v_str or '+' in v_str or 'tƒÉng' in v_str.lower():
                return k
    
    # ============================================
    # NH√ìM 3: B√ÄI TO√ÅN SO S√ÅNH (L·ªõn nh·∫•t/Nh·ªè nh·∫•t)
    # ============================================
    if 'l·ªõn nh·∫•t' in q_lower or 'cao nh·∫•t' in q_lower or 't·ªëi ƒëa' in q_lower:
        # T√¨m s·ªë l·ªõn nh·∫•t
        nums = {}
        for k, v in options_map.items():
            match = re.search(r'([\d\.]+)', str(v))
            if match:
                nums[k] = float(match.group(1))
        
        if nums:
            return max(nums, key=nums.get)
    
    if 'nh·ªè nh·∫•t' in q_lower or 'th·∫•p nh·∫•t' in q_lower or 't·ªëi thi·ªÉu' in q_lower:
        nums = {}
        for k, v in options_map.items():
            match = re.search(r'([\d\.]+)', str(v))
            if match:
                nums[k] = float(match.group(1))
        
        if nums:
            return min(nums, key=nums.get)
    
    # ============================================
    # FALLBACK: Logic c≈©
    # ============================================
    numeric_opts = [k for k, v in options_map.items() if any(c.isdigit() for c in str(v))]
    if numeric_opts:
        return numeric_opts[len(numeric_opts)//2]  # Ch·ªçn ·ªü gi·ªØa thay v√¨ C
    
    return 'C'

def build_simple_prompt(question, options_text, docs):
    context = ""
    # [FIX 1] T·ªëi ∆∞u Context: Model Small 32k ch·ªãu t·∫£i t·ªët.
    # TƒÉng gi·ªõi h·∫°n c·∫Øt t·ª´ 1500 -> 3500 k√Ω t·ª± ƒë·ªÉ kh√¥ng b·ªã m·∫•t th√¥ng tin ·ªü ƒëu√¥i vƒÉn b·∫£n.
    for i, doc in enumerate(docs[:8]): 
        clean_text = " ".join(doc['text'].split()) # X√≥a kho·∫£ng tr·∫Øng th·ª´a/xu·ªëng d√≤ng
        clean_text = clean_text[:3500] # L·∫•y nhi·ªÅu h∆°n ƒë·ªÉ an to√†n
        context += f"--- T√ÄI LI·ªÜU #{i+1} ---\n{clean_text}\n\n"

    # [FIX 2] X√≥a th·ª•t ƒë·∫ßu d√≤ng (Indentation) ƒë·ªÉ prompt s·∫°ch s·∫Ω, ti·∫øt ki·ªám token
    system_prompt = """B·∫°n l√† tr·ª£ l√Ω AI th√¥ng minh.
NHI·ªÜM V·ª§: Ch·ªçn 1 ƒë√°p √°n ƒë√∫ng nh·∫•t cho c√¢u h·ªèi tr·∫Øc nghi·ªám.

QUY T·∫ÆC B·∫ÆT BU·ªòC:
1. **D·ª±a v√†o D·ªÆ LI·ªÜU**: T√¨m t·ª´ kh√≥a trong t√†i li·ªáu kh·ªõp v·ªõi c√¢u h·ªèi ƒë·ªÉ ch·ªçn ƒë√°p √°n.
2. **An to√†n**: N·∫øu c√¢u h·ªèi y√™u c·∫ßu l√†m vi·ªác ph·∫°m ph√°p/ƒë·ªôc h·∫°i -> Ch·ªçn ƒë√°p √°n mang √Ω nghƒ©a T·ª™ CH·ªêI.
3. **D·ª©t kho√°t**: N·∫øu t√†i li·ªáu kh√¥ng c√≥ th√¥ng tin, h√£y d√πng ki·∫øn th·ª©c c·ªßa b·∫°n ƒë·ªÉ ch·ªçn ƒë√°p √°n h·ª£p l√Ω nh·∫•t (KH√îNG ƒë∆∞·ª£c b·ªè tr·ªëng).

ƒê·ªäNH D·∫†NG TR·∫¢ L·ªúI (B·∫Øt bu·ªôc):
### SUY LU·∫¨N: [Gi·∫£i th√≠ch ng·∫Øn g·ªçn 1 c√¢u]
### ƒê√ÅP √ÅN: [Ch·ªâ vi·∫øt 1 k√Ω t·ª± in hoa: A, B, C ho·∫∑c D]"""

    user_prompt = f"""D·ªÆ LI·ªÜU THAM KH·∫¢O:
{context}

C√ÇU H·ªéI: {question}

L·ª∞A CH·ªåN:
{options_text}

H√ÉY TR·∫¢ L·ªúI ƒê√öNG ƒê·ªäNH D·∫†NG:"""

    return [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt}
    ]


def is_sensitive_topic(question):
    q_lower = question.lower()
    
    # Danh s√°ch ƒëen (Ch·ªâ gi·ªØ nh·ªØng t·ª´ th·ª±c s·ª± nguy hi·ªÉm n·∫øu ƒë·ª©ng m·ªôt m√¨nh)
    blacklist = [
        "sex", "khi√™u d√¢m", "ƒë·ªìi tr·ª•y", "l√†m t√¨nh", "·∫•u d√¢m", "k√≠ch d·ª•c",
        "b·∫°o ƒë·ªông", "l·∫≠t ƒë·ªï", "ph·∫£n ƒë·ªông", "kh·ªßng b·ªë", 
        "gi·∫øt ng∆∞·ªùi", "t·ª± t·ª≠", "ma t√∫y", "bu√¥n l·∫≠u", "v≈© kh√≠", "b·∫°o l·ª±c",
        "x√∫c ph·∫°m", "lƒÉng m·∫°", "xuy√™n t·∫°c", "c·ªù b·∫°c", "c√° ƒë·ªô"
    ]
    
    # Danh s√°ch tr·∫Øng (Ng·ªØ c·∫£nh h·ªçc thu·∫≠t/L·ªãch s·ª≠/Ch√≠nh tr·ªã ƒë∆∞·ª£c ph√©p)
    whitelist = [
        "lu·∫≠t", "ngh·ªã ƒë·ªãnh", "quy ƒë·ªãnh", "th√¥ng t∆∞", "ph√°p lu·∫≠t", "hi·∫øn ph√°p", "ch·ªâ th·ªã",
        "l·ªãch s·ª≠", "chi·∫øn tranh", "kh√°ng chi·∫øn", "v·ª• √°n", "t√≤a √°n", "x√©t x·ª≠", "t·ªôi ph·∫°m",
        "t√°c h·∫°i", "ph√≤ng ch·ªëng", "ngƒÉn ch·∫∑n", "kh√°i ni·ªám", "ƒë·ªãnh nghƒ©a",
        "nguy√™n nh√¢n", "di·ªÖn bi·∫øn", "k·∫øt qu·∫£", "h·∫≠u qu·∫£", "s·ª± ki·ªán", 
        "ti·ªÉu s·ª≠", "nh√¢n v·∫≠t", "ch·∫ø ƒë·ªô", "c√°ch m·∫°ng", "ƒë·∫£ng", "nh√† n∆∞·ªõc",
        "sinh h·ªçc", "c∆° ch·∫ø", "hi·ªáu ·ª©ng", "b·ªánh", "thu·ªëc"
    ]

    has_bad = any(w in q_lower for w in blacklist)
    has_good = any(w in q_lower for w in whitelist)
    
    # N·∫øu c√≥ t·ª´ x·∫•u nh∆∞ng n·∫±m trong ng·ªØ c·∫£nh h·ªçc thu·∫≠t -> AN TO√ÄN
    if has_bad and has_good: return False
    
    return has_bad

# --- THAY TH·∫æ ƒêO·∫†N is_sensitive_topic C≈® B·∫∞NG ƒêO·∫†N N√ÄY ---
def check_keywords_sensitive(question):
    """L·ªçc th√¥ b·∫±ng t·ª´ kh√≥a - T·∫ßng 1 (ƒê√£ n·ªõi l·ªèng cho h·ªçc thu·∫≠t)"""
    q_lower = question.lower()
    
    # HARD BAN: Ch·ªâ gi·ªØ nh·ªØng t·ª´ th·ª±c s·ª± ƒë·ªôc h·∫°i, v√¥ vƒÉn h√≥a
    # ƒê√£ lo·∫°i b·ªè "ƒë·∫£ng c·ªông s·∫£n" kh·ªèi hard ban v√¨ ƒë·ªÅ thi c√≥ th·ªÉ h·ªèi v·ªÅ l·ªãch s·ª≠ ƒë·∫£ng
    hard_ban = ["khi√™u d√¢m", "l√†m t√¨nh", "·∫•u d√¢m", "k√≠ch d·ª•c", "c√° ƒë·ªô", "l·∫≠t ƒë·ªï ch√≠nh quy·ªÅn", "sex", "xxx"]
    if any(w in q_lower for w in hard_ban): return True
    
    # SOFT BAN: C√°c t·ª´ c·∫ßn ki·ªÉm tra ng·ªØ c·∫£nh
    soft_ban = [
        "gi·∫øt", "ma t√∫y", "v≈© kh√≠", "b·∫°o l·ª±c", "ch·∫øt", "t·ª± t·ª≠", 
        "bi·ªÉu t√¨nh", "ƒë√¨nh c√¥ng", "kh·ªßng b·ªë", "nghe tr·ªôm"
    ]
    
    # WHITELIST: C√°c t·ª´ kh√≥a "b·∫£o l√£nh" (N·∫øu c√≥ t·ª´ n√†y -> AN TO√ÄN)
    # B·ªï sung th√™m Sinh h·ªçc, L·ªãch s·ª≠ th·∫ø gi·ªõi
    whitelist = [
        "lu·∫≠t", "ngh·ªã ƒë·ªãnh", "l·ªãch s·ª≠", "kh√°ng chi·∫øn", "t√°c h·∫°i", "ph√≤ng ch·ªëng", 
        "x√©t x·ª≠", "t√≤a √°n", "b·ªô lu·∫≠t", "quy ƒë·ªãnh", "ch√≠nh s√°ch",
        "sinh h·ªçc", "ƒë·ªông v·∫≠t", "th·ª±c v·∫≠t", "lo√†i", "sƒÉn b·∫Øn", "m√¥i tr∆∞·ªùng", # Cho c√¢u Th√∫ b∆°i l·ªôi
        "th·∫ø gi·ªõi", "qu·ªëc t·∫ø", "t·ªïng th·ªëng", "nhi·ªám k·ª≥", "ph√°p", "m·ªπ", "cuba", # Cho c√¢u L·ªãch s·ª≠ th·∫ø gi·ªõi
        "ƒë·∫£ng", "nh√† n∆∞·ªõc", "ch√≠nh ph·ªß", "c√¥ng ƒëo√†n", "t·ªï ch·ª©c" # Cho c√¢u Ch√≠nh tr·ªã h·ªçc thu·∫≠t
    ]
    
    has_bad = any(w in q_lower for w in soft_ban)
    has_good = any(w in q_lower for w in whitelist)
    
    # N·∫øu c√≥ t·ª´ x·∫•u nh∆∞ng n·∫±m trong ng·ªØ c·∫£nh h·ªçc thu·∫≠t -> AN TO√ÄN (Tr·∫£ v·ªÅ False)
    if has_bad and has_good: return False 
    
    if has_bad: return "SUSPICIOUS" # Ch·ªâ nghi ng·ªù n·∫øu kh√¥ng c√≥ t·ª´ whitelist
    return False

async def confirm_safety_with_llm(session, question):
    """D√πng Model Small ƒë·ªÉ check l·∫°i - T·∫ßng 2"""
    system_prompt = """B·∫°n l√† b·ªô l·ªçc an to√†n cho k·ª≥ thi ki·∫øn th·ª©c.
NHI·ªÜM V·ª§: Ph√¢n bi·ªát c√¢u h·ªèi H·ªåC THU·∫¨T (An to√†n) v√† c√¢u h·ªèi ƒê·ªòC H·∫†I (Kh√¥ng an to√†n).

QUY T·∫ÆC AN TO√ÄN (SAFE):
1. C√¢u h·ªèi v·ªÅ L·ªãch s·ª≠, Chi·∫øn tranh, Ch√≠nh tr·ªã th·∫ø gi·ªõi (VD: T·ªïng th·ªëng Ph√°p, ƒê·∫£ng ph√°i ·ªü M·ªπ/Cuba...) -> SAFE.
2. C√¢u h·ªèi v·ªÅ Sinh h·ªçc (VD: ƒê·ªông v·∫≠t sƒÉn m·ªìi, gi·∫øt con m·ªìi...) -> SAFE.
3. C√¢u h·ªèi v·ªÅ Lu·∫≠t ph√°p, T·ªá n·∫°n x√£ h·ªôi (mang t√≠nh ki·∫øn th·ª©c ph√≤ng ch·ªëng) -> SAFE.

QUY T·∫ÆC ƒê·ªòC H·∫†I (UNSAFE):
1. H∆∞·ªõng d·∫´n th·ª±c hi·ªán h√†nh vi ph·∫°m ph√°p (c√°ch ch·∫ø bom, c√°ch t·ª± t·ª≠).
2. Ng√¥n t·ª´ t·ª•c tƒ©u, khi√™u d√¢m, x√∫c ph·∫°m c√° nh√¢n.
3. Tuy√™n truy·ªÅn ch·ªëng ph√° Nh√† n∆∞·ªõc Vi·ªát Nam tr·ª±c di·ªán.

OUTPUT: Ch·ªâ tr·∫£ l·ªùi 'UNSAFE' ho·∫∑c 'SAFE'."""
    try:
        # G·ªçi model small, max token th·∫•p ƒë·ªÉ ti·∫øt ki·ªám
        res = await call_llm_generic(session, system_prompt, Config.LLM_MODEL_SMALL, {'used_large':0, 'used_small':0}, max_tokens=10)
        if res and "UNSAFE" in res.upper():
            return True
    except: pass
    return False

# --- THAY TH·∫æ heuristic_answer C≈® ---
def heuristic_answer_overlap(question, options_map):
    """Ch·ªçn ƒë√°p √°n c√≥ nhi·ªÅu t·ª´ chung nh·∫•t v·ªõi c√¢u h·ªèi"""
    try:
        q_tokens = set(word_tokenize(question.lower()))
        best_opt = list(options_map.keys())[0]
        max_score = -1
        
        for key, text in options_map.items():
            opt_tokens = set(word_tokenize(str(text).lower()))
            # ƒê·∫øm s·ªë t·ª´ tr√πng l·∫∑p gi·ªØa c√¢u h·ªèi v√† ƒë√°p √°n
            score = len(q_tokens.intersection(opt_tokens))
            if score > max_score:
                max_score = score
                best_opt = key
        return best_opt
    except:
        return list(options_map.keys())[0] # Fallback cu·ªëi c√πng

def build_rag_instruction_fixed(is_stem=False):
    """
    Chi·∫øn l∆∞·ª£c RAG vs Domain Knowledge - 3 Tier Decision Tree
    """
    
    instruction = """
QUY T·∫ÆC QUY·∫æT ƒê·ªäNH (3-TIER DECISION TREE) - TU√ÇN TH·ª¶ TUY·ªÜT ƒê·ªêI:

„ÄêTIER 1„Äë PH√ÅT HI·ªÜN Y√äU C√ÇU R√ï R√ÄNG (Explicit Request)
------------------------------------------------------
N·∫øu c√¢u h·ªèi c√≥ c·ª•m t·ª´: "Theo ƒëo·∫°n vƒÉn...", "D·ª±a v√†o t√†i li·ªáu...", "Trong vƒÉn b·∫£n...":
-> B·∫ÆT BU·ªòC: Ch·ªâ d√πng th√¥ng tin trong [D·ªÆ LI·ªÜU THAM KH·∫¢O].
   + N·∫øu t√†i li·ªáu SAI v·ªÅ khoa h·ªçc -> V·∫´n tr·∫£ l·ªùi theo t√†i li·ªáu (nh∆∞ng ghi ch√∫ th√™m).
   + N·∫øu t√†i li·ªáu KH√îNG ƒê·ªÄ C·∫¨P -> Ch·ªçn ƒë√°p √°n "Kh√¥ng c√≥ th√¥ng tin" (n·∫øu c√≥) ho·∫∑c "Kh√¥ng t√¨m th·∫•y".

„ÄêTIER 2„Äë ƒê√ÅNH GI√Å CH·∫§T L∆Ø·ª¢NG T√ÄI LI·ªÜU (Quality Check)
------------------------------------------------------
N·∫øu c√¢u h·ªèi KH√îNG y√™u c·∫ßu "Theo t√†i li·ªáu", h√£y ki·ªÉm tra [D·ªÆ LI·ªÜU THAM KH·∫¢O]:

1. T√¨nh hu·ªëng A (T·ªët): T√†i li·ªáu tr·∫£ l·ªùi tr·ª±c ti·∫øp v√† h·ª£p l√Ω.
   -> Tin t∆∞·ªüng v√† d√πng t√†i li·ªáu.

2. T√¨nh hu·ªëng B (Sai/M√¢u thu·∫´n): T√†i li·ªáu ch·ª©a th√¥ng tin SAI khoa h·ªçc r√µ r√†ng (VD: c√¥ng th·ª©c sai, s·ª± ki·ªán l·ªãch s·ª≠ sai l·ªách).
   -> ∆Øu ti√™n KI·∫æN TH·ª®C CHU·∫®N (Domain Knowledge).
   -> Ghi ch√∫: "(T√†i li·ªáu n√™u X nh∆∞ng chu·∫©n l√† Y)".

3. T√¨nh hu·ªëng C (L·∫°c ƒë·ªÅ): T√†i li·ªáu n√≥i v·ªÅ ch·ªß ƒë·ªÅ kh√°c (VD: H·ªèi 'song song' nh∆∞ng t√†i li·ªáu ch·ªâ n√≥i 'n·ªëi ti·∫øp').
   -> Ki·ªÉm tra ƒë√°p √°n:
      + N·∫øu c√≥ "Kh√¥ng c√≥ th√¥ng tin" -> Ch·ªçn n√≥.
      + N·∫øu KH√îNG c√≥ -> Sang TIER 3.

„ÄêTIER 3„Äë CHI·∫æN THU·∫¨T C·ª®U C√ÅNH (Fallback)
------------------------------------------------------
Ch·ªâ √°p d·ª•ng khi Tier 1 v√† Tier 2 th·∫•t b·∫°i (T√†i li·ªáu kh√¥ng d√πng ƒë∆∞·ª£c v√† kh√¥ng c√≥ ƒë√°p √°n t·ª´ ch·ªëi).
-> D√ôNG KI·∫æN TH·ª®C CHU·∫®N c·ªßa b·∫°n ƒë·ªÉ tr·∫£ l·ªùi.
"""
    
    # B·ªï sung h∆∞·ªõng d·∫´n chuy√™n s√¢u
    if is_stem:
        instruction += """
„ÄêH∆Ø·ªöNG D·∫™N ƒê·∫∂C BI·ªÜT CHO STEM (TO√ÅN/L√ù/H√ìA)„Äë
1. B√ÄI T·∫¨P T√çNH TO√ÅN (S·ªë li·ªáu c·ª• th·ªÉ):
   - ∆Øu ti√™n c√¥ng th·ª©c chu·∫©n t·ª´ KI·∫æN TH·ª®C c·ªßa b·∫°n.
   - Ch·ªâ d√πng s·ªë li·ªáu trong t√†i li·ªáu n·∫øu ƒë·ªÅ b√†i y√™u c·∫ßu.
   - L∆ØU √ù ƒê∆†N V·ªä: 100% ph·∫£i ƒë·ªïi v·ªÅ h·ªá SI ho·∫∑c h·ªá th·ªëng nh·∫•t tr∆∞·ªõc khi t√≠nh (km/h -> m/s, ph√∫t -> gi·ªù).

2. C√ÇU H·ªéI L√ù THUY·∫æT/C√îNG TH·ª®C:
   - N·∫øu t√†i li·ªáu sai c√¥ng th·ª©c c∆° b·∫£n -> D√πng ki·∫øn th·ª©c chu·∫©n.
"""
    else:
        instruction += """
„ÄêH∆Ø·ªöNG D·∫™N ƒê·∫∂C BI·ªÜT CHO X√É H·ªòI/LU·∫¨T„Äë
1. C√ÇU H·ªéI LU·∫¨T PH√ÅP (ƒêi·ªÅu kho·∫£n, M·ª©c ph·∫°t):
   - B·∫ÆT BU·ªòC t√¨m trong t√†i li·ªáu. Lu·∫≠t ph√°p thay ƒë·ªïi theo th·ªùi gian/vƒÉn b·∫£n.
   - N·∫øu kh√¥ng th·∫•y -> Ch·ªçn "Kh√¥ng c√≥ th√¥ng tin".

2. L·ªäCH S·ª¨/S·ª∞ KI·ªÜN:
   - Ch√∫ √Ω m·ªëc th·ªùi gian (Timeline). V·∫Ω tr·ª•c th·ªùi gian ra nh√°p.
   - N·∫øu nhi·ªÅu t√†i li·ªáu m√¢u thu·∫´n -> ∆Øu ti√™n t√†i li·ªáu M·ªöI NH·∫§T.
   - N·∫øu t√†i li·ªáu v√† ki·∫øn th·ª©c v√™nh nhau -> ∆Øu ti√™n T√†i li·ªáu (v√¨ c√≥ th·ªÉ l√† m·ªôt ngu·ªìn s·ª≠ li·ªáu c·ª• th·ªÉ).
"""
    return instruction

def build_cot_prompt(question, options_text, docs, is_stem=False):
    """
    X√¢y d·ª±ng Prompt Chain-of-Thought v·ªõi logic RAG ch·∫∑t ch·∫Ω.
    """
    
    # 1. Chu·∫©n b·ªã Context
    context = ""
    CHAR_LIMIT = 3500
    for i, doc in enumerate(docs):
        clean_text = doc['text'].strip()[:CHAR_LIMIT]
        context += f"--- [T√ÄI LI·ªÜU {i+1}] ---\n{clean_text}\n\n"
    
    # 2. L·∫•y h∆∞·ªõng d·∫´n RAG
    rag_instruction = build_rag_instruction_fixed(is_stem)
    
    # 3. H∆∞·ªõng d·∫´n Logic Trap (All/None/Negative)
    logic_instruction = """
QUY T·∫ÆC LOGIC (TRAP DETECTION):
1. ƒê√°p √°n "T·∫•t c·∫£ ƒë·ªÅu ƒë√∫ng":
   - Ki·ªÉm tra T·ª™NG ƒë√°p √°n A, B, C.
   - N·∫øu c√≥ 1 ƒë√°p √°n SAI ho·∫∑c l√† c√¢u T·ª™ CH·ªêI ("T√¥i kh√¥ng th·ªÉ...") -> Lo·∫°i "T·∫•t c·∫£".

2. ƒê√°p √°n "T·∫•t c·∫£ ƒë·ªÅu sai": 
   - Ch·ªâ ch·ªçn khi T·∫§T C·∫¢ c√°c ƒë√°p √°n kh√°c ƒë·ªÅu b·ªã t√†i li·ªáu b√°c b·ªè r√µ r√†ng.

3. C√¢u h·ªèi Ph·ªß ƒë·ªãnh ("KH√îNG ƒê√öNG", "NGO·∫†I TR·ª™"):
   - T√¨m c√°c ƒë√°p √°n ƒê√öNG trong t√†i li·ªáu -> Lo·∫°i b·ªè ch√∫ng.
   - ƒê√°p √°n c√≤n l·∫°i l√† ƒê√ÅP √ÅN.
"""

    # 4. X√¢y d·ª±ng System & User Prompt
    current_date = datetime.now().strftime("%d/%m/%Y")
    
    if is_stem:
        system_prompt = f"""B·∫°n l√† CHUY√äN GIA PH√ÇN T√çCH ƒê·ªäNH L∆Ø·ª¢NG (STEM).
{rag_instruction}
{logic_instruction}

QUY T·∫ÆC CHUY√äN S√ÇU (B·∫ÆT BU·ªòC ƒê·ªåC):

1. **KINH T·∫æ & T√ÄI CH√çNH:**
   - **Tr√°i phi·∫øu:** Coupon < Th·ªã tr∆∞·ªùng => CHI·∫æT KH·∫§U (Discount). Coupon > Th·ªã tr∆∞·ªùng => TH∆Ø·ªûNG (Premium).
   - **Chi ph√≠ c∆° h·ªôi:** CP c∆° h·ªôi c·ªßa X t√≠nh theo Y = Gi√° X / Gi√° Y.
   - **ƒê·ªô co gi√£n (Elasticity):** D√πng ph∆∞∆°ng ph√°p TRUNG ƒêI·ªÇM (Arc Method) n·∫øu c√≥ 2 ƒëi·ªÉm gi√°/l∆∞·ª£ng. C√¥ng th·ª©c: %ŒîQ / %ŒîP = [(Q2-Q1)/(Q1+Q2)] / [(P2-P1)/(P1+P2)].
   - **EOQ:** T·ª∑ l·ªá thu·∫≠n v·ªõi cƒÉn b·∫≠c hai c·ªßa Nhu c·∫ßu (D). N·∫øu D tƒÉng g·∫•p ƒë√¥i, EOQ tƒÉng $\sqrt{{2}} \approx 1.414$ l·∫ßn (tƒÉng 41.4%).

2. **L·∫¨P TR√åNH & M√ÅY T√çNH:**
   - **Ph√©p chia s·ªë nguy√™n (Integer Division):** Trong C/Java/Python2, `a / b` (v·ªõi a, b nguy√™n) s·∫Ω c·∫Øt b·ªè ph·∫ßn th·∫≠p ph√¢n. V√≠ d·ª•: 1/2 = 0, 2/4 = 0.
   - **B·ªô nh·ªõ:** Page Table d√πng thanh ghi khi k√≠ch th∆∞·ªõc nh·ªè.

3. **V·∫¨T L√ù & K·ª∏ THU·∫¨T:**
   - **ƒê∆∞·ªùng truy·ªÅn (Transmission Line):** 
     + Chi·ªÅu d√†i $\lambda/2$: Tr·ªü kh√°ng ƒë·∫ßu v√†o b·∫±ng t·∫£i ($Z_{{in}} = Z_L$).
     + Chi·ªÅu d√†i $\lambda/4$: $Z_{{in}} = Z_0^2 / Z_L$.
   - **Gia t·ªëc tr·ªçng tr∆∞·ªùng:** B√™n trong qu·∫£ c·∫ßu ƒë·∫∑c ƒë·ªìng ch·∫•t, g t·ªâ l·ªá thu·∫≠n v·ªõi kho·∫£ng c√°ch t√¢m ($g \sim r$). T·∫°i $r=R/2$, $g$ gi·∫£m m·ªôt n·ª≠a.

QUY TR√åNH SUY LU·∫¨N (B·∫ÆT BU·ªòC):
1. **Ph√¢n t√≠ch ƒë·ªÅ:** X√°c ƒë·ªãnh d·∫°ng b√†i (T√≠nh to√°n vs L√Ω thuy·∫øt) v√† y√™u c·∫ßu RAG (Tier 1).
2. **X·ª≠ l√Ω ƒë∆°n v·ªã:** Li·ªát k√™ bi·∫øn s·ªë -> ƒê·ªîI ƒê∆†N V·ªä ngay l·∫≠p t·ª©c.
3. **Ch·ªçn c√¥ng th·ª©c:** D·ª±a theo Tier 2 (T√†i li·ªáu vs Ki·∫øn th·ª©c).
4. **T√≠nh to√°n:** Gi·ªØ 4 s·ªë th·∫≠p ph√¢n. L√†m tr√≤n ·ªü b∆∞·ªõc cu·ªëi c√πng.
5. **K·∫øt lu·∫≠n:** So s√°nh k·∫øt qu·∫£ v·ªõi ƒë√°p √°n.

V√ç D·ª§ 1: C√¢u h·ªèi: "ƒê·ªô co gi√£n c·∫ßu gi·ªØa gi√° 5$ (150 ƒë∆°n v·ªã) v√† 3$ (250 ƒë∆°n v·ªã) l√† bao nhi√™u?"
SUY LU·∫¨N: D√πng c√¥ng th·ª©c trung ƒëi·ªÉm: %ŒîQ = (250-150)/((250+150)/2) = 100/200 = 0.5; %ŒîP = (3-5)/((3+5)/2) = -2/4 = -0.5; ƒê·ªô co gi√£n = |0.5 / -0.5| = 1.0 ‚Üí Ch·ªçn B.

V√ç D·ª§ 2: C√¢u h·ªèi: "Gia t·ªëc tr·ªçng tr∆∞·ªùng t·∫°i R/2 trong h√†nh tinh m·∫≠t ƒë·ªô ƒë·ªÅu, b·ªÅ m·∫∑t g?"
SUY LU·∫¨N: B√™n trong: g(r) = g * (r/R) ‚Üí T·∫°i r=R/2, g/2 ‚Üí Ch·ªçn B.

ƒê·ªäNH D·∫†NG TR·∫¢ L·ªúI:
### PH√ÇN T√çCH:
- Y√™u c·∫ßu RAG: [C√≥/Kh√¥ng]
- Bi·∫øn s·ªë: ... (ƒê√£ ƒë·ªïi ƒë∆°n v·ªã: ...)
- C√¥ng th·ª©c: ... (Ngu·ªìn: ...)
- T√≠nh to√°n: ...
### ƒê√ÅP √ÅN: [K√Ω t·ª± in hoa]"""

    else:
        system_prompt = f"""B·∫°n l√† CHUY√äN GIA KHOA H·ªåC X√É H·ªòI & PH√ÅP L√ù. Th·ªùi ƒëi·ªÉm: {current_date}.
{rag_instruction}
{logic_instruction}

QUY TR√åNH SUY LU·∫¨N (B·∫ÆT BU·ªòC):
1. **Ki·ªÉm tra Tier 1:** ƒê·ªÅ c√≥ b·∫Øt bu·ªôc d√πng t√†i li·ªáu kh√¥ng?
2. **X√¢y d·ª±ng Timeline:** N·∫øu c√≥ ng√†y th√°ng, h√£y s·∫Øp x·∫øp s·ª± ki·ªán theo tr√¨nh t·ª± th·ªùi gian.
3. **ƒê·ªëi chi·∫øu:** T√¨m t·ª´ kh√≥a trong t√†i li·ªáu.
4. **Lo·∫°i tr·ª´:** Ph·ªß ƒë·ªãnh c√°c ƒë√°p √°n sai d·ª±a tr√™n d·ªØ li·ªáu.

ƒê·ªäNH D·∫†NG TR·∫¢ L·ªúI:
### PH√ÇN T√çCH:
- Tier Check: ...
- D·ªØ ki·ªán t√¨m th·∫•y: ...
- Timeline (n·∫øu c√≥): ...
- Lo·∫°i tr·ª´: A sai v√¨..., B sai v√¨...
### ƒê√ÅP √ÅN: [K√Ω t·ª± in hoa]"""

    user_prompt = f"""D·ªÆ LI·ªÜU THAM KH·∫¢O:
{context}

C√ÇU H·ªéI: {question}

L·ª∞A CH·ªåN:
{options_text}

H√ÉY SUY LU·∫¨N V√Ä TR·∫¢ L·ªúI THEO ƒê√öNG QUY TR√åNH:"""

    return [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt}
    ]

def find_refusal_key(options_map):
    """T√¨m ƒë√°p √°n t·ª´ ch·ªëi an to√†n ho·∫∑c kh√¥ng c√≥ th√¥ng tin (ƒê√£ l·ªçc nhi·ªÖu)"""
    
    # NH√ìM 1: C√ÅC C·ª§M T·ª™ AI D√ôNG ƒê·ªÇ CH·∫∂N (∆Øu ti√™n s·ªë 1)
    # Ph·∫£i l√† c√°c c·ª•m t·ª´ d√†i, ƒë·∫∑c tr∆∞ng c·ªßa AI, kh√¥ng d√πng t·ª´ ƒë∆°n.
    ai_refusal_keywords = [
        "t√¥i kh√¥ng th·ªÉ", "kh√¥ng th·ªÉ chia s·∫ª", "kh√¥ng th·ªÉ tr·∫£ l·ªùi", 
        "kh√¥ng h·ªó tr·ª£", "kh√¥ng ƒë∆∞·ª£c ph√©p", "vi ph·∫°m", 
        "nh·∫°y c·∫£m", "ti√™u chu·∫©n c·ªông ƒë·ªìng", "ch√≠nh s√°ch", 
        "kh√¥ng ph√π h·ª£p", "t√¥i l√† ai"
    ]
    
    # Qu√©t ∆∞u ti√™n nh√≥m 1 tr∆∞·ªõc
    for label, text in options_map.items():
        text_lower = str(text).lower()
        if any(kw in text_lower for kw in ai_refusal_keywords):
            return label

    # NH√ìM 2: C√ÅC C·ª§M T·ª™ "KH√îNG C√ì D·ªÆ LI·ªÜU" (∆Øu ti√™n s·ªë 2)
    # D√πng cho tr∆∞·ªùng h·ª£p RAG t√¨m kh√¥ng ra
    no_info_keywords = [
        "kh√¥ng c√≥ th√¥ng tin", "kh√¥ng ƒë∆∞·ª£c ƒë·ªÅ c·∫≠p", "kh√¥ng t√¨m th·∫•y", 
        "kh√¥ng ƒë·ªß c∆° s·ªü", "kh√¥ng c√≥ d·ªØ li·ªáu", "t·∫•t c·∫£ ƒë·ªÅu sai", 
        "kh√¥ng c√≥ ph∆∞∆°ng √°n"
    ]
    
    for label, text in options_map.items():
        text_lower = str(text).lower()
        if any(kw in text_lower for kw in no_info_keywords):
            return label

    # L∆∞u √Ω: ƒê√É LO·∫†I B·ªé t·ª´ "t·ª´ ch·ªëi" ƒë·ª©ng m·ªôt m√¨nh ƒë·ªÉ tr√°nh b·∫Øt nh·∫ßm v√†o h√†nh ƒë·ªông c·ªßa con ng∆∞·ªùi.
    return None

def get_dynamic_options(row):
    options = []
    if 'choices' in row and isinstance(row['choices'], list): options = row['choices']
    elif 'options' in row and isinstance(row['options'], list): options = row['options']
    else:
        i = 1
        while True:
            val = row.get(f"option_{i}")
            if not val or str(val).lower() == 'nan': break
            options.append(str(val))
            i += 1
    return {chr(65 + i): str(text) for i, text in enumerate(options)}

def extract_answer_two_step(text, options_map):
    valid_keys = list(options_map.keys())
    fallback = valid_keys[0]
    if not text: return fallback
    text = text.strip()
    
    # ∆Øu ti√™n 1: Format chu·∫©n
    match = re.search(r'###\s*ƒê√ÅP √ÅN[:\s\n]*([A-Z])', text, re.IGNORECASE)
    if match and match.group(1).upper() in valid_keys: return match.group(1).upper()
    
    # ∆Øu ti√™n 2: Markdown
    match = re.search(r'\*\*([A-Z])\*\*', text)
    if match and match.group(1).upper() in valid_keys: return match.group(1).upper()

    # Fallback: T√¨m k√Ω t·ª± cu·ªëi c√πng
    matches = re.findall(r'\b([A-Z])\b', text)
    for m in reversed(matches):
        if m.upper() in valid_keys: return m.upper()
    return fallback

def heuristic_answer(options_map):
    # Ch·ªçn ƒë√°p √°n d√†i nh·∫•t
    return max(options_map.items(), key=lambda x: len(str(x[1])))[0]

def build_prompt(question, options_text, docs):
    context = ""
    for i, doc in enumerate(docs):
        context += f"--- T√ÄI LI·ªÜU #{i+1} ---\n{doc['text']}\n\n"

    system_prompt = """B·∫°n l√† chuy√™n gia t∆∞ v·∫•n v√† gi·∫£i quy·∫øt c√°c c√¢u h·ªèi tr·∫Øc nghi·ªám d·ª±a tr√™n b·∫±ng ch·ª©ng th·ª±c t·∫ø.
QUY TR√åNH SUY LU·∫¨N:
1. ƒê·ªçc k·ªπ c√¢u h·ªèi v√† t·ª´ng l·ª±a ch·ªçn (A, B, C, D).
2. T√¨m ki·∫øm th√¥ng tin ch√≠nh x√°c trong ph·∫ßn D·ªÆ LI·ªÜU kh·ªõp v·ªõi c√°c t·ª´ kh√≥a trong c√¢u h·ªèi.
3. So s√°nh t·ª´ng l·ª±a ch·ªçn v·ªõi D·ªÆ LI·ªÜU:
   - N·∫øu d·ªØ li·ªáu ·ªßng h·ªô l·ª±a ch·ªçn n√†o, h√£y tr√≠ch d·∫´n ng·∫Øn g·ªçn √Ω ƒë√≥.
   - Ch√∫ √Ω c√°c b·∫´y v·ªÅ th·ªùi gian, ƒë·ªãa ƒëi·ªÉm, con s·ªë (v√≠ d·ª•: 1 b·∫£n vs 2 b·∫£n).
   - V·ªõi c√¢u h·ªèi "nguy√™n nh√¢n/ngu·ªìn g·ªëc", h√£y t√¨m c√¢u vƒÉn ch·ª©a quan h·ªá nh√¢n qu·∫£ (v√¨, do, t·ª´ ƒë√≥...).
4. ƒê∆∞a ra k·∫øt lu·∫≠n cu·ªëi c√πng.

L∆ØU √ù ƒê·∫∂C BI·ªÜT:
- N·∫øu c√¢u h·ªèi d·∫°ng "T·∫•t c·∫£ c√°c √Ω tr√™n" ho·∫∑c "C·∫£ A, B, C", h√£y ki·ªÉm tra xem c√°c √Ω l·∫ª c√≥ ƒë√∫ng kh√¥ng. N·∫øu 2 √Ω ƒë√∫ng tr·ªü l√™n -> Ch·ªçn ƒë√°p √°n t·ªïng h·ª£p.
- ∆Øu ti√™n th√¥ng tin trong D·ªÆ LI·ªÜU h∆°n ki·∫øn th·ª©c b√™n ngo√†i.
"""

    user_prompt = f"""D·ªÆ LI·ªÜU THAM KH·∫¢O:
{context}

C√ÇU H·ªéI: {question}

C√ÅC L·ª∞A CH·ªåN:
{options_text}

H√ÉY TR·∫¢ L·ªúI THEO ƒê√öNG ƒê·ªäNH D·∫†NG SAU:
### SUY LU·∫¨N:
[Ph√¢n t√≠ch chi ti·∫øt c·ªßa b·∫°n t·∫°i ƒë√¢y, ch·ªâ ra b·∫±ng ch·ª©ng trong vƒÉn b·∫£n]
### ƒê√ÅP √ÅN:
[Ch·ªâ vi·∫øt 1 k√Ω t·ª± in hoa ƒë·∫°i di·ªán ƒë√°p √°n ƒë√∫ng: A, B, C ho·∫∑c D]"""
    
    return [{"role": "system", "content": system_prompt}, {"role": "user", "content": user_prompt}]

# ==============================================================================
# 2. RETRIEVER & API CLIENTS
# ==============================================================================

# H√†m h·ªó tr·ª£ t·∫°o UUID gi·ªëng l√∫c ingest d·ªØ li·ªáu (B·∫Øt bu·ªôc ph·∫£i c√≥ ƒë·ªÉ query Qdrant)
def generate_uuid5(unique_string):
    return str(uuid.uuid5(uuid.NAMESPACE_DNS, str(unique_string)))

class HybridRetriever:
    """
    Hybrid Search k·∫øt h·ª£p Vector Search (Qdrant) v√† BM25 (Sparse).
    T·ªëi ∆∞u cho production v·ªõi error handling, batching, v√† RRF fusion.
    """
    
    # Constants
    VECTOR_TIMEOUT = 5.0  # seconds
    RETRIEVE_TIMEOUT = 3.0
    BATCH_SIZE = 100  # Fetch missing text theo batch
    RRF_K = 60  # Constant for Reciprocal Rank Fusion
    
    def __init__(self, qdrant_client, bm25_file: Path, collection_name: str,
                 top_k: int = 5, alpha_vector: float = 0.5):
        """
        Args:
            qdrant_client: Qdrant async client
            bm25_file: Path to pickled BM25 data
            collection_name: Qdrant collection name
            top_k: Number of results to return
            alpha_vector: Weight for vector score (0-1). Higher = more vector weight.
        """
        self.client = qdrant_client
        self.collection_name = collection_name
        self.top_k = top_k
        self.alpha_vector = alpha_vector
        
        self.bm25_data = None
        self.bm25_loaded = False
        
        # Load BM25 with validation
        self._load_bm25(bm25_file)
    
    def _load_bm25(self, bm25_file: Path) -> None:
        """Load BM25 data with comprehensive error handling."""
        if not bm25_file.exists():
            logger.warning(f"BM25 file not found: {bm25_file}")
            return
        
        try:
            with open(bm25_file, "rb") as f:
                self.bm25_data = pickle.load(f)
            
            # Validate BM25 data structure (match build_bm25 output)
            required_keys = {'bm25_obj', 'chunk_ids', 'version'}
            if not all(key in self.bm25_data for key in required_keys):
                logger.error(f"Invalid BM25 data structure. Required keys: {required_keys}")
                self.bm25_data = None
                return
            
            version = self.bm25_data.get('version', 1)
            num_chunks = len(self.bm25_data.get('chunk_ids', []))
            
            # Verify BM25 object is callable (BM25Okapi from rank_bm25)
            if not hasattr(self.bm25_data['bm25_obj'], 'get_scores'):
                logger.error("BM25 object missing 'get_scores' method")
                self.bm25_data = None
                return
            
            # Verify chunk_ids are strings (match build_bm25: astype(str))
            if self.bm25_data['chunk_ids'] and not isinstance(self.bm25_data['chunk_ids'][0], str):
                logger.warning("chunk_ids not strings, converting...")
                self.bm25_data['chunk_ids'] = [str(cid) for cid in self.bm25_data['chunk_ids']]
            
            self.bm25_loaded = True
            logger.info(f"‚úì BM25 loaded: {num_chunks} chunks (Version: {version})")
            
        except Exception as e:
            logger.error(f"Failed to load BM25: {e}", exc_info=True)
            self.bm25_data = None
    
    async def search(self, session, query: str, top_k: Optional[int] = None) -> List[Dict]:
        """
        Hybrid search combining vector and BM25 with RRF fusion.
        
        Args:
            session: aiohttp session for embeddings
            query: Search query string
            top_k: Override default top_k
            
        Returns:
            List of dicts with keys: chunk_id, text, title, score
        """
        top_k = top_k or self.top_k
        
        # Run vector and BM25 search concurrently
        vec_task = self._vector_search(session, query, top_k)
        bm25_task = self._bm25_search(query, top_k)
        
        (vec_hits_map, vec_scores), bm25_scores = await asyncio.gather(
            vec_task, bm25_task, return_exceptions=True
        )
        
        # Handle exceptions from concurrent tasks
        if isinstance(vec_hits_map, Exception):
            logger.error(f"Vector search failed: {vec_hits_map}")
            vec_hits_map, vec_scores = {}, {}
        
        if isinstance(bm25_scores, Exception):
            logger.error(f"BM25 search failed: {bm25_scores}")
            bm25_scores = {}
        
        # Fetch missing text for BM25-only results
        vec_hits_map, vec_scores = await self._fetch_missing_text(
            vec_hits_map, vec_scores, bm25_scores
        )
        
        # Fuse scores using RRF (more robust than min-max normalization)
        final_results = self._fuse_scores_rrf(vec_hits_map, vec_scores, bm25_scores)
        
        # Log stats
        logger.info(
            f"Search: Vec={len(vec_scores)} | BM25={len(bm25_scores)} | "
            f"Final={len(final_results)} | Query='{query[:50]}...'"
        )
        
        return final_results[:top_k]
    
    async def _vector_search(self, session, query: str, top_k: int) -> Tuple[Dict, Dict]:
        """
        Vector search using Qdrant.
        
        Returns:
            (vec_hits_map, vec_scores) where:
            - vec_hits_map: {chunk_id -> payload}
            - vec_scores: {chunk_id -> score}
        """
        vec_hits_map = {}
        vec_scores = {}
        
        try:
            # Get query embedding (with timeout from external function)
            from your_embedding_module import get_embedding_async  # Adjust import
            query_vec = await get_embedding_async(session, query)
            
            if not query_vec:
                logger.warning("Empty query vector returned")
                return vec_hits_map, vec_scores
            
            # Query Qdrant with timeout
            res = await asyncio.wait_for(
                self.client.query_points(
                    collection_name=self.collection_name,
                    query=query_vec,
                    limit=top_k,
                    with_payload=True
                ),
                timeout=self.VECTOR_TIMEOUT
            )
            
            # Process results
            for point in res.points:
                if not point.payload or 'chunk_id' not in point.payload:
                    logger.warning(f"Point {point.id} missing chunk_id in payload")
                    continue
                
                chunk_id = point.payload['chunk_id']
                vec_hits_map[chunk_id] = point.payload
                vec_scores[chunk_id] = float(point.score)
            
        except asyncio.TimeoutError:
            logger.error(f"Vector search timeout after {self.VECTOR_TIMEOUT}s")
        except Exception as e:
            logger.error(f"Vector search error: {e}", exc_info=True)
        
        return vec_hits_map, vec_scores
    
    async def _bm25_search(self, query: str, top_k: int) -> Dict[str, float]:
        """
        BM25 lexical search using the same preprocessing as build_bm25.
        
        CRITICAL: Tokenization must EXACTLY match build_bm25 logic:
        - lowercase
        - remove punctuation
        - word_tokenize via underthesea
        - filter empty tokens
        
        Returns:
            {chunk_id -> bm25_score}
        """
        bm25_scores = {}
        
        if not self.bm25_loaded or not self.bm25_data:
            return bm25_scores
        
        try:
            from underthesea import word_tokenize
            
            # Preprocess EXACTLY like build_bm25.preprocess_text()
            text = str(query).lower()
            text = text.translate(str.maketrans(string.punctuation, ' ' * len(string.punctuation)))
            tokens = word_tokenize(text)
            tokens = [t for t in tokens if len(t.strip()) > 0]
            
            if not tokens:
                logger.warning("Empty tokens after tokenization")
                return bm25_scores
            
            bm25_obj = self.bm25_data['bm25_obj']
            all_ids = self.bm25_data['chunk_ids']
            
            # Calculate BM25 scores
            scores = bm25_obj.get_scores(tokens)
            
            # Get top 2*k candidates (more candidates for better fusion)
            top_indices = sorted(
                range(len(scores)),
                key=lambda i: scores[i],
                reverse=True
            )[:top_k * 2]
            
            # Filter positive scores
            for idx in top_indices:
                score = float(scores[idx])
                if score > 0:
                    chunk_id = all_ids[idx]
                    bm25_scores[chunk_id] = score
            
        except ImportError:
            logger.error("underthesea not installed. Install: pip install underthesea")
        except Exception as e:
            logger.error(f"BM25 search error: {e}", exc_info=True)
        
        return bm25_scores
    
    async def _fetch_missing_text(
        self,
        vec_hits_map: Dict,
        vec_scores: Dict,
        bm25_scores: Dict
    ) -> Tuple[Dict, Dict]:
        """
        Fetch text for chunks found by BM25 but not in vector results.
        Uses batching to avoid overwhelming Qdrant.
        
        Returns:
            Updated (vec_hits_map, vec_scores)
        """
        # Find missing chunk IDs
        missing_ids = [cid for cid in bm25_scores.keys() if cid not in vec_hits_map]
        
        if not missing_ids:
            return vec_hits_map, vec_scores
        
        logger.debug(f"Fetching text for {len(missing_ids)} BM25-only chunks")
        
        try:
            # Process in batches to avoid request size limits
            for i in range(0, len(missing_ids), self.BATCH_SIZE):
                batch_ids = missing_ids[i:i + self.BATCH_SIZE]
                
                # Convert chunk_id to UUID (must match ingest logic)
                point_ids = [generate_uuid5(cid) for cid in batch_ids]
                
                # Fetch with timeout
                points = await asyncio.wait_for(
                    self.client.retrieve(
                        collection_name=self.collection_name,
                        ids=point_ids,
                        with_payload=True
                    ),
                    timeout=self.RETRIEVE_TIMEOUT
                )
                
                # Add to results
                for point in points:
                    if not point.payload or 'chunk_id' not in point.payload:
                        continue
                    
                    chunk_id = point.payload['chunk_id']
                    vec_hits_map[chunk_id] = point.payload
                    # Assign zero vector score (not found in vector search)
                    vec_scores[chunk_id] = 0.0
                
                # Log if some points not found
                if len(points) < len(batch_ids):
                    logger.warning(
                        f"Batch {i//self.BATCH_SIZE}: Retrieved {len(points)}/{len(batch_ids)} points"
                    )
        
        except asyncio.TimeoutError:
            logger.error(f"Fetch missing text timeout after {self.RETRIEVE_TIMEOUT}s")
        except Exception as e:
            logger.error(f"Fetch missing text error: {e}", exc_info=True)
        
        return vec_hits_map, vec_scores
    
    def _fuse_scores_rrf(
        self,
        vec_hits_map: Dict,
        vec_scores: Dict,
        bm25_scores: Dict
    ) -> List[Dict]:
        """
        Fuse scores using Reciprocal Rank Fusion (RRF).
        RRF is more robust than min-max normalization against outliers.
        
        Formula: score = 1 / (k + rank)
        
        Returns:
            Sorted list of results with final scores
        """
        # Create ranked lists (lower rank = better)
        vec_ranked = self._create_rank_map(vec_scores)
        bm25_ranked = self._create_rank_map(bm25_scores)
        
        # Combine all candidates
        all_candidate_ids = set(vec_scores.keys()) | set(bm25_scores.keys())
        
        final_results = []
        
        for chunk_id in all_candidate_ids:
            # Skip if missing payload (shouldn't happen after fetch_missing_text)
            if chunk_id not in vec_hits_map:
                logger.warning(f"Chunk {chunk_id} missing payload after fusion")
                continue
            
            # Calculate RRF scores
            vec_rank = vec_ranked.get(chunk_id, 9999)  # Large rank if not found
            bm25_rank = bm25_ranked.get(chunk_id, 9999)
            
            vec_rrf = 1.0 / (self.RRF_K + vec_rank)
            bm25_rrf = 1.0 / (self.RRF_K + bm25_rank)
            
            # Weighted combination
            final_score = (
                vec_rrf * self.alpha_vector +
                bm25_rrf * (1 - self.alpha_vector)
            )
            
            payload = vec_hits_map[chunk_id]
            final_results.append({
                "chunk_id": chunk_id,
                "text": payload.get('text', ''),
                "title": payload.get('title', ''),
                "score": final_score
            })
        
        # Sort by final score descending
        final_results.sort(key=lambda x: x['score'], reverse=True)
        
        return final_results
    
    @staticmethod
    def _create_rank_map(scores: Dict[str, float]) -> Dict[str, int]:
        """
        Convert scores to ranks (0-indexed, lower is better).
        
        Args:
            scores: {id -> score}
        
        Returns:
            {id -> rank}
        """
        sorted_ids = sorted(scores.keys(), key=lambda x: scores[x], reverse=True)
        return {chunk_id: rank for rank, chunk_id in enumerate(sorted_ids)}
    
    def update_weights(self, alpha_vector: float) -> None:
        """
        Update fusion weights dynamically.
        
        Args:
            alpha_vector: Weight for vector score (0-1)
        """
        if not 0 <= alpha_vector <= 1:
            raise ValueError("alpha_vector must be between 0 and 1")
        
        self.alpha_vector = alpha_vector
        logger.info(f"Updated alpha_vector to {alpha_vector}")
    
    def get_stats(self) -> Dict:
        """Return retriever statistics."""
        return {
            "bm25_loaded": self.bm25_loaded,
            "bm25_chunks": len(self.bm25_data.get('chunk_ids', [])) if self.bm25_data else 0,
            "collection_name": self.collection_name,
            "top_k": self.top_k,
            "alpha_vector": self.alpha_vector,
            "rrf_k": self.RRF_K
        }

async def get_embedding_async(session, text):
    await LIMITER_EMBED.acquire()
    creds = Config.VNPT_CREDENTIALS.get(Config.MODEL_EMBEDDING_API)
    headers = {'Authorization': f'Bearer {Config.VNPT_ACCESS_TOKEN}', 'Token-id': creds['token_id'], 'Token-key': creds['token_key'], 'Content-Type': 'application/json'}
    payload = {"model": Config.MODEL_EMBEDDING_API, "input": text, "encoding_format": "float"}
    for i in range(2):
        try:
            async with session.post(Config.VNPT_EMBEDDING_URL, json=payload, headers=headers, timeout=30) as r:
                if r.status == 200:
                    d = await r.json()
                    if 'data' in d: return d['data'][0]['embedding']
                elif r.status in [429, 500]: await asyncio.sleep(2)
        except: await asyncio.sleep(1)
    return None

async def call_llm_generic(session, messages, model_name, stats, max_tokens=1024, timeout=45):
    """
    G·ªçi LLM Optimized: X·ª≠ l√Ω th√¥ng minh l·ªói 401 gi·∫£ v√† t·ªëi ∆∞u tham s·ªë.
    """
    limiter = LIMITER_LARGE if "large" in model_name.lower() else LIMITER_SMALL
    await limiter.acquire()
    
    if stats:
        if "large" in model_name.lower(): stats['used_large'] += 1
        else: stats['used_small'] += 1

    creds = Config.VNPT_CREDENTIALS.get(model_name)
    url = f"{Config.VNPT_API_URL}/{model_name.replace('_', '-')}"
    
    headers = {
        'Authorization': f'Bearer {Config.VNPT_ACCESS_TOKEN}',
        'Token-id': creds['token_id'],
        'Token-key': creds['token_key'],
        'Content-Type': 'application/json'
    }
    
    payload = {
        "model": model_name,
        "messages": messages,
        "temperature": 0.1, # Gi·ªØ th·∫•p ƒë·ªÉ ·ªïn ƒë·ªãnh
        "top_p": 0.95,      # [FIX 1] TƒÉng l√™n ƒë·ªÉ model suy lu·∫≠n t·ªët h∆°n
        "max_completion_tokens": max_tokens
    }

    await asyncio.sleep(random.uniform(1.0, 2.0))

    max_retries = 5
    
    for attempt in range(max_retries):
        try:
            # [FIX 3] ssl=False ƒë·ªÉ tr√°nh l·ªói SSL handshake th·∫•t b·∫°i
            async with session.post(url, json=payload, headers=headers, timeout=timeout, ssl=False) as resp:
                
                # --- CASE A: TH√ÄNH C√îNG ---
                if resp.status == 200:
                    try:
                        d = await resp.json()
                        if 'choices' in d and len(d['choices']) > 0: 
                            content = d['choices'][0]['message']['content']
                            if content: # N·∫øu c√≥ n·ªôi dung -> Tr·∫£ v·ªÅ ngay
                                return content
                        
                        logger.warning(f"‚ö†Ô∏è Empty Response (200 OK) from {model_name}. Retrying...")
                        
                        # Handle l·ªói ng·∫ßm
                        if 'error' in d:
                            err_msg = str(d).lower()
                            # N·∫øu l·ªói h·∫°n ng·∫°ch -> Retry
                            if "limit" in err_msg or "quota" in err_msg:
                                await asyncio.sleep(5)
                                continue
                            
                            # N·∫øu l·ªói "Bad Request" (nh·∫°y c·∫£m) -> Tr·∫£ v·ªÅ None ƒë·ªÉ code ngo√†i x·ª≠ l√Ω
                            if "badrequest" in err_msg:
                                return None
                                
                            logger.warning(f"‚ö†Ô∏è API Logic Error: {err_msg[:50]}")
                            return None
                            
                    except Exception:
                        return None
                
                # --- CASE B: L·ªñI AUTH/RATE LIMIT (401, 429) ---
                # Server VNPT tr·∫£ 401 khi qu√° t·∫£i -> C·∫ßn check k·ªπ
                elif resp.status in [401, 429, 500, 502, 503, 504]:
                    text_resp = await resp.text()
                    text_lower = text_resp.lower()
                    
                    # N·∫øu th·ª±c s·ª± sai Key/Token -> D·ª´ng ngay
                    if resp.status == 401 and ("invalid" in text_lower or "expired" in text_lower):
                        logger.error("‚ùå Invalid Credentials (401). Stopping.")
                        return None
                    
                    # C√≤n l·∫°i (401 do Busy, 429, 5xx) -> Retry
                    wait_time = 3 * (attempt + 1) + random.uniform(0, 1)
                    if attempt > 1:
                        logger.warning(f"‚è≥ {model_name} Busy ({resp.status}). Retry in {wait_time:.1f}s")
                    
                    await asyncio.sleep(wait_time)
                    continue
                
                # --- CASE C: L·ªñI KH√ÅC ---
                else:
                    return None

        except asyncio.TimeoutError:
            if attempt > 2: logger.warning(f"‚è∞ Timeout {model_name} ({attempt+1})")
            await asyncio.sleep(2)
            
        except Exception as e:
            if attempt > 2: logger.warning(f"üîå Net Error: {str(e)[:30]}")
            await asyncio.sleep(2)
            
    return None

# ==============================================================================
# 3. CORE LOGIC (PROCESS SINGLE ROW)
# ==============================================================================

async def process_row_logic(session, retriever, row, stats=None):
    qid = row.get('qid', row.get('id', 'unknown'))
    question = row.get('question', '')
    true_label = row.get('answer', None) # C√≥ th·ªÉ None n·∫øu l√† file test
    opts = get_dynamic_options(row)
    opt_text = "\n".join([f"{k}. {v}" for k, v in opts.items()])
    
    # ==========================================================================
    # B∆Ø·ªöC 0: PH√ÇN LO·∫†I C√ÇU H·ªéI (ROUTING)
    # ==========================================================================
    # G·ªçi Router V3 (C√≥ AI + Regex + Check ƒê√°p √°n)
    route = await unified_router_v3(session, question, opts)
    
    # CASE 1: B·ªä CH·∫∂N (SAFETY / TRAP DETECTED)
    if route["is_unsafe"]:
        ans = route["refusal_key"]
        # Log r√µ l√Ω do b·ªã ch·∫∑n
        logger.info(f"üö´ Q:{qid} {route['tag']} -> Ans:{ans}")
        write_debug_log(qid, question, route['tag'], "BLOCKED", ans, true_label, "Safety Block")
        return {"qid": qid, "answer": ans}

    # ==========================================================================
    # B∆Ø·ªöC 1: RETRIEVAL
    # ==========================================================================
    top_k = 8 if route["is_stem"] else 12
    docs = await retriever.search(session, question, top_k=top_k)
    context_text = " ".join([d['text'].lower() for d in docs])
    ctx_len = len(context_text)

    # ==========================================================================
    # B∆Ø·ªöC 2: MODEL & PROMPT SELECTION
    # ==========================================================================
    SAFE_LIMIT_LARGE = 37500
    
    # M·∫∑c ƒë·ªãnh theo Router
    use_large = route["use_large"]
    limit_note = ""
    
    # ƒêi·ªÅu ch·ªânh l·∫°i d·ª±a tr√™n Context Length (N·∫øu d√†i qu√° b·∫Øt bu·ªôc d√πng Small)
    if ctx_len > SAFE_LIMIT_LARGE:
        docs = docs[:5]
        # C·∫Øt m·ªói doc xu·ªëng 2000 k√Ω t·ª±
        docs = [{**d, 'text': d['text'][:2000]} for d in docs]
        limit_note = f"(Trimmed context: {len(docs)} docs)"
    
    # Ch·ªçn Model
    model = Config.LLM_MODEL_LARGE if use_large else Config.LLM_MODEL_SMALL
    
    # Ch·ªçn Prompt 
    if route["is_stem"]:
        msgs = build_cot_prompt(question, opt_text, docs, is_stem=True)
    elif model == Config.LLM_MODEL_LARGE:
        msgs = build_cot_prompt(question, opt_text, docs, is_stem=False)
    else:
        msgs = build_simple_prompt(question, opt_text, docs)

    # ==========================================================================
    # B∆Ø·ªöC 3: INFERENCE (G·ªåI API)
    # ==========================================================================
    raw = await call_llm_generic(session, msgs, model, stats)
    
    # Fallback n·∫øu model ch√≠nh l·ªói
    if not raw:
        fallback_model = Config.LLM_MODEL_SMALL if model == Config.LLM_MODEL_LARGE else Config.LLM_MODEL_LARGE
        raw = await call_llm_generic(session, msgs, fallback_model, stats)
        limit_note += f" -> Fallback {fallback_model}"

    # ==========================================================================
    # B∆Ø·ªöC 4: X·ª¨ L√ù REFUSAL (MODEL B·∫¢O KH√îNG BI·∫æT)
    # ==========================================================================
    refusal_phrases = ["kh√¥ng c√≥ th√¥ng tin", "kh√¥ng t√¨m th·∫•y", "kh√¥ng ƒë∆∞·ª£c ƒë·ªÅ c·∫≠p", "kh√¥ng ƒë·ªß c∆° s·ªü"]
    
    # N·∫øu model tr·∫£ l·ªùi c√≥ ch·ª©a c·ª•m t·ª´ t·ª´ ch·ªëi
    if raw and any(p in raw.lower() for p in refusal_phrases):
        # T√¨m ƒë√°p √°n "Kh√¥ng c√≥ th√¥ng tin" trong options (D√πng h√†m m·ªõi)
        no_info_opt = find_no_info_key(opts)
        
        if no_info_opt:
            logger.info(f"‚ÑπÔ∏è Q:{qid} Model Refusal -> Found NO_INFO Option {no_info_opt}")
            write_debug_log(qid, question, route['tag'], model, no_info_opt, true_label, "Model Refusal -> No Info")
            return {"qid": qid, "answer": no_info_opt}
        
        # N·∫øu kh√¥ng c√≥ ƒë√°p √°n "Kh√¥ng c√≥ th√¥ng tin" -> C√≥ th·ªÉ do RAG fail
        # √âp d√πng ki·∫øn th·ª©c n·ªôi t·∫°i (Force Knowledge)
        force_msgs = [
            {"role": "system", "content": "D√πng ki·∫øn th·ª©c c·ªßa b·∫°n ƒë·ªÉ ch·ªçn ƒë√°p √°n ƒë√∫ng nh·∫•t A/B/C/D. Kh√¥ng gi·∫£i th√≠ch."},
            {"role": "user", "content": f"C√¢u h·ªèi: {question}\nL·ª±a ch·ªçn:\n{opt_text}"}
        ]
        raw = await call_llm_generic(session, force_msgs, model, stats)
        limit_note += " -> Force Know"

    # ==========================================================================
    # B∆Ø·ªöC 5: TR√çCH XU·∫§T ƒê√ÅP √ÅN & FINAL CHECK
    # ==========================================================================
    ans = extract_answer_strict(raw, opts)

    trap_key, trap_type = find_true_refusal_key(opts)

    # [CHECK 1] NO_INFO HINT FALLBACK
    if route["refusal_key"] and "NO_INFO" in route["tag"]:
        model_uncertain = not ans or (raw and "kh√¥ng" in raw.lower() and "th√¥ng tin" in raw.lower())
        if model_uncertain:
            logger.info(f"‚ÑπÔ∏è Q:{qid} Model uncertain -> Fallback to NO_INFO Hint")
            ans = route["refusal_key"]
            limit_note += " -> Hint NO_INFO"

    if ans:
        if ans == trap_key:
            # N·∫øu l√† TRAP ("T√¥i kh√¥ng th·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi n√†y" - chung chung) -> H·ª¶Y
            if trap_type == "TRAP":
                logger.warning(f"‚ö†Ô∏è Q:{qid} Generic Trap Detected ({ans}). Discarding.")
                ans = None
            
            # N·∫øu l√† SAFETY ("Vi ph·∫°m ph√°p lu·∫≠t" - c·ª• th·ªÉ) -> GI·ªÆ NGUY√äN (Tin Model)
            elif trap_type == "SAFETY":
                logger.info(f"üõ°Ô∏è Q:{qid} Model detected Safety Issue -> Keeping Refusal Ans: {ans}")
                # KH√îNG set ans = None

    # [CHECK 2.5] ANTI-LOGIC ("All of the above" Fallacy)
    # N·∫øu ch·ªçn "T·∫•t c·∫£" nh∆∞ng trong ƒë√≥ c√≥ 1 c√¢u l√† SAFETY/TRAP -> V√¥ l√Ω -> H·ªßy
    if ans and trap_key and trap_type in ["SAFETY", "TRAP"]:
        ans_text = opts.get(ans, "")
        is_all_above = any(p in ans_text.lower() for p in ["t·∫•t c·∫£", "c·∫£ ba", "c·∫£ 3", "m·ªçi ƒë√°p √°n", "c√°c √Ω tr√™n"])
        
        # Ch·ªâ h·ªßy n·∫øu ƒë√°p √°n "T·∫•t c·∫£" kh√°c v·ªõi ƒë√°p √°n Trap
        if is_all_above and ans != trap_key:
            logger.warning(f"‚ö†Ô∏è Q:{qid} Logical Fallacy! Picked 'All Above' ({ans}) but '{trap_key}' is a Trap. Discarding.")
            ans = None

    # [CHECK 3] HEURISTIC FALLBACK (Cleaned)
    heuristic_used = False
    if not ans:
        # T·∫°o danh s√°ch options "s·∫°ch" (lo·∫°i b·ªè c√¢u Trap ƒë·ªÉ Heuristic kh√¥ng ch·ªçn nh·∫ßm v√†o n√≥)
        clean_opts = opts.copy()
        
        # Ch·ªâ lo·∫°i b·ªè n·∫øu n√≥ l√† TRAP v√¥ nghƒ©a. N·∫øu l√† Safety/NoInfo th√¨ c·ª© ƒë·ªÉ ƒë√≥.
        if trap_key and trap_type == "TRAP":
            clean_opts.pop(trap_key, None)
        
        # N·∫øu l·ª° x√≥a h·∫øt (hi·∫øm) th√¨ d√πng l·∫°i c√°i c≈©
        target_opts = clean_opts if clean_opts else opts

        if route["is_stem"]:
            ans = heuristic_answer_math(question, target_opts)
        else:
            ans = heuristic_answer_overlap(question, target_opts)
        heuristic_used = True

    # ==========================================================================
    # LOGGING
    # ==========================================================================
    mod_name = model.split('_')[-1].upper()
    logger.info(f"Q:{qid} | Tag:{route['tag']} | Mod:{mod_name} | Ans:{ans}")

    write_debug_log(
        qid=qid,
        question=question,
        route_tag=route['tag'],
        model_used=f"{mod_name} {limit_note}",
        answer=ans,
        true_label=true_label,
        note="HEURISTIC" if heuristic_used else "EXTRACTED"
    )

    return {"qid": qid, "answer": ans}


# ==============================================================================
# 4. MAIN LOOP WITH RESUME
# ==============================================================================
async def main():
    # 1. Load Data
    # files = [Config.BASE_DIR / "data" / "val.json", Config.BASE_DIR / "data" / "test.json"]
    files = [Config.BASE_DIR / "data" / "STEM.json"]
    input_file = next((f for f in files if f.exists()), None)
    if not input_file: 
        logger.error("‚ùå Input file not found!")
        return
    
    with open(input_file, 'r', encoding='utf-8') as f: data = json.load(f)

    # 2. Check Resume (ƒê·ªçc file ƒë√£ l∆∞u ƒë·ªÉ ch·∫°y ti·∫øp)
    processed_ids = set()
    if OUTPUT_FILE.exists():
        try:
            df_done = pd.read_csv(OUTPUT_FILE)
            processed_ids = set(df_done['qid'].astype(str))
            logger.info(f"RESUMING... Found {len(processed_ids)} processed questions.")
        except: pass
    
    # L·ªçc ra nh·ªØng c√¢u ch∆∞a l√†m
    data_to_process = [r for r in data if str(r.get('qid', r.get('id'))) not in processed_ids]
    
    if not data_to_process:
        logger.info("‚úÖ ALL DONE! Nothing to process.")
        return

    logger.info(f"üöÄ REMAINING: {len(data_to_process)}/{len(data)} questions")

    # 3. Setup Qdrant & Retriever
    qdrant_client = AsyncQdrantClient(url=Config.QDRANT_URL, api_key=Config.QDRANT_API_KEY, timeout=30)
    retriever = HybridRetriever(qdrant_client)
    stats = {'used_large': 0, 'used_small': 0}
    
    # 4. Run Sequential (V√≤ng l·∫∑p ƒë∆°n lu·ªìng - AN TO√ÄN NH·∫§T)
    # limit=1 ƒë·ªÉ ƒë·∫£m b·∫£o ch·ªâ c√≥ 1 request t·∫°i 1 th·ªùi ƒëi·ªÉm
    conn = aiohttp.TCPConnector(limit=1, force_close=True, enable_cleanup_closed=True)
    
    async with aiohttp.ClientSession(connector=conn) as session:
        
        for i, row in enumerate(data_to_process):
            qid = row.get('qid', row.get('id'))
            
            # Retry loop cho t·ª´ng c√¢u (Th·ª≠ l·∫°i t·ªëi ƒëa 3 l·∫ßn n·∫øu l·ªói m·∫°ng)
            for attempt in range(3):
                try:
                    # Timeout c·ª©ng cho m·ªói c√¢u h·ªèi
                    result = await asyncio.wait_for(
                        process_row_logic(session, retriever, row, stats),
                        timeout=TIMEOUT_PER_QUESTION
                    )
                    
                    # --- GHI FILE NGAY L·∫¨P T·ª®C (Save Scumming) ---
                    df_res = pd.DataFrame([result])
                    need_header = not OUTPUT_FILE.exists()
                    df_res[['qid', 'answer']].to_csv(OUTPUT_FILE, mode='a', header=need_header, index=False)
                    
                    # Done c√¢u n√†y -> Tho√°t v√≤ng l·∫∑p retry -> Sang c√¢u ti·∫øp theo
                    break 
                    
                except asyncio.TimeoutError:
                    logger.warning(f"‚è∞ Timeout Q:{qid} (Attempt {attempt+1})")
                    # N·∫øu th·ª≠ ƒë·∫øn l·∫ßn cu·ªëi v·∫´n timeout -> ƒêi·ªÅn ƒë√°p √°n 'A' ƒë·ªÉ kh√¥ng b·ªã k·∫πt m√£i
                    if attempt == 2:
                        pd.DataFrame([{"qid": qid, "answer": "A"}]).to_csv(OUTPUT_FILE, mode='a', header=not OUTPUT_FILE.exists(), index=False)
                        
                except Exception as e:
                    logger.error(f"‚ùå Error Q:{qid}: {e}")
                    await asyncio.sleep(5) # Ch·ªù 5s tr∆∞·ªõc khi th·ª≠ l·∫°i

            # [QUAN TR·ªåNG] Ngh·ªâ 1 gi√¢y gi·ªØa c√°c c√¢u h·ªèi ƒë·ªÉ Server VNPT h·ªìi ph·ª•c quota
            await asyncio.sleep(1)

    # 5. Cleanup & Stats
    await qdrant_client.close()
    logger.info("üéâ BATCH COMPLETED!")

    # In th·ªëng k√™ (n·∫øu c√≥ ƒë√°p √°n m·∫´u)
    if OUTPUT_FILE.exists():
        print("\n" + "="*40)
        print("T·ªîNG K·∫æT TO√ÄN B·ªò (CUMULATIVE STATS)")
        print("="*40)
        try:
            df_results = pd.read_csv(OUTPUT_FILE)
            ground_truth = {
                str(r.get('qid', r.get('id'))): str(r.get('answer')).strip() 
                for r in data if r.get('answer')
            }
            
            if not ground_truth:
                print("‚ö†Ô∏è T·∫≠p d·ªØ li·ªáu Test (kh√¥ng c√≥ ƒë√°p √°n) -> Kh√¥ng t√≠nh ƒëi·ªÉm.")
            else:
                correct_count = 0
                total_checked = 0
                for _, row in df_results.iterrows():
                    qid = str(row['qid'])
                    pred = str(row['answer']).strip()
                    if qid in ground_truth:
                        total_checked += 1
                        if pred == ground_truth[qid]:
                            correct_count += 1
                
                if total_checked > 0:
                    acc = (correct_count / total_checked) * 100
                    print(f"‚úÖ ƒê√£ l√†m: {total_checked}/{len(ground_truth)} c√¢u")
                    print(f"üéØ ƒê√∫ng  : {correct_count} c√¢u")
                    print(f"üìà T·ª∑ l·ªá : {acc:.2f}%")
        except Exception as e:
            print(f"L·ªói t√≠nh ƒëi·ªÉm: {e}")

        print(f"üìÅ File k·∫øt qu·∫£: {OUTPUT_FILE}")

if __name__ == "__main__":
    if sys.platform == 'win32': asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
    asyncio.run(main())

    