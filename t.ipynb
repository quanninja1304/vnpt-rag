{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07104997",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b88cc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "huhu = pd.read_parquet(path=\"output/delta_chunks_to_index.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "722c1b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114797, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "huhu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1a62ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hihi = pd.read_parquet(path=\"output/1_manual_law_strict.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "088381aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2084, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hihi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6efb13d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>doc_title</th>\n",
       "      <th>doc_category</th>\n",
       "      <th>doc_url</th>\n",
       "      <th>vector_text</th>\n",
       "      <th>display_text</th>\n",
       "      <th>crawled_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>law_luat_hon_nhan_va_gia_dinh.txt_0</td>\n",
       "      <td>Lu·∫≠t H√¥n nh√¢n v√† Gia ƒë√¨nh 2014</td>\n",
       "      <td>Ph√°p lu·∫≠t</td>\n",
       "      <td>local/luat_hon_nhan_va_gia_dinh.txt</td>\n",
       "      <td>VƒÉn b·∫£n: Lu·∫≠t H√¥n nh√¢n v√† Gia ƒë√¨nh 2014\\nCh∆∞∆°n...</td>\n",
       "      <td>VƒÉn b·∫£n: Lu·∫≠t H√¥n nh√¢n v√† Gia ƒë√¨nh 2014\\nCh∆∞∆°n...</td>\n",
       "      <td>2025-12-11T10:46:46.879494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>law_luat_hon_nhan_va_gia_dinh.txt_1</td>\n",
       "      <td>Lu·∫≠t H√¥n nh√¢n v√† Gia ƒë√¨nh 2014</td>\n",
       "      <td>Ph√°p lu·∫≠t</td>\n",
       "      <td>local/luat_hon_nhan_va_gia_dinh.txt</td>\n",
       "      <td>VƒÉn b·∫£n: Lu·∫≠t H√¥n nh√¢n v√† Gia ƒë√¨nh 2014\\nCh∆∞∆°n...</td>\n",
       "      <td>VƒÉn b·∫£n: Lu·∫≠t H√¥n nh√¢n v√† Gia ƒë√¨nh 2014\\nCh∆∞∆°n...</td>\n",
       "      <td>2025-12-11T10:46:46.879494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>law_luat_hon_nhan_va_gia_dinh.txt_2</td>\n",
       "      <td>Lu·∫≠t H√¥n nh√¢n v√† Gia ƒë√¨nh 2014</td>\n",
       "      <td>Ph√°p lu·∫≠t</td>\n",
       "      <td>local/luat_hon_nhan_va_gia_dinh.txt</td>\n",
       "      <td>VƒÉn b·∫£n: Lu·∫≠t H√¥n nh√¢n v√† Gia ƒë√¨nh 2014\\nCh∆∞∆°n...</td>\n",
       "      <td>VƒÉn b·∫£n: Lu·∫≠t H√¥n nh√¢n v√† Gia ƒë√¨nh 2014\\nCh∆∞∆°n...</td>\n",
       "      <td>2025-12-11T10:46:46.879494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>law_luat_hon_nhan_va_gia_dinh.txt_3</td>\n",
       "      <td>Lu·∫≠t H√¥n nh√¢n v√† Gia ƒë√¨nh 2014</td>\n",
       "      <td>Ph√°p lu·∫≠t</td>\n",
       "      <td>local/luat_hon_nhan_va_gia_dinh.txt</td>\n",
       "      <td>VƒÉn b·∫£n: Lu·∫≠t H√¥n nh√¢n v√† Gia ƒë√¨nh 2014\\nCh∆∞∆°n...</td>\n",
       "      <td>VƒÉn b·∫£n: Lu·∫≠t H√¥n nh√¢n v√† Gia ƒë√¨nh 2014\\nCh∆∞∆°n...</td>\n",
       "      <td>2025-12-11T10:46:46.879494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>law_luat_hon_nhan_va_gia_dinh.txt_4</td>\n",
       "      <td>Lu·∫≠t H√¥n nh√¢n v√† Gia ƒë√¨nh 2014</td>\n",
       "      <td>Ph√°p lu·∫≠t</td>\n",
       "      <td>local/luat_hon_nhan_va_gia_dinh.txt</td>\n",
       "      <td>VƒÉn b·∫£n: Lu·∫≠t H√¥n nh√¢n v√† Gia ƒë√¨nh 2014\\nCh∆∞∆°n...</td>\n",
       "      <td>VƒÉn b·∫£n: Lu·∫≠t H√¥n nh√¢n v√† Gia ƒë√¨nh 2014\\nCh∆∞∆°n...</td>\n",
       "      <td>2025-12-11T10:46:46.879494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              chunk_id                       doc_title  \\\n",
       "0  law_luat_hon_nhan_va_gia_dinh.txt_0  Lu·∫≠t H√¥n nh√¢n v√† Gia ƒë√¨nh 2014   \n",
       "1  law_luat_hon_nhan_va_gia_dinh.txt_1  Lu·∫≠t H√¥n nh√¢n v√† Gia ƒë√¨nh 2014   \n",
       "2  law_luat_hon_nhan_va_gia_dinh.txt_2  Lu·∫≠t H√¥n nh√¢n v√† Gia ƒë√¨nh 2014   \n",
       "3  law_luat_hon_nhan_va_gia_dinh.txt_3  Lu·∫≠t H√¥n nh√¢n v√† Gia ƒë√¨nh 2014   \n",
       "4  law_luat_hon_nhan_va_gia_dinh.txt_4  Lu·∫≠t H√¥n nh√¢n v√† Gia ƒë√¨nh 2014   \n",
       "\n",
       "  doc_category                              doc_url  \\\n",
       "0    Ph√°p lu·∫≠t  local/luat_hon_nhan_va_gia_dinh.txt   \n",
       "1    Ph√°p lu·∫≠t  local/luat_hon_nhan_va_gia_dinh.txt   \n",
       "2    Ph√°p lu·∫≠t  local/luat_hon_nhan_va_gia_dinh.txt   \n",
       "3    Ph√°p lu·∫≠t  local/luat_hon_nhan_va_gia_dinh.txt   \n",
       "4    Ph√°p lu·∫≠t  local/luat_hon_nhan_va_gia_dinh.txt   \n",
       "\n",
       "                                         vector_text  \\\n",
       "0  VƒÉn b·∫£n: Lu·∫≠t H√¥n nh√¢n v√† Gia ƒë√¨nh 2014\\nCh∆∞∆°n...   \n",
       "1  VƒÉn b·∫£n: Lu·∫≠t H√¥n nh√¢n v√† Gia ƒë√¨nh 2014\\nCh∆∞∆°n...   \n",
       "2  VƒÉn b·∫£n: Lu·∫≠t H√¥n nh√¢n v√† Gia ƒë√¨nh 2014\\nCh∆∞∆°n...   \n",
       "3  VƒÉn b·∫£n: Lu·∫≠t H√¥n nh√¢n v√† Gia ƒë√¨nh 2014\\nCh∆∞∆°n...   \n",
       "4  VƒÉn b·∫£n: Lu·∫≠t H√¥n nh√¢n v√† Gia ƒë√¨nh 2014\\nCh∆∞∆°n...   \n",
       "\n",
       "                                        display_text  \\\n",
       "0  VƒÉn b·∫£n: Lu·∫≠t H√¥n nh√¢n v√† Gia ƒë√¨nh 2014\\nCh∆∞∆°n...   \n",
       "1  VƒÉn b·∫£n: Lu·∫≠t H√¥n nh√¢n v√† Gia ƒë√¨nh 2014\\nCh∆∞∆°n...   \n",
       "2  VƒÉn b·∫£n: Lu·∫≠t H√¥n nh√¢n v√† Gia ƒë√¨nh 2014\\nCh∆∞∆°n...   \n",
       "3  VƒÉn b·∫£n: Lu·∫≠t H√¥n nh√¢n v√† Gia ƒë√¨nh 2014\\nCh∆∞∆°n...   \n",
       "4  VƒÉn b·∫£n: Lu·∫≠t H√¥n nh√¢n v√† Gia ƒë√¨nh 2014\\nCh∆∞∆°n...   \n",
       "\n",
       "                   crawled_at  \n",
       "0  2025-12-11T10:46:46.879494  \n",
       "1  2025-12-11T10:46:46.879494  \n",
       "2  2025-12-11T10:46:46.879494  \n",
       "3  2025-12-11T10:46:46.879494  \n",
       "4  2025-12-11T10:46:46.879494  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hihi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1bb87d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>doc_title</th>\n",
       "      <th>doc_category</th>\n",
       "      <th>vector_text</th>\n",
       "      <th>display_text</th>\n",
       "      <th>doc_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anh h√πng d√¢n t·ªôc Vi·ªát Nam_0</td>\n",
       "      <td>Anh h√πng d√¢n t·ªôc Vi·ªát Nam</td>\n",
       "      <td>Nh√¢n v·∫≠t l·ªãch s·ª≠ Vi·ªát Nam</td>\n",
       "      <td>Lƒ©nh v·ª±c: Nh√¢n v·∫≠t l·ªãch s·ª≠ Vi·ªát Nam. Ch·ªß ƒë·ªÅ: A...</td>\n",
       "      <td>Anh h√πng d√¢n t·ªôc Vi·ªát Nam l√† thu·∫≠t ng·ªØ ch·ªâ nh·ªØ...</td>\n",
       "      <td>https://vi.wikipedia.org/wiki/Anh_h%C3%B9ng_d%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anh h√πng d√¢n t·ªôc Vi·ªát Nam_1</td>\n",
       "      <td>Anh h√πng d√¢n t·ªôc Vi·ªát Nam</td>\n",
       "      <td>Nh√¢n v·∫≠t l·ªãch s·ª≠ Vi·ªát Nam</td>\n",
       "      <td>Lƒ©nh v·ª±c: Nh√¢n v·∫≠t l·ªãch s·ª≠ Vi·ªát Nam. Ch·ªß ƒë·ªÅ: A...</td>\n",
       "      <td>ƒêinh Ti√™n Ho√†ng, t·ª©c ƒêinh B·ªô Lƒ©nh: ng∆∞·ªùi ƒë√°nh ...</td>\n",
       "      <td>https://vi.wikipedia.org/wiki/Anh_h%C3%B9ng_d%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anh h√πng d√¢n t·ªôc Vi·ªát Nam_2</td>\n",
       "      <td>Anh h√πng d√¢n t·ªôc Vi·ªát Nam</td>\n",
       "      <td>Nh√¢n v·∫≠t l·ªãch s·ª≠ Vi·ªát Nam</td>\n",
       "      <td>Lƒ©nh v·ª±c: Nh√¢n v·∫≠t l·ªãch s·ª≠ Vi·ªát Nam. Ch·ªß ƒë·ªÅ: A...</td>\n",
       "      <td>Ti√™u chu·∫©n\\n\\n14 v·ªã Anh h√πng d√¢n t·ªôc Vi·ªát Nam ...</td>\n",
       "      <td>https://vi.wikipedia.org/wiki/Anh_h%C3%B9ng_d%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>An D∆∞∆°ng V∆∞∆°ng_0</td>\n",
       "      <td>An D∆∞∆°ng V∆∞∆°ng</td>\n",
       "      <td>Tri·ªÅu ƒë·∫°i Vi·ªát Nam</td>\n",
       "      <td>Lƒ©nh v·ª±c: Tri·ªÅu ƒë·∫°i Vi·ªát Nam. Ch·ªß ƒë·ªÅ: An D∆∞∆°ng...</td>\n",
       "      <td>An D∆∞∆°ng V∆∞∆°ng (ch·ªØ H√°n: ÂÆâÈôΩÁéã), t√™n th·∫≠t l√† Th·ª•...</td>\n",
       "      <td>https://vi.wikipedia.org/wiki/An_D%C6%B0%C6%A1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nh√† n∆∞·ªõc Vi·ªát Nam_0</td>\n",
       "      <td>Nh√† n∆∞·ªõc Vi·ªát Nam</td>\n",
       "      <td>Nh√† n∆∞·ªõc Vi·ªát Nam</td>\n",
       "      <td>Lƒ©nh v·ª±c: Nh√† n∆∞·ªõc Vi·ªát Nam. Ch·ªß ƒë·ªÅ: Nh√† n∆∞·ªõc ...</td>\n",
       "      <td>Nh√† n∆∞·ªõc C·ªông h√≤a x√£ h·ªôi ch·ªß nghƒ©a Vi·ªát Nam l√†...</td>\n",
       "      <td>https://vi.wikipedia.org/wiki/Nh%C3%A0_n%C6%B0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      chunk_id                  doc_title  \\\n",
       "0  Anh h√πng d√¢n t·ªôc Vi·ªát Nam_0  Anh h√πng d√¢n t·ªôc Vi·ªát Nam   \n",
       "1  Anh h√πng d√¢n t·ªôc Vi·ªát Nam_1  Anh h√πng d√¢n t·ªôc Vi·ªát Nam   \n",
       "2  Anh h√πng d√¢n t·ªôc Vi·ªát Nam_2  Anh h√πng d√¢n t·ªôc Vi·ªát Nam   \n",
       "3             An D∆∞∆°ng V∆∞∆°ng_0             An D∆∞∆°ng V∆∞∆°ng   \n",
       "4          Nh√† n∆∞·ªõc Vi·ªát Nam_0          Nh√† n∆∞·ªõc Vi·ªát Nam   \n",
       "\n",
       "                doc_category  \\\n",
       "0  Nh√¢n v·∫≠t l·ªãch s·ª≠ Vi·ªát Nam   \n",
       "1  Nh√¢n v·∫≠t l·ªãch s·ª≠ Vi·ªát Nam   \n",
       "2  Nh√¢n v·∫≠t l·ªãch s·ª≠ Vi·ªát Nam   \n",
       "3         Tri·ªÅu ƒë·∫°i Vi·ªát Nam   \n",
       "4          Nh√† n∆∞·ªõc Vi·ªát Nam   \n",
       "\n",
       "                                         vector_text  \\\n",
       "0  Lƒ©nh v·ª±c: Nh√¢n v·∫≠t l·ªãch s·ª≠ Vi·ªát Nam. Ch·ªß ƒë·ªÅ: A...   \n",
       "1  Lƒ©nh v·ª±c: Nh√¢n v·∫≠t l·ªãch s·ª≠ Vi·ªát Nam. Ch·ªß ƒë·ªÅ: A...   \n",
       "2  Lƒ©nh v·ª±c: Nh√¢n v·∫≠t l·ªãch s·ª≠ Vi·ªát Nam. Ch·ªß ƒë·ªÅ: A...   \n",
       "3  Lƒ©nh v·ª±c: Tri·ªÅu ƒë·∫°i Vi·ªát Nam. Ch·ªß ƒë·ªÅ: An D∆∞∆°ng...   \n",
       "4  Lƒ©nh v·ª±c: Nh√† n∆∞·ªõc Vi·ªát Nam. Ch·ªß ƒë·ªÅ: Nh√† n∆∞·ªõc ...   \n",
       "\n",
       "                                        display_text  \\\n",
       "0  Anh h√πng d√¢n t·ªôc Vi·ªát Nam l√† thu·∫≠t ng·ªØ ch·ªâ nh·ªØ...   \n",
       "1  ƒêinh Ti√™n Ho√†ng, t·ª©c ƒêinh B·ªô Lƒ©nh: ng∆∞·ªùi ƒë√°nh ...   \n",
       "2  Ti√™u chu·∫©n\\n\\n14 v·ªã Anh h√πng d√¢n t·ªôc Vi·ªát Nam ...   \n",
       "3  An D∆∞∆°ng V∆∞∆°ng (ch·ªØ H√°n: ÂÆâÈôΩÁéã), t√™n th·∫≠t l√† Th·ª•...   \n",
       "4  Nh√† n∆∞·ªõc C·ªông h√≤a x√£ h·ªôi ch·ªß nghƒ©a Vi·ªát Nam l√†...   \n",
       "\n",
       "                                             doc_url  \n",
       "0  https://vi.wikipedia.org/wiki/Anh_h%C3%B9ng_d%...  \n",
       "1  https://vi.wikipedia.org/wiki/Anh_h%C3%B9ng_d%...  \n",
       "2  https://vi.wikipedia.org/wiki/Anh_h%C3%B9ng_d%...  \n",
       "3  https://vi.wikipedia.org/wiki/An_D%C6%B0%C6%A1...  \n",
       "4  https://vi.wikipedia.org/wiki/Nh%C3%A0_n%C6%B0...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "huhu.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93e56067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üï∑Ô∏è STARTING TARGETED CRAWL (V2 - SSL BYPASS)...\n",
      "\n",
      "üöÄ Campaign: Tu_Lieu_Dang\n",
      "  üîç Inspecting: https://tulieuvankien.dangcongsan.vn/ho-chi-minh-toan-tap\n",
      "    ‚úÖ Connected (Size: 6021 bytes)\n",
      "    ‚ÑπÔ∏è T√¨m th·∫•y 1 th·∫ª <a> trong trang.\n",
      "      üëÄ Sample link: https://tulieuvankien.dangcongsan.vn/\n",
      "    => L·ªçc ƒë∆∞·ª£c 0 link ph√π h·ª£p pattern.\n",
      "  üëâ Th·ª≠ trang 2: https://tulieuvankien.dangcongsan.vn/ho-chi-minh-toan-tap?page=2\n",
      "  üîç Inspecting: https://tulieuvankien.dangcongsan.vn/ho-chi-minh-toan-tap?page=2\n",
      "    ‚úÖ Connected (Size: 6021 bytes)\n",
      "    ‚ÑπÔ∏è T√¨m th·∫•y 1 th·∫ª <a> trong trang.\n",
      "      üëÄ Sample link: https://tulieuvankien.dangcongsan.vn/\n",
      "    => L·ªçc ƒë∆∞·ª£c 0 link ph√π h·ª£p pattern.\n",
      "  üîç Inspecting: https://tulieuvankien.dangcongsan.vn/van-kien-tu-lieu-ve-dang\n",
      "    ‚úÖ Connected (Size: 6021 bytes)\n",
      "    ‚ÑπÔ∏è T√¨m th·∫•y 1 th·∫ª <a> trong trang.\n",
      "      üëÄ Sample link: https://tulieuvankien.dangcongsan.vn/\n",
      "    => L·ªçc ƒë∆∞·ª£c 0 link ph√π h·ª£p pattern.\n",
      "  üëâ Th·ª≠ trang 2: https://tulieuvankien.dangcongsan.vn/van-kien-tu-lieu-ve-dang?page=2\n",
      "  üîç Inspecting: https://tulieuvankien.dangcongsan.vn/van-kien-tu-lieu-ve-dang?page=2\n",
      "    ‚úÖ Connected (Size: 6021 bytes)\n",
      "    ‚ÑπÔ∏è T√¨m th·∫•y 1 th·∫ª <a> trong trang.\n",
      "      üëÄ Sample link: https://tulieuvankien.dangcongsan.vn/\n",
      "    => L·ªçc ƒë∆∞·ª£c 0 link ph√π h·ª£p pattern.\n",
      "  => T·ªïng link thu ƒë∆∞·ª£c cho Tu_Lieu_Dang: 0\n",
      "\n",
      "üöÄ Campaign: Di_San_Van_Hoa\n",
      "  üîç Inspecting: http://dsvh.gov.vn/di-tich-quoc-gia-dac-biet-1756\n",
      "    ‚úÖ Connected (Size: 66596 bytes)\n",
      "    ‚ÑπÔ∏è T√¨m th·∫•y 160 th·∫ª <a> trong trang.\n",
      "      üëÄ Sample link: http://dsvh.gov.vn/\n",
      "      üëÄ Sample link: http://dsvh.gov.vn/gioi-thieu-15\n",
      "      üëÄ Sample link: http://dsvh.gov.vn/thong-tin-chung-1727\n",
      "    => L·ªçc ƒë∆∞·ª£c 63 link ph√π h·ª£p pattern.\n",
      "  üëâ Th·ª≠ trang 2: http://dsvh.gov.vn/di-tich-quoc-gia-dac-biet-1756?page=2\n",
      "  üîç Inspecting: http://dsvh.gov.vn/di-tich-quoc-gia-dac-biet-1756?page=2\n",
      "    ‚úÖ Connected (Size: 66596 bytes)\n",
      "    ‚ÑπÔ∏è T√¨m th·∫•y 160 th·∫ª <a> trong trang.\n",
      "      üëÄ Sample link: http://dsvh.gov.vn/\n",
      "      üëÄ Sample link: http://dsvh.gov.vn/gioi-thieu-15\n",
      "      üëÄ Sample link: http://dsvh.gov.vn/thong-tin-chung-1727\n",
      "    => L·ªçc ƒë∆∞·ª£c 56 link ph√π h·ª£p pattern.\n",
      "  üîç Inspecting: http://dsvh.gov.vn/di-tich-quoc-gia-1757\n",
      "    ‚úÖ Connected (Size: 66596 bytes)\n",
      "    ‚ÑπÔ∏è T√¨m th·∫•y 160 th·∫ª <a> trong trang.\n",
      "      üëÄ Sample link: http://dsvh.gov.vn/\n",
      "      üëÄ Sample link: http://dsvh.gov.vn/gioi-thieu-15\n",
      "      üëÄ Sample link: http://dsvh.gov.vn/thong-tin-chung-1727\n",
      "    => L·ªçc ƒë∆∞·ª£c 85 link ph√π h·ª£p pattern.\n",
      "  üëâ Th·ª≠ trang 2: http://dsvh.gov.vn/di-tich-quoc-gia-1757?page=2\n",
      "  üîç Inspecting: http://dsvh.gov.vn/di-tich-quoc-gia-1757?page=2\n",
      "    ‚úÖ Connected (Size: 66596 bytes)\n",
      "    ‚ÑπÔ∏è T√¨m th·∫•y 160 th·∫ª <a> trong trang.\n",
      "      üëÄ Sample link: http://dsvh.gov.vn/\n",
      "      üëÄ Sample link: http://dsvh.gov.vn/gioi-thieu-15\n",
      "      üëÄ Sample link: http://dsvh.gov.vn/thong-tin-chung-1727\n",
      "    => L·ªçc ƒë∆∞·ª£c 63 link ph√π h·ª£p pattern.\n",
      "  => T·ªïng link thu ƒë∆∞·ª£c cho Di_San_Van_Hoa: 65\n",
      "  Downloading content (65 b√†i)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 65/65 [12:08<00:00, 11.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ DONE! ƒê√£ l∆∞u 1 b√†i vi·∫øt ch·∫•t l∆∞·ª£ng v√†o targeted_knowledge.parquet\n",
      "\n",
      "üëÄ V√≠ d·ª• d·ªØ li·ªáu:\n",
      "  doc_title                                            doc_url\n",
      "0            http://dsvh.gov.vn/mo-cu-pho-bang-nguyen-sinh-...\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import trafilatura\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "from urllib.parse import urljoin\n",
    "from tqdm import tqdm\n",
    "import urllib3\n",
    "\n",
    "# [QUAN TR·ªåNG] T·∫Øt c·∫£nh b√°o b·∫£o m·∫≠t (SSL Warning) ƒë·ªÉ crawl web ch√≠nh ph·ªß c≈©\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "# --- C·∫§U H√åNH ---\n",
    "OUTPUT_FILE = \"targeted_knowledge.parquet\"\n",
    "MAX_PAGES = 5\n",
    "\n",
    "CAMPAIGNS = [\n",
    "    {\n",
    "        \"name\": \"Tu_Lieu_Dang\",\n",
    "        \"base_url\": \"https://tulieuvankien.dangcongsan.vn\",\n",
    "        \"seed_urls\": [\n",
    "            \"https://tulieuvankien.dangcongsan.vn/ho-chi-minh-toan-tap\",\n",
    "            \"https://tulieuvankien.dangcongsan.vn/van-kien-tu-lieu-ve-dang\"\n",
    "        ],\n",
    "        # Regex linh ho·∫°t h∆°n: Ch·∫•p nh·∫≠n m·ªçi link con ch·ª©a t·ª´ kh√≥a\n",
    "        \"link_pattern\": r\"(ho-chi-minh-toan-tap|van-kien-tu-lieu-ve-dang)/\" \n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Di_San_Van_Hoa\",\n",
    "        \"base_url\": \"http://dsvh.gov.vn\", # ƒê·ªïi sang trang C·ª•c Di s·∫£n vƒÉn h√≥a (chuy√™n s√¢u h∆°n)\n",
    "        \"seed_urls\": [\n",
    "            \"http://dsvh.gov.vn/di-tich-quoc-gia-dac-biet-1756\",\n",
    "            \"http://dsvh.gov.vn/di-tich-quoc-gia-1757\"\n",
    "        ],\n",
    "        \"link_pattern\": r\"dsvh.gov.vn/.*\" \n",
    "    }\n",
    "]\n",
    "\n",
    "def get_soup(url):\n",
    "    \"\"\"G·ª≠i request v·ªõi ch·∫ø ƒë·ªô 'gi·∫£ danh' tr√¨nh duy·ªát th·∫≠t\"\"\"\n",
    "    try:\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',\n",
    "            'Referer': 'https://google.com'\n",
    "        }\n",
    "        # [QUAN TR·ªåNG] verify=False ƒë·ªÉ b·ªè qua l·ªói SSL\n",
    "        resp = requests.get(url, headers=headers, timeout=20, verify=False)\n",
    "        \n",
    "        if resp.status_code == 200:\n",
    "            # In ra ƒë·ªô d√†i n·ªôi dung ƒë·ªÉ debug\n",
    "            print(f\"    ‚úÖ Connected (Size: {len(resp.content)} bytes)\")\n",
    "            return BeautifulSoup(resp.content, 'html.parser')\n",
    "        else:\n",
    "            print(f\"    ‚ùå Status Code: {resp.status_code}\")\n",
    "    except Exception as e:\n",
    "        print(f\"    ‚ö†Ô∏è Connect Error: {url} - {e}\")\n",
    "    return None\n",
    "\n",
    "def extract_links_from_list(campaign, url):\n",
    "    links = set()\n",
    "    print(f\"  üîç Inspecting: {url}\")\n",
    "    soup = get_soup(url)\n",
    "    \n",
    "    if not soup: \n",
    "        print(\"    ‚ùå Kh√¥ng l·∫•y ƒë∆∞·ª£c HTML.\")\n",
    "        return []\n",
    "\n",
    "    found_count = 0\n",
    "    match_count = 0\n",
    "    \n",
    "    # T√¨m t·∫•t c·∫£ th·∫ª a\n",
    "    all_tags = soup.find_all('a', href=True)\n",
    "    print(f\"    ‚ÑπÔ∏è T√¨m th·∫•y {len(all_tags)} th·∫ª <a> trong trang.\")\n",
    "\n",
    "    for a in all_tags:\n",
    "        href = a['href']\n",
    "        full_url = urljoin(campaign['base_url'], href)\n",
    "        \n",
    "        # [DEBUG] In th·ª≠ 3 link ƒë·∫ßu ti√™n ƒë·ªÉ xem format\n",
    "        if found_count < 3:\n",
    "            print(f\"      üëÄ Sample link: {full_url}\")\n",
    "        found_count += 1\n",
    "\n",
    "        # L·ªçc link\n",
    "        if re.search(campaign['link_pattern'], full_url):\n",
    "            if any(x in full_url for x in ['print', 'javascript', '#', 'download', 'jpg', 'png']):\n",
    "                continue\n",
    "            \n",
    "            # Ch·ªâ l·∫•y link chi ti·∫øt (th∆∞·ªùng d√†i h∆°n link danh m·ª•c)\n",
    "            if len(full_url) > len(url) + 5: \n",
    "                links.add(full_url)\n",
    "                match_count += 1\n",
    "    \n",
    "    print(f\"    => L·ªçc ƒë∆∞·ª£c {match_count} link ph√π h·ª£p pattern.\")\n",
    "    return list(links)\n",
    "\n",
    "def crawl_article(url, category):\n",
    "    try:\n",
    "        # Trafilatura c≈©ng c·∫ßn config ƒë·ªÉ b·ªè qua SSL\n",
    "        config = trafilatura.settings.use_config()\n",
    "        config.set(\"DEFAULT\", \"USER_AGENT\", \"Mozilla/5.0\")\n",
    "        \n",
    "        # Download th·ªß c√¥ng b·∫±ng requests ƒë·ªÉ bypass SSL, sau ƒë√≥ ƒë∆∞a v√†o trafilatura\n",
    "        resp = requests.get(url, verify=False, timeout=10)\n",
    "        \n",
    "        if resp.status_code == 200:\n",
    "            data = trafilatura.extract(resp.text, output_format=\"json\", include_comments=False)\n",
    "            if data:\n",
    "                import json\n",
    "                j = json.loads(data)\n",
    "                title = j.get('title', '')\n",
    "                text = j.get('text', '')\n",
    "                \n",
    "                # Validation: B·ªè qua b√†i qu√° ng·∫Øn (l·ªói parse)\n",
    "                if len(text) < 100: return None\n",
    "                \n",
    "                return {\n",
    "                    \"doc_title\": title,\n",
    "                    \"doc_url\": url,\n",
    "                    \"doc_category\": category,\n",
    "                    \"original_text\": text,\n",
    "                    \"vector_text\": f\"Ngu·ªìn: {category}\\nTi√™u ƒë·ªÅ: {title}\\nN·ªôi dung:\\n{text}\",\n",
    "                    \"display_text\": f\"Ngu·ªìn: {category}\\nTi√™u ƒë·ªÅ: {title}\\nN·ªôi dung:\\n{text}\",\n",
    "                    \"chunk_id\": f\"crawl_{int(time.time())}_{random.randint(1000,9999)}\"\n",
    "                }\n",
    "    except: pass\n",
    "    return None\n",
    "\n",
    "def main():\n",
    "    print(\"üï∑Ô∏è STARTING TARGETED CRAWL (V2 - SSL BYPASS)...\")\n",
    "    all_data = []\n",
    "    \n",
    "    for camp in CAMPAIGNS:\n",
    "        print(f\"\\nüöÄ Campaign: {camp['name']}\")\n",
    "        campaign_links = set()\n",
    "        \n",
    "        # 1. Qu√©t danh s√°ch\n",
    "        for seed in camp['seed_urls']:\n",
    "            links = extract_links_from_list(camp, seed)\n",
    "            campaign_links.update(links)\n",
    "            \n",
    "            # Pagination c∆° b·∫£n (Trang 2)\n",
    "            # Th∆∞·ªùng web VN d√πng ?page=2 ho·∫∑c /p2\n",
    "            next_page = f\"{seed}?page=2\"\n",
    "            print(f\"  üëâ Th·ª≠ trang 2: {next_page}\")\n",
    "            links_p2 = extract_links_from_list(camp, next_page)\n",
    "            campaign_links.update(links_p2)\n",
    "\n",
    "        unique_links = list(campaign_links)\n",
    "        print(f\"  => T·ªïng link thu ƒë∆∞·ª£c cho {camp['name']}: {len(unique_links)}\")\n",
    "        \n",
    "        # 2. Crawl chi ti·∫øt\n",
    "        if unique_links:\n",
    "            print(f\"  Downloading content ({len(unique_links)} b√†i)...\")\n",
    "            for url in tqdm(unique_links):\n",
    "                row = crawl_article(url, camp['name'])\n",
    "                if row:\n",
    "                    all_data.append(row)\n",
    "                time.sleep(random.uniform(0.5, 1.0))\n",
    "\n",
    "    # 3. L∆∞u\n",
    "    if all_data:\n",
    "        df = pd.DataFrame(all_data)\n",
    "        # Lo·∫°i b·ªè tr√πng l·∫∑p n·ªôi dung\n",
    "        df.drop_duplicates(subset=['doc_title'], inplace=True)\n",
    "        \n",
    "        df.to_parquet(OUTPUT_FILE, index=False)\n",
    "        print(f\"\\n‚úÖ DONE! ƒê√£ l∆∞u {len(df)} b√†i vi·∫øt ch·∫•t l∆∞·ª£ng v√†o {OUTPUT_FILE}\")\n",
    "        \n",
    "        # Preview\n",
    "        print(\"\\nüëÄ V√≠ d·ª• d·ªØ li·ªáu:\")\n",
    "        print(df[['doc_title', 'doc_url']].head())\n",
    "    else:\n",
    "        print(\"\\n‚ùå V·∫´n kh√¥ng l·∫•y ƒë∆∞·ª£c d·ªØ li·ªáu n√†o. H√£y copy log tr√™n ƒë·ªÉ debug.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "772fad07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ B·∫ÆT ƒê·∫¶U CRAWL (FIXED VERSION)...\n",
      "\n",
      "üìÇ ƒêang x·ª≠ l√Ω ngu·ªìn: Nguoi_Ke_Su\n",
      "   -> ƒêang qu√©t 150 trang danh m·ª•c...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [03:41<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   => T√¨m th·∫•y 453 link b√†i vi·∫øt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 453/453 [11:33<00:00,  1.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚ùå Kh√¥ng t·∫£i ƒë∆∞·ª£c n·ªôi dung b√†i n√†o.\n",
      "\n",
      "üìÇ ƒêang x·ª≠ l√Ω ngu·ªìn: Tuyen_Giao\n",
      "   -> ƒêang qu√©t 150 trang danh m·ª•c...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:00<00:00, 204.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   => T√¨m th·∫•y 0 link b√†i vi·∫øt.\n",
      "   ‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y link n√†o. B·ªè qua ngu·ªìn n√†y.\n",
      "\n",
      "üìÇ ƒêang x·ª≠ l√Ω ngu·ªìn: Van_Ban_Chinh_Phu\n",
      "   -> ƒêang qu√©t 50 trang danh m·ª•c...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:52<00:00,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   => T√¨m th·∫•y 0 link b√†i vi·∫øt.\n",
      "   ‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y link n√†o. B·ªè qua ngu·ªìn n√†y.\n",
      "\n",
      "üéâ T·ªîNG K·∫æT: ƒê√£ thu th·∫≠p 0 b√†i vi·∫øt m·ªõi.\n",
      "üëâ H√£y th√™m c√°c file 'crawl_*.parquet' v√†o build_bm25_incremental.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import trafilatura\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "from urllib.parse import urljoin\n",
    "from tqdm import tqdm\n",
    "import urllib3\n",
    "import hashlib\n",
    "import os\n",
    "\n",
    "# T·∫Øt c·∫£nh b√°o SSL\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "# --- C·∫§U H√åNH ---\n",
    "MAX_PAGES = 50  # S·ªë trang m·ªói m·ª•c\n",
    "\n",
    "# ƒê·ªãnh nghƒ©a l·∫°i Campaign v·ªõi ngu·ªìn d·ªÖ th·ªü h∆°n\n",
    "CAMPAIGNS = [\n",
    "    # 1. L·ªäCH S·ª¨ (ƒê√£ ngon, gi·ªØ nguy√™n)\n",
    "    {\n",
    "        \"name\": \"Nguoi_Ke_Su\",\n",
    "        \"base_url\": \"https://nguoikesu.com\",\n",
    "        \"seed_urls\": [\n",
    "            \"https://nguoikesu.com/nhan-vat\",\n",
    "            \"https://nguoikesu.com/dong-lich-su\",\n",
    "            \"https://nguoikesu.com/di-tich-lich-su\"\n",
    "        ],\n",
    "        \"link_pattern\": r\"nguoikesu.com/(nhan-vat|dong-lich-su|di-tich-lich-su)/\",\n",
    "        \"page_param\": \"?start={}\", # start=0, 5, 10\n",
    "        \"step\": 5\n",
    "    },\n",
    "    \n",
    "    # 2. CH√çNH TR·ªä (C·∫≠p nh·∫≠t Seed URL)\n",
    "    {\n",
    "        \"name\": \"Tuyen_Giao\",\n",
    "        \"base_url\": \"https://tuyengiao.vn\",\n",
    "        \"seed_urls\": [\n",
    "            \"https://tuyengiao.vn/hoc-tap-va-lam-theo-loi-bac\",\n",
    "            \"https://tuyengiao.vn/bao-ve-nen-tang-tu-tuong-cua-dang\",\n",
    "            \"https://tuyengiao.vn/van-hoa-xa-hoi\"\n",
    "        ],\n",
    "        # L·∫•y t·∫•t c·∫£ link b√†i vi·∫øt (th∆∞·ªùng c√≥ .html ho·∫∑c kh√¥ng c√≥ ext nh∆∞ng n·∫±m trong subfolder)\n",
    "        \"link_pattern\": r\"tuyengiao.vn/.*\", \n",
    "        \"page_param\": \"?page={}\", \n",
    "        \"step\": 1\n",
    "    },\n",
    "\n",
    "    # 3. LU·∫¨T (Thay th·∫ø VBPL b·∫±ng ChinhPhu.vn - D·ªÖ crawl h∆°n)\n",
    "    {\n",
    "        \"name\": \"Van_Ban_Chinh_Phu\",\n",
    "        \"base_url\": \"https://vanban.chinhphu.vn\",\n",
    "        \"seed_urls\": [\n",
    "            # Trang t√¨m ki·∫øm vƒÉn b·∫£n m·ªõi\n",
    "            \"https://vanban.chinhphu.vn/?pageid=27160\", \n",
    "        ],\n",
    "        # Link chi ti·∫øt th∆∞·ªùng ch·ª©a 'van-ban'\n",
    "        \"link_pattern\": r\"vanban.chinhphu.vn/.*van-ban\", \n",
    "        \"page_param\": \"&page={}\", \n",
    "        \"step\": 1\n",
    "    }\n",
    "]\n",
    "\n",
    "def get_soup(url):\n",
    "    try:\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "        }\n",
    "        # verify=False ƒë·ªÉ bypass l·ªói SSL c·ªßa web ch√≠nh ph·ªß\n",
    "        resp = requests.get(url, headers=headers, timeout=20, verify=False)\n",
    "        if resp.status_code == 200:\n",
    "            return BeautifulSoup(resp.content, 'html.parser')\n",
    "    except Exception as e:\n",
    "        # print(f\"L·ªói connect {url}: {e}\")\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "def generate_urls(camp):\n",
    "    urls = []\n",
    "    for seed in camp['seed_urls']:\n",
    "        urls.append(seed)\n",
    "        for i in range(2, MAX_PAGES + 1):\n",
    "            # T√≠nh to√°n tham s·ªë ph√¢n trang\n",
    "            val = i if camp.get('step', 1) == 1 else (i-1) * camp['step']\n",
    "            \n",
    "            if \"{}\" in camp['page_param']:\n",
    "                param = camp['page_param'].format(val)\n",
    "            else:\n",
    "                param = camp['page_param'] + str(val)\n",
    "                \n",
    "            if \"?\" in seed:\n",
    "                full = f\"{seed}&{param.replace('?', '')}\"\n",
    "            else:\n",
    "                full = f\"{seed}{param}\"\n",
    "            urls.append(full)\n",
    "    return urls\n",
    "\n",
    "def extract_links(camp, url):\n",
    "    soup = get_soup(url)\n",
    "    if not soup: return []\n",
    "    \n",
    "    links = set()\n",
    "    for a in soup.find_all('a', href=True):\n",
    "        href = a['href']\n",
    "        full = urljoin(camp['base_url'], href)\n",
    "        \n",
    "        # L·ªçc r√°c\n",
    "        if any(x in full for x in ['#', 'jpg', 'pdf', 'doc', 'download', 'print', 'javascript', 'mailto']):\n",
    "            continue\n",
    "            \n",
    "        if re.search(camp['link_pattern'], full):\n",
    "            # V·ªõi chinhphu.vn, link ph·∫£i ch·ª©a 'handle' ho·∫∑c 'chi-tiet'\n",
    "            if camp['name'] == \"Van_Ban_Chinh_Phu\":\n",
    "                if \"chi-tiet\" in full or \"handle\" in full:\n",
    "                    links.add(full)\n",
    "            else:\n",
    "                # C√°c trang kh√°c: ƒë·ªô d√†i URL ph·∫£i ƒë·ªß l·ªõn (tr√°nh link trang ch·ªß)\n",
    "                if len(full) > len(camp['base_url']) + 10:\n",
    "                    links.add(full)\n",
    "    return list(links)\n",
    "\n",
    "def crawl_content(url, category):\n",
    "    try:\n",
    "        # D√πng requests t·∫£i tr∆∞·ªõc ƒë·ªÉ bypass SSL\n",
    "        resp = requests.get(url, verify=False, timeout=15, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        if resp.status_code != 200: return None\n",
    "        \n",
    "        # Parse\n",
    "        data = trafilatura.extract(resp.text, output_format=\"json\", include_comments=False)\n",
    "        if data:\n",
    "            import json\n",
    "            j = json.loads(data)\n",
    "            title = j.get('title', '').strip()\n",
    "            text = j.get('text', '').strip()\n",
    "            \n",
    "            if len(text) < 200: return None\n",
    "            \n",
    "            doc_hash = hashlib.md5(url.encode()).hexdigest()[:10]\n",
    "            \n",
    "            return {\n",
    "                \"chunk_id\": f\"{category}_{doc_hash}\",\n",
    "                \"doc_title\": title,\n",
    "                \"doc_url\": url,\n",
    "                \"doc_category\": category,\n",
    "                \"vector_text\": f\"Ngu·ªìn: {category}\\nTi√™u ƒë·ªÅ: {title}\\nN·ªôi dung:\\n{text}\",\n",
    "                \"display_text\": f\"Title: {title}\\nSource: {url}\\n\\n{text}\"\n",
    "            }\n",
    "    except: pass\n",
    "    return None\n",
    "\n",
    "def main():\n",
    "    print(\"üöÄ B·∫ÆT ƒê·∫¶U CRAWL (FIXED VERSION)...\")\n",
    "    \n",
    "    total_collected = 0\n",
    "    \n",
    "    for camp in CAMPAIGNS:\n",
    "        print(f\"\\nüìÇ ƒêang x·ª≠ l√Ω ngu·ªìn: {camp['name']}\")\n",
    "        list_urls = generate_urls(camp)\n",
    "        \n",
    "        # 1. Qu√©t Link\n",
    "        article_links = set()\n",
    "        print(f\"   -> ƒêang qu√©t {len(list_urls)} trang danh m·ª•c...\")\n",
    "        for l_url in tqdm(list_urls, desc=\"Scanning\"):\n",
    "            found = extract_links(camp, l_url)\n",
    "            article_links.update(found)\n",
    "        \n",
    "        print(f\"   => T√¨m th·∫•y {len(article_links)} link b√†i vi·∫øt.\")\n",
    "        if len(article_links) == 0:\n",
    "            print(\"   ‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y link n√†o. B·ªè qua ngu·ªìn n√†y.\")\n",
    "            continue\n",
    "\n",
    "        # 2. T·∫£i n·ªôi dung\n",
    "        rows = []\n",
    "        for url in tqdm(list(article_links), desc=\"Downloading\"):\n",
    "            row = crawl_content(url, camp['name'])\n",
    "            if row:\n",
    "                rows.append(row)\n",
    "            # Sleep nh·∫π ƒë·ªÉ kh√¥ng b·ªã ban\n",
    "            time.sleep(0.2) \n",
    "            \n",
    "        # 3. L∆ØU NGAY L·∫¨P T·ª®C (Save Checkpoint)\n",
    "        if rows:\n",
    "            filename = f\"crawl_{camp['name']}.parquet\"\n",
    "            df = pd.DataFrame(rows)\n",
    "            df.drop_duplicates(subset=['doc_url'], inplace=True)\n",
    "            df.to_parquet(filename, index=False)\n",
    "            print(f\"   üíæ ƒê√£ l∆∞u {len(df)} b√†i v√†o '{filename}'\")\n",
    "            total_collected += len(df)\n",
    "        else:\n",
    "            print(\"   ‚ùå Kh√¥ng t·∫£i ƒë∆∞·ª£c n·ªôi dung b√†i n√†o.\")\n",
    "\n",
    "    print(f\"\\nüéâ T·ªîNG K·∫æT: ƒê√£ thu th·∫≠p {total_collected} b√†i vi·∫øt m·ªõi.\")\n",
    "    print(\"üëâ H√£y th√™m c√°c file 'crawl_*.parquet' v√†o build_bm25_incremental.py\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43422074",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vnpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
