import google.generativeai as genai
import pandas as pd
import json
import time
import os
from tqdm import tqdm
from config import Config

# --- Cáº¤U HÃŒNH GEMINI ---
GEMINI_API_KEY = "AIzaSyC5kbuXLInHNLX4S6OWCkGGeZh4NPHtIyA" 

# Cáº¥u hÃ¬nh Model
genai.configure(api_key=GEMINI_API_KEY)
model = genai.GenerativeModel('gemini-1.5-flash-latest') # DÃ¹ng Flash cho nhanh vÃ  quota cao

# Danh sÃ¡ch danh má»¥c chuáº©n (Ä‘á»ƒ Gemini chá»n)
TARGET_CATEGORIES = [
    "Lá»‹ch sá»­ Viá»‡t Nam", "Äá»‹a lÃ½ & HÃ nh chÃ­nh", "PhÃ¡p luáº­t & NhÃ  nÆ°á»›c", 
    "VÄƒn hÃ³a & XÃ£ há»™i", "Kinh táº¿ & Doanh nghiá»‡p", "QuÃ¢n sá»± & Quá»‘c phÃ²ng",
    "NhÃ¢n váº­t lá»‹ch sá»­", "GiÃ¡o dá»¥c & Y táº¿", "Khoa há»c & Ká»¹ thuáº­t"
]

def clean_json_string(text):
    """LÃ m sáº¡ch string tráº£ vá» tá»« Gemini Ä‘á»ƒ parse JSON"""
    text = text.strip()
    if text.startswith("```json"):
        text = text[7:]
    if text.startswith("```"):
        text = text[3:]
    if text.endswith("```"):
        text = text[:-3]
    return text.strip()

def classify_batch(titles_batch):
    """Gá»­i 1 lÃ´ tiÃªu Ä‘á» cho Gemini phÃ¢n loáº¡i"""
    prompt = f"""
    Báº¡n lÃ  má»™t chuyÃªn gia phÃ¢n loáº¡i dá»¯ liá»‡u RAG. 
    HÃ£y phÃ¢n loáº¡i danh sÃ¡ch cÃ¡c TiÃªu Ä‘á» bÃ i viáº¿t Wikipedia sau vÃ o 1 trong cÃ¡c nhÃ³m: {json.dumps(TARGET_CATEGORIES, ensure_ascii=False)}.
    
    Quy táº¯c:
    1. Tráº£ vá» Ä‘á»‹nh dáº¡ng JSON: {{"TiÃªu Ä‘á» 1": "NhÃ³m 1", "TiÃªu Ä‘á» 2": "NhÃ³m 2"}}
    2. Náº¿u khÃ´ng cháº¯c cháº¯n, hÃ£y chá»n nhÃ³m phÃ¹ há»£p nháº¥t hoáº·c "Tá»•ng há»£p".
    3. KHÃ”NG giáº£i thÃ­ch, chá»‰ tráº£ vá» JSON thuáº§n.

    Danh sÃ¡ch tiÃªu Ä‘á»:
    {json.dumps(titles_batch, ensure_ascii=False)}
    """
    
    try:
        # Gá»i Gemini
        response = model.generate_content(prompt)
        json_str = clean_json_string(response.text)
        return json.loads(json_str)
    except Exception as e:
        print(f"âš ï¸ Lá»—i Batch Gemini: {e}")
        return {}


def run_gemini_categorization():
    input_file = Config.LATEST_CHUNKS_FILE
    
    if not input_file.exists():
        print("âŒ ChÆ°a cÃ³ file chunks. Cháº¡y chunking.py trÆ°á»›c!")
        return

    print(f"ğŸ“‚ Äang Ä‘á»c: {input_file}")
    df = pd.read_parquet(input_file)
    
    # 1. Láº¥y danh sÃ¡ch tiÃªu Ä‘á» duy nháº¥t
    unique_titles = df['doc_title'].unique().tolist()
    print(f"ğŸ” TÃ¬m tháº¥y {len(unique_titles)} bÃ i viáº¿t duy nháº¥t.")
    
    # Checkpoint (Ä‘á»ƒ lá»¡ máº¡ng lag khÃ´ng máº¥t cÃ´ng cháº¡y láº¡i)
    cache_file = "gemini_categories_cache.json"
    title_to_cat = {}
    
    if os.path.exists(cache_file):
        with open(cache_file, "r", encoding="utf-8") as f:
            title_to_cat = json.load(f)
        print(f"ğŸ”„ ÄÃ£ load {len(title_to_cat)} bÃ i tá»« cache.")
        
    # Lá»c nhá»¯ng bÃ i chÆ°a lÃ m
    titles_to_process = [t for t in unique_titles if t not in title_to_cat]
    print(f"ğŸ”¥ Cáº§n phÃ¢n loáº¡i: {len(titles_to_process)} bÃ i.")

    # 2. Cháº¡y Batching
    BATCH_SIZE = 40 # Gá»­i 40 tiÃªu Ä‘á» 1 láº§n (Flash chá»‹u tá»‘t)
    
    # Thanh tiáº¿n trÃ¬nh
    pbar = tqdm(total=len(titles_to_process))
    
    for i in range(0, len(titles_to_process), BATCH_SIZE):
        batch = titles_to_process[i : i + BATCH_SIZE]
        
        # Gá»i Gemini
        results = classify_batch(batch)
        
        # LÆ°u káº¿t quáº£
        title_to_cat.update(results)
        
        # Cáº­p nháº­t tiáº¿n trÃ¬nh
        pbar.update(len(batch))
        
        # LÆ°u Cache má»—i 5 batch (an toÃ n)
        if i % (BATCH_SIZE * 5) == 0:
            with open(cache_file, "w", encoding="utf-8") as f:
                json.dump(title_to_cat, f, ensure_ascii=False)
        
        # Rate Limit Sleep (Gemini Free Tier giá»›i háº¡n 15 req/phÃºt -> 4s/req)
        # Batch 40 bÃ i x 15 req = 600 bÃ i/phÃºt -> 50k bÃ i máº¥t ~1.5 tiáº¿ng
        time.sleep(4) 

    pbar.close()
    
    # LÆ°u cache láº§n cuá»‘i
    with open(cache_file, "w", encoding="utf-8") as f:
        json.dump(title_to_cat, f, ensure_ascii=False)

    # 3. Map ngÆ°á»£c láº¡i vÃ o DataFrame vÃ  cáº­p nháº­t vector_text
    print("ğŸ”„ Äang cáº­p nháº­t dá»¯ liá»‡u gá»‘c...")
    
    def apply_update(row):
        title = row['doc_title']
        # Láº¥y category tá»« Gemini, náº¿u lá»—i/thiáº¿u thÃ¬ dÃ¹ng cÃ¡i cÅ©
        new_cat = title_to_cat.get(title, row['doc_category'])
        
        # Cáº­p nháº­t vector_text
        # Format cÅ© trong chunking.py: "TiÃªu Ä‘á»: ...\nLÄ©nh vá»±c: ...\nNá»™i dung: ..."
        old_vec_text = row['vector_text']
        
        # Thay tháº¿ dÃ²ng LÄ©nh vá»±c cÅ© báº±ng cÃ¡i má»›i
        lines = old_vec_text.split('\n')
        new_lines = []
        for line in lines:
            if line.startswith("LÄ©nh vá»±c:"):
                new_lines.append(f"LÄ©nh vá»±c: {new_cat}")
            else:
                new_lines.append(line)
        
        return pd.Series([new_cat, '\n'.join(new_lines)])

    tqdm.pandas(desc="Applying updates")
    df[['doc_category', 'vector_text']] = df.apply(apply_update, axis=1)

    # 4. LÆ°u Parquet
    df.to_parquet(input_file, index=False)
    print(f"âœ… HOÃ€N Táº¤T! ÄÃ£ cáº­p nháº­t category xá»‹n tá»« Gemini vÃ o {input_file}")
    print("ğŸ‘‰ Giá» báº¡n hÃ£y cháº¡y indexing.py")

if __name__ == "__main__":
    run_gemini_categorization()