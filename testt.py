import asyncio
import sys
import json
import logging
import pandas as pd
import aiohttp
from pathlib import Path

# Qdrant
from qdrant_client import AsyncQdrantClient

# modules
from config import Config, TIMEOUT_PER_QUESTION, LIMITER_EMBED, LIMITER_LARGE, LIMITER_SMALL
from utils.logger import logger
from core.retriever import HybridRetriever
from core.logic import process_row_logic


# ==============================================================================
# 0. Cáº¤U HÃŒNH CHIáº¾N THUáº¬T (Tactical Config)
# ==============================================================================
Config.LOGS_DIR.mkdir(parents=True, exist_ok=True)
Config.OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

# File lÆ°u káº¿t quáº£ (DÃ¹ng Ä‘á»ƒ Resume)
OUTPUT_FILE = Config.OUTPUT_FILE
DEBUG_LOG_FILE = Config.DEBUG_LOG_FILE

# Constants
BM25_FILE = Config.BM25_FILE

async def main():
    # 1. Load Data
    # files = [Config.BASE_DIR / "data" / "val.json", Config.BASE_DIR / "data" / "test.json"]
    files = [Config.BASE_DIR / "data" / "test.json"]
    input_file = next((f for f in files if f.exists()), None)
    if not input_file: 
        logger.error("âŒ Input file not found!")
        return
    
    with open(input_file, 'r', encoding='utf-8') as f: data = json.load(f)

    # 2. Check Resume (Äá»c file Ä‘Ã£ lÆ°u Ä‘á»ƒ cháº¡y tiáº¿p)
    processed_ids = set()
    if OUTPUT_FILE.exists():
        try:
            df_done = pd.read_csv(OUTPUT_FILE)
            processed_ids = set(df_done['qid'].astype(str))
            logger.info(f"RESUMING... Found {len(processed_ids)} processed questions.")
        except: pass
    
    # Lá»c ra nhá»¯ng cÃ¢u chÆ°a lÃ m
    data_to_process = [r for r in data if str(r.get('qid', r.get('id'))) not in processed_ids]
    
    if not data_to_process:
        logger.info("âœ… ALL DONE! Nothing to process.")
        return

    logger.info(f"ğŸš€ REMAINING: {len(data_to_process)}/{len(data)} questions")

    # 3. Setup Qdrant & Retriever
    qdrant_client = AsyncQdrantClient(url=Config.QDRANT_URL, api_key=Config.QDRANT_API_KEY, timeout=30)
    retriever = HybridRetriever(
        qdrant_client=qdrant_client, 
        collection_name=Config.COLLECTION_NAME
    )
    stats = {'used_large': 0, 'used_small': 0}
    
    # 4. Run Sequential (VÃ²ng láº·p Ä‘Æ¡n luá»“ng - AN TOÃ€N NHáº¤T)
    # limit=1 Ä‘á»ƒ Ä‘áº£m báº£o chá»‰ cÃ³ 1 request táº¡i 1 thá»i Ä‘iá»ƒm
    conn = aiohttp.TCPConnector(limit=1, force_close=True, enable_cleanup_closed=True)
    
    async with aiohttp.ClientSession(connector=conn) as session:
        
        for i, row in enumerate(data_to_process):
            qid = row.get('qid', row.get('id'))
            
            # Retry loop cho tá»«ng cÃ¢u (Thá»­ láº¡i tá»‘i Ä‘a 3 láº§n náº¿u lá»—i máº¡ng)
            for attempt in range(3):
                try:
                    # Timeout cá»©ng cho má»—i cÃ¢u há»i
                    result = await asyncio.wait_for(
                        process_row_logic(session, retriever, row, stats),
                        timeout=TIMEOUT_PER_QUESTION
                    )
                    
                    # --- GHI FILE NGAY Láº¬P Tá»¨C (Save Scumming) ---
                    df_res = pd.DataFrame([result])
                    need_header = not OUTPUT_FILE.exists()
                    df_res[['qid', 'answer']].to_csv(OUTPUT_FILE, mode='a', header=need_header, index=False)
                    
                    # Done cÃ¢u nÃ y -> ThoÃ¡t vÃ²ng láº·p retry -> Sang cÃ¢u tiáº¿p theo
                    break 
                    
                except asyncio.TimeoutError:
                    logger.warning(f"â° Timeout Q:{qid} (Attempt {attempt+1})")
                    # Náº¿u thá»­ Ä‘áº¿n láº§n cuá»‘i váº«n timeout -> Äiá»n Ä‘Ã¡p Ã¡n 'A' Ä‘á»ƒ khÃ´ng bá»‹ káº¹t mÃ£i
                    if attempt == 2:
                        pd.DataFrame([{"qid": qid, "answer": "A"}]).to_csv(OUTPUT_FILE, mode='a', header=not OUTPUT_FILE.exists(), index=False)
                        
                except Exception as e:
                    logger.error(f"âŒ Error Q:{qid}: {e}")
                    await asyncio.sleep(5) # Chá» 5s trÆ°á»›c khi thá»­ láº¡i

            # [QUAN TRá»ŒNG] Nghá»‰ 1 giÃ¢y giá»¯a cÃ¡c cÃ¢u há»i Ä‘á»ƒ Server VNPT há»“i phá»¥c quota
            await asyncio.sleep(1)

    # 5. Cleanup & Stats
    await qdrant_client.close()
    logger.info("ğŸ‰ BATCH COMPLETED!")

    # In thá»‘ng kÃª (náº¿u cÃ³ Ä‘Ã¡p Ã¡n máº«u)
    if OUTPUT_FILE.exists():
        print("\n" + "="*40)
        print("Tá»”NG Káº¾T TOÃ€N Bá»˜ (CUMULATIVE STATS)")
        print("="*40)
        try:
            df_results = pd.read_csv(OUTPUT_FILE)
            ground_truth = {
                str(r.get('qid', r.get('id'))): str(r.get('answer')).strip() 
                for r in data if r.get('answer')
            }
            
            if not ground_truth:
                print("âš ï¸ Táº­p dá»¯ liá»‡u Test (khÃ´ng cÃ³ Ä‘Ã¡p Ã¡n) -> KhÃ´ng tÃ­nh Ä‘iá»ƒm.")
            else:
                correct_count = 0
                total_checked = 0
                for _, row in df_results.iterrows():
                    qid = str(row['qid'])
                    pred = str(row['answer']).strip()
                    if qid in ground_truth:
                        total_checked += 1
                        if pred == ground_truth[qid]:
                            correct_count += 1
                
                if total_checked > 0:
                    acc = (correct_count / total_checked) * 100
                    print(f"âœ… ÄÃ£ lÃ m: {total_checked}/{len(ground_truth)} cÃ¢u")
                    print(f"ğŸ¯ ÄÃºng  : {correct_count} cÃ¢u")
                    print(f"ğŸ“ˆ Tá»· lá»‡ : {acc:.2f}%")
        except Exception as e:
            print(f"Lá»—i tÃ­nh Ä‘iá»ƒm: {e}")

        print(f"ğŸ“ File káº¿t quáº£: {OUTPUT_FILE}")

if __name__ == "__main__":
    if sys.platform == 'win32': asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
    asyncio.run(main())

    