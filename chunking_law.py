import pandas as pd
import re
import os
import glob
from datetime import datetime

# --- Cáº¤U HÃŒNH ---
INPUT_DIR = "phap_luat_txt"
OUTPUT_FILE = "output/1_manual_law_strict.parquet"

FILENAME_MAP = {
    "hien_phap_2025.txt": "Hiáº¿n phÃ¡p nÆ°á»›c CHXHCN Viá»‡t Nam 2013", # Nhá»› sá»­a tÃªn file náº¿u báº¡n Ä‘Ã£ Ä‘á»•i láº¡i thÃ nh 2013
    "hien_phap_2013.txt": "Hiáº¿n phÃ¡p nÆ°á»›c CHXHCN Viá»‡t Nam 2013",
    "luat_an_ninh_mang.txt": "Luáº­t An ninh máº¡ng 2018",
    "luat_dan_su.txt": "Bá»™ luáº­t DÃ¢n sá»± 2015",
    "luat_dat_dai.txt": "Luáº­t Äáº¥t Ä‘ai 2024",
    "luat_giao_duc.txt": "Luáº­t GiÃ¡o dá»¥c 2019",
    "luat_hinh_su.txt": "Bá»™ luáº­t HÃ¬nh sá»± 2015",
    "luat_giao_thong_duong_bo.txt": "Luáº­t Giao thÃ´ng Ä‘Æ°á»ng bá»™ 2008",
    "luat_hon_nhan_va_gia_dinh.txt": "Luáº­t HÃ´n nhÃ¢n vÃ  Gia Ä‘Ã¬nh 2014",
    "luat_lao_dong.txt": "Bá»™ luáº­t Lao Ä‘á»™ng 2019"
}

def clean_line(line):
    """XÃ³a kÃ½ tá»± rÃ¡c Ä‘áº§u/cuá»‘i dÃ²ng"""
    # Thay tháº¿ non-breaking space báº±ng space thÆ°á»ng
    line = line.replace('\xa0', ' ').replace('\u200b', '')
    return line.strip()

def parse_strict(content, doc_title):
    lines = content.split('\n')
    chunks = []
    
    # State variables
    current_context = [] # ["CHÆ¯Æ NG I", "CHáº¾ Äá»˜ CHÃNH TRá»Š"]
    current_article_header = "" # "Äiá»u 1."
    current_body = [] # ["NÆ°á»›c CHXHCN VN...", "lÃ  nÆ°á»›c Ä‘á»™c láº­p..."]
    
    # Regex neo cháº·t Ä‘áº§u dÃ²ng (^): Chá»‰ báº¯t khi "Äiá»u" Ä‘á»©ng Ä‘áº§u
    re_article_start = re.compile(r'^Äiá»u\s+\d+', re.IGNORECASE)
    re_context_start = re.compile(r'^(CHÆ¯Æ NG|Má»¤C|PHáº¦N)\s+', re.IGNORECASE)

    for line in lines:
        line = clean_line(line)
        if not line: continue
        
        # Bá» qua rÃ¡c
        if any(x in line for x in ["Táº£i vá»", "Má»¥c lá»¥c", "Vá» Ä‘áº§u trang"]): continue

        # --- CASE 1: Báº®T Gáº¶P ÄIá»€U LUáº¬T Má»šI ---
        if re_article_start.match(line):
            # 1. LÆ°u Äiá»u luáº­t CÅ¨ (náº¿u Ä‘ang gom dá»Ÿ)
            if current_article_header:
                context_str = " - ".join(current_context)
                full_text = f"VÄƒn báº£n: {doc_title}\n{context_str}\n{current_article_header}\n" + "\n".join(current_body)
                chunks.append(full_text.strip())
            
            # 2. Reset Ä‘á»ƒ báº¯t Ä‘áº§u Äiá»u luáº­t Má»šI
            current_article_header = line
            current_body = []
            
        # --- CASE 2: Báº®T Gáº¶P NGá»® Cáº¢NH (CHÆ¯Æ NG/Má»¤C) ---
        elif re_context_start.match(line) or (line.isupper() and len(line) < 100 and "ÄIá»€U" not in line and "Cá»˜NG HÃ’A" not in line):
            # Náº¿u gáº·p ChÆ°Æ¡ng má»›i -> CÅ©ng pháº£i lÆ°u Äiá»u luáº­t cÅ© láº¡i (vÃ¬ háº¿t chÆ°Æ¡ng rá»“i)
            if current_article_header:
                context_str = " - ".join(current_context)
                full_text = f"VÄƒn báº£n: {doc_title}\n{context_str}\n{current_article_header}\n" + "\n".join(current_body)
                chunks.append(full_text.strip())
                current_article_header = ""
                current_body = []

            # Cáº­p nháº­t Context
            if re_context_start.match(line):
                # Gáº·p "CHÆ¯Æ NG..." -> Reset context cÅ©
                current_context = [line]
            else:
                # Gáº·p tiÃªu Ä‘á» viáº¿t hoa "CHáº¾ Äá»˜ CHÃNH TRá»Š" -> Ná»‘i thÃªm vÃ o
                if line not in current_context:
                    current_context.append(line)

        # --- CASE 3: Ná»˜I DUNG ---
        else:
            if current_article_header:
                current_body.append(line)
            else:
                # Ná»™i dung chÆ°a thuá»™c Ä‘iá»u nÃ o (Lá»i nÃ³i Ä‘áº§u, CÄƒn cá»© phÃ¡p lÃ½...)
                pass

    # --- LÆ¯U CHUNK CUá»I CÃ™NG ---
    if current_article_header:
        context_str = " - ".join(current_context)
        full_text = f"VÄƒn báº£n: {doc_title}\n{context_str}\n{current_article_header}\n" + "\n".join(current_body)
        chunks.append(full_text.strip())
        
    return chunks

def main():
    if not os.path.exists(INPUT_DIR):
        print(f"âŒ ThÆ° má»¥c '{INPUT_DIR}' khÃ´ng tá»“n táº¡i.")
        return

    os.makedirs(os.path.dirname(OUTPUT_FILE), exist_ok=True)
    all_data = []
    txt_files = glob.glob(f"{INPUT_DIR}/*.txt")

    print(f"ğŸ“‚ TÃ¬m tháº¥y {len(txt_files)} file.")

    for file_path in txt_files:
        filename = os.path.basename(file_path)
        doc_title = FILENAME_MAP.get(filename, filename.replace(".txt", "").title())
        
        print(f"\nğŸ”¨ Processing: {filename} -> {doc_title}")
        
        try:
            # DÃ¹ng utf-8-sig Ä‘á»ƒ trÃ¡nh kÃ½ tá»± BOM (\ufeff) Ä‘áº§u file
            with open(file_path, 'r', encoding='utf-8-sig') as f:
                content = f.read()
            
            chunks = parse_strict(content, doc_title)
            
            if not chunks:
                print(f"   âš ï¸ 0 CHUNKS! Kiá»ƒm tra láº¡i xem file cÃ³ chá»¯ 'Äiá»u' á»Ÿ Ä‘áº§u dÃ²ng khÃ´ng.")
            else:
                # In ra 3 tiÃªu Ä‘á» Ä‘áº§u tiÃªn báº¯t Ä‘Æ°á»£c Ä‘á»ƒ kiá»ƒm tra
                titles = [c.split('\n')[2] for c in chunks[:3] if len(c.split('\n')) > 2]
                print(f"   âœ… OK: {len(chunks)} Ä‘iá»u luáº­t.")
                print(f"   ğŸ‘€ Sample: {titles}...")

                for i, chunk_text in enumerate(chunks):
                    # Bá» qua chunk quÃ¡ ngáº¯n
                    if len(chunk_text) < 30: continue
                    
                    all_data.append({
                        # [QUAN TRá»ŒNG] ID duy nháº¥t Ä‘á»ƒ khÃ´ng bá»‹ trÃ¹ng Ä‘Ã¨ trong Qdrant
                        # Káº¿t há»£p tÃªn file vÃ  sá»‘ thá»© tá»± chunk
                        "chunk_id": f"law_{filename}_{i}",
                        
                        # [QUAN TRá»ŒNG] CÃ¡c trÆ°á»ng khá»›p vá»›i indexing.py
                        "doc_title": doc_title,
                        "doc_category": "PhÃ¡p luáº­t",        # Äá»ƒ string, khÃ´ng Ä‘á»ƒ list
                        "doc_url": f"local/{filename}",
                        
                        # Text dÃ¹ng Ä‘á»ƒ Embed (Gá»­i lÃªn API)
                        "vector_text": chunk_text,
                        
                        # Text lÆ°u vÃ o Payload (Äá»ƒ LLM Ä‘á»c sau nÃ y)
                        "display_text": chunk_text
                    })
                
        except Exception as e:
            print(f"âŒ Error: {e}")

    # Summary
    if all_data:
        df = pd.DataFrame(all_data)
        df['crawled_at'] = datetime.now().isoformat()
        
        print("\nğŸ“Š THá»NG KÃŠ:")
        print(df['doc_title'].value_counts())
        
        df.to_parquet(OUTPUT_FILE, index=False)
        print(f"\nğŸ’¾ ÄÃ£ lÆ°u: {OUTPUT_FILE}")
    else:
        print("\nâŒ KhÃ´ng cÃ³ dá»¯ liá»‡u.")

if __name__ == "__main__":
    main()